# backend/app/services/chat_service.py
# Ana chat mesaj iÅŸleme servisi

import re
import traceback
import io
from typing import List, Dict, Any, Set
import time
from fastapi import HTTPException, status 

from app.schemas.chat import ChatRequest, ChatResponse, ChatMessage, ActiveContextFile
from app.schemas.user import UserInDB
from app.schemas.file import FileOut 
from app.repositories.base import BaseRepository
from app.storage_adapters.base import BaseStorageAdapter
from app.services import vector_service

# --- LangChain ImportlarÄ± ---
from langchain_core.documents import Document
from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser 
# --- Bitti ---

# --- ModÃ¼ler Importlar ---
from app.services.llm_providers import get_llm_for_model, get_cheap_llm
from app.services.token_tracking import TokenTracker, extract_token_usage_from_response
from app.services.chat_helpers import (
    normalize_text_for_matching,
    calculate_filename_match_score,
    identify_and_filter_high_confidence_document,
    is_list_intent,
    rerank_chunks_with_llm_wrapper,
    rerank_chunks_with_cross_encoder,
    create_hypothetical_document_for_query_wrapper,
    is_off_topic_query,
    is_help_or_support_query,
    get_help_response,
    is_greeting_query,
    get_greeting_response
)
from app.services.prompts import RAG_PROMPT_TEMPLATE


# --- Context Memory ---

class ContextMemory:
    # ... (Bu sÄ±nÄ±f deÄŸiÅŸmedi) ...
    def __init__(self): self.context_items: Dict[str, ActiveContextFile] = {}
    def set_context(self, items: List[ActiveContextFile]):
        self.context_items = {item.id: item for item in items}
        print(f"ðŸ§  BaÄŸlam HafzasÄ± AyarlandÄ±: {len(self.context_items)} kalem.")
    def get_context(self) -> List[ActiveContextFile]: return list(self.context_items.values())
    def get_file_ids(self) -> Set[str]: return {item.id for item in self.context_items.values() if item.type == 'file'}
    def get_folder_ids(self) -> Set[str]: return {item.id for item in self.context_items.values() if item.type == 'folder'}
    def has_context(self) -> bool: return bool(self.context_items)
    def clear(self):
        self.context_items = {}
        print("ðŸ—‘ï¸ BaÄŸlam HafzasÄ± Temizlendi")

_context_memory_store: Dict[str, ContextMemory] = {}

def get_context_memory_for_chat(chat_id: str) -> ContextMemory:
    if chat_id not in _context_memory_store: _context_memory_store[chat_id] = ContextMemory()
    return _context_memory_store[chat_id]

# --- GÃ¼venlik Fonksiyonu (DeÄŸiÅŸiklik yok) ---
def get_all_accessible_files_for_user(db: BaseRepository, user: UserInDB) -> List[FileOut]:
    if user.role == "Admin":
        print(f"KullanÄ±cÄ± '{user.email}' Admin. TÃ¼m tenant dosyalarÄ± getiriliyor.")
        return db.get_all_files_for_tenant(tenant_id=user.tenant_id)

    print(f"KullanÄ±cÄ± '{user.email}' (Rol: {user.role}) iÃ§in eriÅŸilebilir dosyalar hesaplanÄ±yor...")
    user_role = db.get_role_by_name(tenant_id=user.tenant_id, role_name=user.role)
    allowed_folder_ids = set()
    allowed_file_ids = set()
    if user_role:
        allowed_folder_ids = set(user_role.allowed_folders or [])
        allowed_file_ids = set(user_role.allowed_files or [])
    all_tenant_files = db.get_all_files_for_tenant(tenant_id=user.tenant_id)
    accessible_files: List[FileOut] = []
    for file in all_tenant_files:
        is_owner = file.owner_id == user.id
        is_file_allowed = file.id in allowed_file_ids
        is_folder_allowed = file.folder_id and file.folder_id in allowed_folder_ids
        if is_owner or is_file_allowed or is_folder_allowed:
            accessible_files.append(file)
    print(f"KullanÄ±cÄ± {len(accessible_files)} adet dosyaya eriÅŸebilir.")
    return accessible_files

# --- YardÄ±mcÄ± fonksiyonlar chat_helpers.py'de ---

def is_simple_query(query: str) -> bool:
    """Sorgunun basit (tek adÄ±mlÄ±/olgusal) olup olmadÄ±ÄŸÄ±nÄ± tahmin et."""
    query_lower = query.lower()
    
    # 1. KÄ±sa sorgular genellikle basittir
    if len(query.split()) < 5:
        return True
        
    # 2. SelamlaÅŸma ve basit etkileÅŸimler
    greetings = ['merhaba', 'selam', 'gÃ¼naydÄ±n', 'iyi gÃ¼nler', 'nasÄ±lsÄ±n', 'kimsin', 'ne yapabilirsin']
    if any(g in query_lower for g in greetings):
        return True
        
    # 3. Basit "nedir", "ne zaman" sorularÄ± (eÄŸer Ã§ok karmaÅŸÄ±k deÄŸilse)
    simple_starters = ['nedir', 'ne zaman', 'kim', 'nerede', 'kaÃ§']
    # EÄŸer "karÅŸÄ±laÅŸtÄ±r", "analiz et", "Ã¶zetle", "farkÄ± nedir" gibi karmaÅŸÄ±k ifadeler yoksa
    complex_indicators = ['karÅŸÄ±laÅŸtÄ±r', 'analiz', 'Ã¶zetle', 'fark', 'iliÅŸki', 'neden', 'nasÄ±l', 'yorumla', 'deÄŸerlendir']
    
    if any(s in query_lower for s in simple_starters) and not any(c in query_lower for c in complex_indicators):
        return True
        
    return False

def _get_file_bytes(file_record: FileOut, user: UserInDB, storage: BaseStorageAdapter) -> bytes:
    """
    Dosya iÃ§eriÄŸini dÃ¶ndÃ¼rÃ¼r. External storage dosyalarÄ± iÃ§in Google Drive/OneDrive'dan indirir.
    """
    # EÄŸer dosya external storage'dan geliyorsa, Google Drive/OneDrive'dan indir
    if file_record.external_file_id and file_record.external_storage_type:
        from google.cloud import firestore
        from app.storage_adapters.google_drive_adapter import GoogleDriveAdapter
        from app.storage_adapters.onedrive_adapter import OneDriveAdapter
        from app.core.config import GOOGLE_DRIVE_CLIENT_ID, GOOGLE_DRIVE_CLIENT_SECRET, ONEDRIVE_CLIENT_ID, ONEDRIVE_CLIENT_SECRET
        
        firestore_db = firestore.Client()
        storage_type = file_record.external_storage_type
        
        # KullanÄ±cÄ±nÄ±n storage baÄŸlantÄ±sÄ±nÄ± al
        if storage_type == "google_drive":
            user_storage = firestore_db.collection("user_external_storage").document(user.id).get()
            if not user_storage.exists:
                # Admin seviyesinde baÄŸlantÄ±yÄ± kontrol et
                admin_settings = firestore_db.collection("external_storage_settings").document(user.tenant_id).get()
                if not admin_settings.exists:
                    raise Exception("Google Drive baÄŸlantÄ±sÄ± bulunamadÄ±")
                admin_data = admin_settings.to_dict()
                access_token = admin_data.get('google_drive_access_token')
                refresh_token = admin_data.get('google_drive_refresh_token')
                client_id = GOOGLE_DRIVE_CLIENT_ID
                client_secret = GOOGLE_DRIVE_CLIENT_SECRET
            else:
                storage_data = user_storage.to_dict()
                access_token = storage_data.get('access_token')
                refresh_token = storage_data.get('refresh_token')
                client_id = GOOGLE_DRIVE_CLIENT_ID
                client_secret = GOOGLE_DRIVE_CLIENT_SECRET
            
            adapter = GoogleDriveAdapter()
        elif storage_type == "onedrive":
            user_storage = firestore_db.collection("user_external_storage").document(user.id).get()
            if not user_storage.exists:
                # Admin seviyesinde baÄŸlantÄ±yÄ± kontrol et
                admin_settings = firestore_db.collection("external_storage_settings").document(user.tenant_id).get()
                if not admin_settings.exists:
                    raise Exception("OneDrive baÄŸlantÄ±sÄ± bulunamadÄ±")
                admin_data = admin_settings.to_dict()
                access_token = admin_data.get('onedrive_access_token')
                refresh_token = admin_data.get('onedrive_refresh_token')
                client_id = ONEDRIVE_CLIENT_ID
                client_secret = ONEDRIVE_CLIENT_SECRET
            else:
                storage_data = user_storage.to_dict()
                access_token = storage_data.get('access_token')
                refresh_token = storage_data.get('refresh_token')
                client_id = ONEDRIVE_CLIENT_ID
                client_secret = ONEDRIVE_CLIENT_SECRET
            
            adapter = OneDriveAdapter()
        else:
            raise Exception(f"Desteklenmeyen storage tipi: {storage_type}")
        
        if not access_token:
            raise Exception(f"{storage_type} baÄŸlantÄ±sÄ± bulunamadÄ±")
        
        # Token'Ä± kontrol et ve gerekirse yenile
        try:
            if storage_type == "google_drive":
                file_bytes = adapter.download_file(
                    file_id=file_record.external_file_id,
                    access_token=access_token,
                    mime_type=file_record.content_type
                )
            else:  # onedrive
                file_bytes = adapter.download_file(
                    file_id=file_record.external_file_id,
                    access_token=access_token
                )
        except Exception as e:
            # Token sÃ¼resi dolmuÅŸ olabilir
            if refresh_token and client_id and client_secret:
                try:
                    tokens = adapter.refresh_access_token(
                        refresh_token=refresh_token,
                        client_id=client_id,
                        client_secret=client_secret
                    )
                    access_token = tokens['access_token']
                    
                    # Token'Ä± gÃ¼ncelle
                    if user_storage.exists:
                        firestore_db.collection("user_external_storage").document(user.id).update({
                            'access_token': access_token
                        })
                    else:
                        # Admin seviyesinde gÃ¼ncelle
                        update_data = {}
                        if storage_type == "google_drive":
                            update_data['google_drive_access_token'] = access_token
                        else:
                            update_data['onedrive_access_token'] = access_token
                        firestore_db.collection("external_storage_settings").document(user.tenant_id).update(update_data)
                    
                    # Tekrar dene
                    if storage_type == "google_drive":
                        file_bytes = adapter.download_file(
                            file_id=file_record.external_file_id,
                            access_token=access_token,
                            mime_type=file_record.content_type
                        )
                    else:
                        file_bytes = adapter.download_file(
                            file_id=file_record.external_file_id,
                            access_token=access_token
                        )
                except Exception as refresh_error:
                    raise Exception(f"Dosya indirilemedi (token yenileme baÅŸarÄ±sÄ±z): {refresh_error}")
            else:
                raise Exception(f"Dosya indirilemedi: {e}")
        
        return file_bytes
    else:
        # Normal dosyalar iÃ§in mevcut mantÄ±k
        if not file_record.storage_path:
            raise Exception("Dosya storage path'i bulunamadÄ±.")
        return storage.download_file_content(storage_path=file_record.storage_path)

# --- ANA FONKSÄ°YON ---
def process_chat_message(
    request: ChatRequest, user: UserInDB, db: BaseRepository, storage: BaseStorageAdapter
) -> ChatResponse:
    # traceback modÃ¼lÃ¼nÃ¼ fonksiyon baÅŸÄ±nda kullanÄ±labilir hale getir
    # (Python'Ä±n local variable algÄ±lamasÄ±nÄ± Ã¶nlemek iÃ§in)
    import traceback as tb_module
    
    t_start = time.monotonic()
    
    # Model seÃ§imini al
    model_name = request.model_name or "gemini"
    agent_type = request.agent_type or "default"
    
    # EÄŸer agent_type default ise ama Ã¶nceki mesajlarda Ã¶zel agent (excel, presentation) kullanÄ±lmÄ±ÅŸsa, devam ettir
    if agent_type == "default" and request.chat_id:
        try:
            print(f"ðŸ” Agent type kontrolÃ¼: chat_id={request.chat_id}, agent_type={agent_type}")
            previous_messages = db.get_chat_messages(chat_id=request.chat_id, tenant_id=user.tenant_id)
            print(f"ðŸ” Ã–nceki mesaj sayÄ±sÄ±: {len(previous_messages)}")
            # Son AI mesajÄ±nÄ± kontrol et
            for msg in reversed(previous_messages):
                if msg.sender == "ai" and msg.metadata:
                    metadata = msg.metadata
                    print(f"ðŸ” AI mesaj metadata: {metadata}")
                    previous_agent_type = metadata.get("agent_type")
                    
                    # Presentation agent eksik bilgi toplama aÅŸamasÄ±nda, devam ettir
                    if previous_agent_type == "presentation" and metadata.get("presentation_state") == "collecting_info":
                        agent_type = "presentation"
                        print(f"âœ… Presentation Agent: Ã–nceki sohbette eksik bilgi toplama aÅŸamasÄ±nda, devam ediliyor")
                        break
                    # Excel agent kullanÄ±lmÄ±ÅŸsa, devam ettir
                    elif previous_agent_type == "excel":
                        agent_type = "excel"
                        print(f"âœ… Excel Agent: Ã–nceki sohbette Excel agent kullanÄ±lmÄ±ÅŸ, devam ediliyor")
                        break
        except Exception as e:
            print(f"âš ï¸ Ã–nceki mesaj kontrolÃ¼ hatasÄ±: {e}")
            tb_module.print_exc()
    
    print(f"\nðŸ¤– KULLANILAN MODEL: {model_name}, AGENT TÄ°PÄ°: {agent_type}\n")
    
    # Excel agent iÃ§in Ã¶zel iÅŸleme
    if agent_type == "excel":
        try:
            from app.services.excel_agent_service import analyze_excel_data, compare_excel_files
            
            # Context dosyalarÄ±nÄ± kontrol et
            if request.context_files and len(request.context_files) > 0:
                excel_files = [f for f in request.context_files if f.type == "file"]
                
                if len(excel_files) == 1:
                    # Tek Excel dosyasÄ± analizi
                    file_record = db.get_file_by_id(user.tenant_id, excel_files[0].id)
                    if file_record:
                        # CSV desteÄŸi iÃ§in uzantÄ± kontrolÃ¼nÃ¼ geniÅŸlettik
                        file_name_lower = file_record.name.lower()
                        if file_name_lower.endswith(('.xlsx', '.xls', '.csv')):
                            print(f"ðŸ“Š Excel Agent: Tek dosya analizi baÅŸlatÄ±lÄ±yor - '{file_record.name}'")
                            file_bytes = _get_file_bytes(file_record, user, storage)
                            
                            # GÃœNCELLEME BURADA: file_name parametresi eklendi
                            response_text = analyze_excel_data(
                                file_bytes=file_bytes,
                                question=request.message,
                                model_name=model_name,
                                file_name=file_record.name  # <--- Dosya adÄ± eklendi
                            )
                            
                            chat_id = request.chat_id or db.create_chat_session(
                                user.id, user.tenant_id, request.message[:40] + "..."
                            ).id
                            db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="user", text=request.message))
                            
                            # Excel agent iÃ§in metadata oluÅŸtur
                            response_metadata = {
                                "agent_type": "excel"
                            }
                            db.save_chat_message(
                                chat_id, 
                                user.tenant_id, 
                                ChatMessage(sender="ai", text=response_text, metadata=response_metadata)
                            )
                            
                            return ChatResponse(
                                chat_id=chat_id,
                                response_message=response_text,
                                active_context_files=request.context_files or [],
                                response_metadata=response_metadata
                            )
                        else:
                            print(f"âš ï¸ Excel Agent: SeÃ§ilen dosya desteklenen formatta deÄŸil (xlsx, xls, csv): '{file_record.name}'")
                    else:
                        print(f"âš ï¸ Excel Agent: Dosya bulunamadÄ±")
                
                elif len(excel_files) == 2:
                    # Ä°ki Excel dosyasÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
                    file1 = db.get_file_by_id(user.tenant_id, excel_files[0].id)
                    file2 = db.get_file_by_id(user.tenant_id, excel_files[1].id)
                    
                    if file1 and file2:
                        file1_name_lower = file1.name.lower()
                        file2_name_lower = file2.name.lower()
                        
                        valid_extensions = ('.xlsx', '.xls', '.csv')
                        if file1_name_lower.endswith(valid_extensions) and file2_name_lower.endswith(valid_extensions):
                            print(f"ðŸ“Š Excel Agent: Ä°ki dosya karÅŸÄ±laÅŸtÄ±rmasÄ± baÅŸlatÄ±lÄ±yor - '{file1.name}' ve '{file2.name}'")
                            file1_bytes = _get_file_bytes(file1, user, storage)
                            file2_bytes = _get_file_bytes(file2, user, storage)
                            
                            # GÃœNCELLEME BURADA: file1_name ve file2_name eklendi
                            response_text = compare_excel_files(
                                file1_bytes=file1_bytes,
                                file2_bytes=file2_bytes,
                                question=request.message,
                                model_name=model_name,
                                file1_name=file1.name,  # <--- Dosya adÄ± 1
                                file2_name=file2.name   # <--- Dosya adÄ± 2
                            )
                            
                            chat_id = request.chat_id or db.create_chat_session(
                                user.id, user.tenant_id, request.message[:40] + "..."
                            ).id
                            db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="user", text=request.message))
                            
                            # Excel agent iÃ§in metadata oluÅŸtur
                            response_metadata = {
                                "agent_type": "excel"
                            }
                            db.save_chat_message(
                                chat_id, 
                                user.tenant_id, 
                                ChatMessage(sender="ai", text=response_text, metadata=response_metadata)
                            )
                            
                            return ChatResponse(
                                chat_id=chat_id,
                                response_message=response_text,
                                active_context_files=request.context_files or [],
                                response_metadata=response_metadata
                            )
                        else:
                            print(f"âš ï¸ Excel Agent: SeÃ§ilen dosyalardan biri desteklenen formatta deÄŸil")
                    else:
                        print(f"âš ï¸ Excel Agent: Dosyalardan biri veya ikisi bulunamadÄ±")
                else:
                    print(f"âš ï¸ Excel Agent: {len(excel_files)} dosya seÃ§ilmiÅŸ. Tek veya iki dosya bekleniyor.")
            else:
                print(f"âš ï¸ Excel Agent: Context dosyasÄ± seÃ§ilmemiÅŸ.")
        except Exception as e:
            print(f"âŒ Excel Agent hatasÄ±: {e}")
            tb_module.print_exc()
    
    # Presentation agent iÃ§in Ã¶zel iÅŸleme
    if agent_type == "presentation":
        try:
            from app.services.presentation_agent_service import (
                analyze_presentation_requirements,
                generate_presentation_content,
                create_presentation_file,
                extract_context_info
            )
            
            print(f"ðŸ“½ï¸ Presentation Agent: Sunum hazÄ±rlama isteÄŸi alÄ±ndÄ±")
            
            # Ã–nceki mesajlarÄ± kontrol et - eksik bilgi toplama aÅŸamasÄ±nda mÄ±yÄ±z?
            previous_topic = request.message
            missing_fields_info = None
            if request.chat_id:
                previous_messages = db.get_chat_messages(chat_id=request.chat_id, tenant_id=user.tenant_id)
                # Son AI mesajÄ±nÄ± kontrol et
                for msg in reversed(previous_messages):
                    if msg.sender == "ai" and msg.metadata:
                        metadata = msg.metadata
                        if metadata.get("agent_type") == "presentation" and metadata.get("presentation_state") == "collecting_info":
                            # Eksik bilgi toplama aÅŸamasÄ±ndayÄ±z
                            missing_fields_info = metadata.get("missing_fields", [])
                            
                            # Ä°lk kullanÄ±cÄ± mesajÄ±nÄ± bul (orijinal konu)
                            for prev_msg in previous_messages:
                                if prev_msg.sender == "user":
                                    previous_topic = prev_msg.text
                                    break
                            
                            # TÃ¼m kullanÄ±cÄ± cevaplarÄ±nÄ± topla (AI mesajÄ±ndan sonraki tÃ¼m user mesajlarÄ±)
                            user_responses = []
                            found_ai_question = False
                            for prev_msg in reversed(previous_messages):
                                if prev_msg.sender == "ai" and prev_msg.metadata and prev_msg.metadata.get("agent_type") == "presentation":
                                    found_ai_question = True
                                elif found_ai_question and prev_msg.sender == "user":
                                    user_responses.insert(0, prev_msg.text)
                            
                            # Yeni mesajÄ± da ekle
                            user_responses.append(request.message)
                            
                            # Daha net bir format oluÅŸtur
                            answers_text = "\n".join([f"- {resp}" for resp in user_responses])
                            combined_topic = f"""ORÄ°JÄ°NAL KONU:
{previous_topic}

KULLANICININ VERDÄ°ÄžÄ° CEVAPLAR:
{answers_text}

NOT: KullanÄ±cÄ± yukarÄ±daki sorularÄ± cevapladÄ±. ArtÄ±k yeterli bilgiye sahipsin, sunum yapÄ±sÄ±nÄ± oluÅŸturabilirsin."""
                            previous_topic = combined_topic
                            print(f"ðŸ“½ï¸ Presentation Agent: Eksik bilgiler toplandÄ± ({len(user_responses)} cevap), tekrar analiz yapÄ±lÄ±yor")
                            break
            
            # Context bilgilerini Ã§Ä±kar
            context_info = ""
            if request.context_files and len(request.context_files) > 0:
                context_info = extract_context_info(
                    [{"id": f.id, "type": f.type, "name": f.name} for f in request.context_files],
                    db, storage, user
                )
            
            # Sunum gereksinimlerini analiz et
            user_answered = missing_fields_info is not None
            analysis_result = analyze_presentation_requirements(
                topic=previous_topic,
                context_info=context_info,
                model_name=model_name,
                user_answered_questions=user_answered
            )
            
            chat_id = request.chat_id or db.create_chat_session(
                user.id, user.tenant_id, request.message[:40] + "..."
            ).id
            db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="user", text=request.message))
            
            if analysis_result.get("status") == "missing_info":
                # Eksik bilgiler var, kullanÄ±cÄ±ya sor
                missing_fields = analysis_result.get("missing_fields", [])
                questions_text = "Sunum hazÄ±rlamak iÃ§in aÅŸaÄŸÄ±daki bilgilere ihtiyacÄ±m var:\n\n"
                for idx, field in enumerate(missing_fields, 1):
                    questions_text += f"{idx}. {field.get('question', '')}\n"
                
                questions_text += "\nLÃ¼tfen bu sorularÄ± yanÄ±tlayÄ±n, ben de sunumunuzu hazÄ±rlayayÄ±m."
                
                # Metadata'ya eksik alanlarÄ± ekle
                response_metadata = {
                    "agent_type": "presentation",
                    "missing_fields": missing_fields,
                    "presentation_state": "collecting_info"
                }
                
                # ChatMessage'a metadata ekle
                db.save_chat_message(chat_id, user.tenant_id, ChatMessage(
                    sender="ai", 
                    text=questions_text,
                    metadata=response_metadata
                ))
                
                return ChatResponse(
                    chat_id=chat_id,
                    response_message=questions_text,
                    active_context_files=request.context_files or [],
                    response_metadata=response_metadata
                )
            
            elif analysis_result.get("status") == "ready":
                # Yeterli bilgi var, sunum iÃ§eriÄŸini oluÅŸtur
                structure = analysis_result.get("presentation_structure", {})
                content_result = generate_presentation_content(structure, model_name)
                
                # EÄŸer content_result boÅŸsa, structure'dan direkt kullan
                slides_to_use = content_result.get("slides", [])
                if not slides_to_use:
                    print(f"âš ï¸ Ä°Ã§erik oluÅŸturulamadÄ±, structure'dan slaytlar kullanÄ±lÄ±yor")
                    # Structure'daki slaytlarÄ± formatla
                    structure_slides = structure.get("slides", [])
                    slides_to_use = []
                    for slide in structure_slides:
                        slide_content = slide.get("content", [])
                        bullet_points = []
                        for content_item in slide_content:
                            if isinstance(content_item, str):
                                bullet_points.append({
                                    "point": content_item,
                                    "description": ""
                                })
                        slides_to_use.append({
                            "slide_number": slide.get("slide_number", len(slides_to_use) + 1),
                            "slide_type": slide.get("slide_type", "content"),
                            "title": slide.get("title", ""),
                            "bullet_points": bullet_points
                        })
                
                # Sunum dosyasÄ±nÄ± oluÅŸtur
                presentation_title = structure.get("title", "Sunum")
                presentation_bytes = create_presentation_file(
                    {
                        "title": presentation_title,
                        "subtitle": structure.get("subtitle", ""),
                        "slides": slides_to_use
                    },
                    title=presentation_title
                )
                
                # Sunumu storage'a kaydet
                from datetime import datetime
                from app.schemas.file import FileCreate
                import uuid
                
                safe_title = "".join(c for c in presentation_title if c.isalnum() or c in (' ', '-', '_')).strip()[:50]
                filename = f"{safe_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pptx"
                
                # DosyayÄ± storage'a yÃ¼kle
                unique_filename = f"{uuid.uuid4()}_{filename}"
                storage_path = storage.upload_file(
                    file_obj=io.BytesIO(presentation_bytes),
                    tenant_id=user.tenant_id,
                    file_name=unique_filename
                )
                
                # Dosya kaydÄ±nÄ± oluÅŸtur
                file_data = FileCreate(
                    name=filename,
                    folder_id=None,  # Root klasÃ¶re kaydet
                    content_type="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                    size=len(presentation_bytes),
                    owner_id=user.id,
                    tenant_id=user.tenant_id,
                    storage_path=storage_path,
                    created_at=datetime.now()
                )
                
                file_record = db.create_file_record(file_data)
                
                # Slayt sayÄ±sÄ±nÄ± kontrol et
                slides_count = len(slides_to_use)
                
                success_message = f"âœ… Sunumunuz hazÄ±r!\n\n"
                success_message += f"**BaÅŸlÄ±k:** {presentation_title}\n"
                success_message += f"**Slayt SayÄ±sÄ±:** {slides_count}\n\n"
                success_message += f"Sunum dosyasÄ± '{file_record.name}' olarak kaydedildi. Dosyalar bÃ¶lÃ¼mÃ¼nden indirebilirsiniz."
                
                print(f"ðŸ“½ï¸ Sunum kaydedildi: {file_record.name}, {slides_count} slayt, {len(presentation_bytes)} bytes")
                
                response_metadata = {
                    "agent_type": "presentation",
                    "presentation_state": "completed",
                    "file_id": file_record.id,
                    "file_name": file_record.name
                }
                
                # ChatMessage'a metadata ekle
                db.save_chat_message(chat_id, user.tenant_id, ChatMessage(
                    sender="ai", 
                    text=success_message,
                    metadata=response_metadata
                ))
                
                return ChatResponse(
                    chat_id=chat_id,
                    response_message=success_message,
                    active_context_files=request.context_files or [],
                    response_metadata=response_metadata
                )
            else:
                # Hata durumu
                error_message = analysis_result.get("message", "Sunum hazÄ±rlanÄ±rken bir hata oluÅŸtu.")
                db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="ai", text=error_message))
                
                return ChatResponse(
                    chat_id=chat_id,
                    response_message=error_message,
                    active_context_files=request.context_files or []
                )
                
        except Exception as e:
            print(f"âŒ Presentation Agent hatasÄ±: {e}")
            tb_module.print_exc()
            # Hata durumunda normal iÅŸleme devam et
    
    # SelamlaÅŸma/hal hatÄ±r kontrolÃ¼ (en Ã¶nce - nazik cevap verilmeli)
    if is_greeting_query(request.message):
        print(f"ðŸ‘‹ SelamlaÅŸma sorgusu tespit edildi: '{request.message}' - Nazik cevap verilecek")
        chat_id = request.chat_id or db.create_chat_session(user.id, user.tenant_id, request.message[:40] + "...").id
        db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="user", text=request.message))
        
        # Nazik selamlaÅŸma cevabÄ±
        greeting_response = get_greeting_response(request.message)
        db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="ai", text=greeting_response))
        
        return ChatResponse(
            chat_id=chat_id,
            response_message=greeting_response,
            token_usage_stats=None
        )
    
    # Off-topic sorgu kontrolÃ¼ (dosya taramasÄ± yapmadan Ã¶nce)
    # NOT: EÄŸer context_files varsa (kullanÄ±cÄ± dosya/klasÃ¶r seÃ§miÅŸse), off-topic kontrolÃ¼nÃ¼ atla
    # Ã§Ã¼nkÃ¼ bu durumda soru kesinlikle platform ile ilgilidir
    # NOT: Ã–zel agent'lar (excel, presentation) iÃ§in de off-topic kontrolÃ¼nÃ¼ atla (bunlar agent'larÄ±n gÃ¶revidir)
    has_context = request.context_files and len(request.context_files) > 0
    is_special_agent = agent_type in ["excel", "presentation"]
    if not has_context and not is_special_agent and is_off_topic_query(request.message):
        print(f"âš ï¸ Off-topic sorgu tespit edildi: '{request.message}' - Dosya taramasÄ± yapÄ±lmayacak")
        chat_id = request.chat_id or db.create_chat_session(user.id, user.tenant_id, request.message[:40] + "...").id
        db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="user", text=request.message))
        
        # Off-topic mesajÄ± kaydet
        off_topic_response = "ÃœzgÃ¼nÃ¼m, bu tÃ¼r genel sohbet sorularÄ±nÄ± yanÄ±tlayamam. LÃ¼tfen Knowvex ile ilgili sorular sorun. Ã–rneÄŸin: 'Dosyalarda X konusunu ara', 'Y projesi hakkÄ±nda bilgi ver', 'Z raporunu Ã¶zetle', 'BugÃ¼n kaÃ§ mail geldi?' gibi."
        db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="ai", text=off_topic_response))
        
        return ChatResponse(
            chat_id=chat_id,
            response_message=off_topic_response,
            token_usage_stats=None
        )
    
    # YardÄ±m/destek sorgu kontrolÃ¼ (dosya taramasÄ± yapmadan Ã¶nce)
    if is_help_or_support_query(request.message):
        print(f"â„¹ï¸ YardÄ±m/destek sorgusu tespit edildi: '{request.message}' - Dosya taramasÄ± yapÄ±lmayacak, direkt cevap verilecek")
        chat_id = request.chat_id or db.create_chat_session(user.id, user.tenant_id, request.message[:40] + "...").id
        db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="user", text=request.message))
        
        # YardÄ±m cevabÄ± oluÅŸtur
        help_response = get_help_response(request.message)
        db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="ai", text=help_response))
        
        return ChatResponse(
            chat_id=chat_id,
            response_message=help_response,
            token_usage_stats=None
        )
    
    # Token tracking baÅŸlat
    token_tracker = TokenTracker()
    print("\nðŸ”¢ TOKEN TRACKING BAÅžLATILDI - TÃ¼m LLM Ã§aÄŸrÄ±larÄ± izlenecek\n")
    
    chat_id = request.chat_id or db.create_chat_session(user.id, user.tenant_id, request.message[:40] + "...").id
    context_memory = get_context_memory_for_chat(chat_id)
    
    db.save_chat_message(chat_id, user.tenant_id, ChatMessage(sender="user", text=request.message))
    
    response_data: Dict[str, Any] = {}
    
    # filtered_context_files'i baÅŸlangÄ±Ã§ta boÅŸ liste olarak baÅŸlat
    filtered_context_files = []
    
    # DEBUG: Gelen context_files bilgisini logla
    print(f"ðŸ” DEBUG: Gelen context_files = {request.context_files} (type: {type(request.context_files)}, is None: {request.context_files is None}, len: {len(request.context_files) if request.context_files is not None else 'N/A'})")
    print(f"ðŸ” DEBUG: Mevcut baÄŸlam hafÄ±zasÄ±: {len(context_memory.get_file_ids())} dosya, {len(context_memory.get_folder_ids())} klasÃ¶r")
    
    # Context dosyalarÄ± iÃ§in eriÅŸim kontrolÃ¼
    # NOT: request.context_files None olabilir (baÄŸlam belirtilmemiÅŸ) veya boÅŸ liste olabilir (baÄŸlam kaldÄ±rÄ±lmÄ±ÅŸ)
    # BoÅŸ liste aÃ§Ä±kÃ§a gÃ¶nderildiyse, baÄŸlamÄ± temizle
    if request.context_files is not None:
        if len(request.context_files) == 0:
            # KullanÄ±cÄ± tÃ¼m baÄŸlamÄ± kaldÄ±rmÄ±ÅŸ - baÄŸlam hafÄ±zasÄ±nÄ± temizle
            context_memory.clear()
            print("ðŸ—‘ï¸ KullanÄ±cÄ± tÃ¼m baÄŸlamÄ± kaldÄ±rdÄ±. BaÄŸlam hafÄ±zasÄ± temizlendi.")
        else:
            # KullanÄ±cÄ±nÄ±n eriÅŸebileceÄŸi dosya ve klasÃ¶rleri al
            accessible_files = get_all_accessible_files_for_user(db, user)
            accessible_file_ids = {file.id for file in accessible_files}
            accessible_folder_ids = set()
            
            # Admin ise tÃ¼m klasÃ¶rlere eriÅŸebilir
            if user.role == "Admin":
                all_folders = db.get_all_folders_for_tenant(user.tenant_id)
                accessible_folder_ids = {folder.id for folder in all_folders}
            else:
                # Rol bazlÄ± klasÃ¶r eriÅŸimleri
                user_role = db.get_role_by_name(tenant_id=user.tenant_id, role_name=user.role)
                if user_role:
                    accessible_folder_ids = set(user_role.allowed_folders or [])
            
            # EriÅŸilebilir context dosyalarÄ±nÄ± filtrele
            filtered_context_files = []
            for context_item in request.context_files:
                if context_item.type == "file":
                    # Dosya eriÅŸim kontrolÃ¼
                    file_record = db.get_file_by_id(user.tenant_id, context_item.id)
                    if file_record:
                        is_owner = file_record.owner_id == user.id  # KullanÄ±cÄ±nÄ±n kendi yÃ¼klediÄŸi dosya
                        is_accessible = context_item.id in accessible_file_ids  # RolÃ¼nde tanÄ±mlÄ± dosya
                        # KullanÄ±cÄ± kendi dosyasÄ±na veya rolÃ¼nde tanÄ±mlÄ± dosyaya eriÅŸebilir, Admin her ÅŸeye eriÅŸebilir
                        if is_owner or is_accessible or user.role == "Admin":
                            filtered_context_files.append(context_item)
                            if is_owner:
                                print(f"âœ… KullanÄ±cÄ±nÄ±n kendi dosyasÄ± baÄŸlama eklendi: '{context_item.name}'")
                        else:
                            print(f"âš ï¸ EriÅŸim reddedildi: KullanÄ±cÄ± '{user.email}' '{context_item.name}' dosyasÄ±na eriÅŸemiyor.")
                    else:
                        print(f"âš ï¸ Dosya bulunamadÄ±: '{context_item.name}' (ID: {context_item.id})")
                elif context_item.type == "folder":
                    # KlasÃ¶r eriÅŸim kontrolÃ¼
                    folder_record = None
                    all_folders = db.get_all_folders_for_tenant(user.tenant_id)
                    for folder in all_folders:
                        if folder.id == context_item.id:
                            folder_record = folder
                            break
                    
                    if folder_record:
                        is_accessible = context_item.id in accessible_folder_ids or user.role == "Admin"
                        if is_accessible:
                            filtered_context_files.append(context_item)
                        else:
                            print(f"âš ï¸ EriÅŸim reddedildi: KullanÄ±cÄ± '{user.email}' '{context_item.name}' klasÃ¶rÃ¼ne eriÅŸemiyor.")
                    else:
                        print(f"âš ï¸ KlasÃ¶r bulunamadÄ±: '{context_item.name}' (ID: {context_item.id})")
                elif context_item.type == "database":
                    # YENÄ°: VeritabanÄ± eriÅŸim kontrolÃ¼
                    try:
                        from app.api.v1.databases import get_database_connection
                        db_connection = get_database_connection(context_item.id, user)
                        if db_connection:
                            filtered_context_files.append(context_item)
                            print(f"âœ… VeritabanÄ± baÄŸlantÄ±sÄ± baÄŸlama eklendi: '{context_item.name}' ({context_item.db_type})")
                        else:
                            print(f"âš ï¸ VeritabanÄ± baÄŸlantÄ±sÄ± bulunamadÄ±: '{context_item.name}' (ID: {context_item.id})")
                    except Exception as e:
                        print(f"âš ï¸ VeritabanÄ± baÄŸlantÄ±sÄ± kontrol edilirken hata: {e}")
            
            if filtered_context_files:
                context_memory.set_context(filtered_context_files)
                print(f"âœ… {len(filtered_context_files)} adet baÄŸlam dosyasÄ±/klasÃ¶rÃ¼ eriÅŸim kontrolÃ¼nden geÃ§ti ve eklendi.")
            else:
                # EriÅŸilebilir dosya yoksa, baÄŸlamÄ± temizle (kullanÄ±cÄ± baÄŸlam kaldÄ±rmÄ±ÅŸ olabilir)
                context_memory.clear()
                print(f"âš ï¸ HiÃ§bir baÄŸlam dosyasÄ±/klasÃ¶rÃ¼ eriÅŸilebilir deÄŸil. BaÄŸlam hafÄ±zasÄ± temizlendi.")
    
    is_general_search = not context_memory.has_context()

    if is_general_search:
        print("BaÄŸlam belirtilmedi, dosya adÄ±yla hÄ±zlÄ± arama yapÄ±lÄ±yor...")
        all_files = get_all_accessible_files_for_user(db, user)
        best_match_file = None
        highest_score = 0.9  
        for file in all_files:
            score = calculate_filename_match_score(request.message, file.name)
            if score > highest_score:
                highest_score = score
                best_match_file = file
        if best_match_file:
            print(f"ðŸ’¡ HÄ±zlÄ± arama baÅŸarÄ±lÄ±! '{best_match_file.name}' dosyasÄ± baÄŸlam olarak ayarlandÄ±.")
            file_context = ActiveContextFile(id=best_match_file.id, name=best_match_file.name, type="file")
            context_memory.set_context([file_context])
            db.save_chat_message(
                chat_id, 
                user.tenant_id, 
                ChatMessage(sender="system", text=f"Sorunuzla ilgili olabilecek '{best_match_file.name}' dosyasÄ± otomatik olarak baÄŸlama eklendi.")
            )
        else:
            print("Dosya adÄ±yla gÃ¼Ã§lÃ¼ bir eÅŸleÅŸme bulunamadÄ±, genel vektÃ¶r aramasÄ±na geÃ§iliyor.")
    
    is_general_search = not context_memory.has_context()
        
    search_file_ids, search_folder_ids = context_memory.get_file_ids(), context_memory.get_folder_ids()
    if search_folder_ids:
        for folder_id in search_folder_ids:
            try:
                file_ids_in_folder = db.get_all_file_ids_in_folder_recursive(tenant_id=user.tenant_id, folder_id=folder_id, user=user)
                search_file_ids.update(file_ids_in_folder)
            except Exception as e:
                print(f"KlasÃ¶r iÃ§eriÄŸi alÄ±nÄ±rken hata: {e}")

    if is_general_search and user.role != "Admin":
        print(f"BaÄŸlamsÄ±z arama. KullanÄ±cÄ± '{user.email}' (Rol: {user.role}) iÃ§in yetki filtresi uygulanÄ±yor.")
        try:
            if 'all_files' not in locals():
                 all_files = get_all_accessible_files_for_user(db, user)
            allowed_file_ids = {file.id for file in all_files}
            search_file_ids = allowed_file_ids
            if not search_file_ids:
                print(f"KullanÄ±cÄ± '{user.email}' hiÃ§bir dosyaya eriÅŸemiyor. Arama engellendi.")
                response_data = {
                    "response_message": "Yetkiniz olan herhangi bir dosya bulunamadÄ±ÄŸÄ± iÃ§in genel arama yapamÄ±yorum. LÃ¼tfen belirli bir dosya veya klasÃ¶rÃ¼ @-etiketleyerek tekrar deneyin.",
                    "source_context": "Yetki Engeli",
                    "token_usage": {}
                }
        except Exception as e:
            print(f"KullanÄ±cÄ± yetkileri alÄ±nÄ±rken hata oluÅŸtu: {e}")
            raise HTTPException(status_code=500, detail=f"Arama yetkileri hesaplanÄ±rken hata oluÅŸtu: {str(e)}")

    # YENÄ°: VeritabanÄ± baÄŸlamÄ± kontrolÃ¼
    database_context = None
    # Ã–nce filtered_context_files'de veritabanÄ± var mÄ± kontrol et
    if filtered_context_files:
        for context_item in filtered_context_files:
            if context_item.type == "database":
                try:
                    from app.api.v1.databases import get_database_connection
                    from app.database_connectors import get_database_connector
                    from app.services.database_query_service import query_database
                    
                    db_connection = get_database_connection(context_item.id, user)
                    if db_connection:
                        connector = get_database_connector(db_connection.type)
                        if connector.connect(db_connection.connection_string):
                            database_context = {
                                "connection": db_connection,
                                "connector": connector
                            }
                            print(f"ðŸ”— VeritabanÄ± baÄŸlantÄ±sÄ± kuruldu: {db_connection.name} ({db_connection.type})")
                            break
                except Exception as e:
                    print(f"âš ï¸ VeritabanÄ± baÄŸlantÄ±sÄ± kurulurken hata: {e}")
    
    # EÄŸer filtered_context_files'de veritabanÄ± yoksa, context_memory'den kontrol et
    if not database_context:
        for context_item in context_memory.get_context():
            if context_item.type == "database":
                try:
                    from app.api.v1.databases import get_database_connection
                    from app.database_connectors import get_database_connector
                    from app.services.database_query_service import query_database
                    
                    db_connection = get_database_connection(context_item.id, user)
                    if db_connection:
                        connector = get_database_connector(db_connection.type)
                        if connector.connect(db_connection.connection_string):
                            database_context = {
                                "connection": db_connection,
                                "connector": connector
                            }
                            print(f"ðŸ”— VeritabanÄ± baÄŸlantÄ±sÄ± kuruldu: {db_connection.name} ({db_connection.type})")
                            break
                except Exception as e:
                    print(f"âš ï¸ VeritabanÄ± baÄŸlantÄ±sÄ± kurulurken hata: {e}")
    
    # EÄŸer veritabanÄ± baÄŸlamÄ± varsa, veritabanÄ± sorgulama yap
    if database_context:
        print("\n" + "="*50 + "\nVERÄ°TABANI SORGULAMA MODU\n" + "="*50)
        try:
            db_result = query_database(
                question=request.message,
                db_connector=database_context["connector"],
                model_name=model_name
            )
            
            # VeritabanÄ± sonucunu response'a ekle
            source_context = f"VeritabanÄ±: {database_context['connection'].name}"
            if db_result.get("sql_query"):
                source_context += f" | SQL: {db_result['sql_query']}"
            
            response_data = {
                "response_message": db_result["answer"],
                "source_context": source_context,
                "token_usage": {
                    "input_tokens": 0,  # VeritabanÄ± sorgusu iÃ§in token tracking yapÄ±lmadÄ± (basit tutuldu)
                    "output_tokens": 0,
                    "total_tokens": 0,
                    "breakdown": [],
                    "estimated_cost_usd": 0.0,
                    "estimated_cost_tl": 0.0
                }
            }
            
            # BaÄŸlantÄ±yÄ± kapat
            database_context["connector"].close()
        except Exception as e:
            print(f"âŒ VeritabanÄ± sorgusu hatasÄ±: {e}")
            response_data = {
                "response_message": f"VeritabanÄ± sorgusu sÄ±rasÄ±nda bir hata oluÅŸtu: {str(e)}",
                "source_context": f"VeritabanÄ±: {database_context['connection'].name}",
                "token_usage": {}
            }
            if database_context and database_context.get("connector"):
                database_context["connector"].close()
    
    is_single_file_context = len(context_memory.get_file_ids()) == 1 and not context_memory.get_folder_ids()

    def retrieve_docs(query: str) -> List[Document]:
        print(f"ðŸ”€ Hibrit arama yapÄ±lÄ±yor (LocalGPT tarzÄ± - Vector + BM25 + RRF): {query[:100]}...")
        
        if is_general_search:
             # EÄŸer liste sorusuysa daha da derin kaz
            search_limit = 500 if is_list_intent(request.message) else 300
        else:
            search_limit = 150
        
        # YENÄ°: Hibrit arama kullan (LocalGPT'in yaklaÅŸÄ±mÄ±)
        chunks_dict = vector_service.hybrid_search_similar_chunks(
            tenant_id=user.tenant_id,
            query=query,
            db=db,
            limit=search_limit,
            filter_file_ids=list(search_file_ids) if search_file_ids else None,
            retrieval_mode="hybrid"  # "hybrid", "vector", "bm25"
        )
        
        # Mail dosyalarÄ±nÄ± filtrele (mail arama ayrÄ± bir endpoint'te yapÄ±lÄ±yor)
        filtered_chunks = [
            chunk for chunk in chunks_dict 
            if not chunk.get("source_file_id", "").startswith("mail_")
        ]
        
        print(f"ðŸ“Š Hibrit arama: {len(chunks_dict)} chunk bulundu, {len(filtered_chunks)} chunk mail olmayan dosyalardan (mail dosyalarÄ± filtrelendi)")
        
        return [Document(page_content=chunk.get("text"), metadata={
            "source_file_name": chunk.get("source_file_name"),
            "source_file_id": chunk.get("source_file_id"),
            "similarity_score": chunk.get("rrf_score", chunk.get("hybrid_score", chunk.get("similarity_score", 0.0))),
            "vector_score": chunk.get("vector_score", 0.0),
            "bm25_score": chunk.get("bm25_score", 0.0),
            "rrf_score": chunk.get("rrf_score", 0.0)
        }) for chunk in filtered_chunks]

    try:
        if not response_data:
            print("\n" + "="*50 + "\nADIM 1: BÄ°LGÄ° GETÄ°RME (RETRIEVAL)\n" + "="*50)

            if is_single_file_context:
                print("ðŸ“„ Tek dosya baÄŸlamÄ± algÄ±landÄ±. Performans iÃ§in HyDE adÄ±mÄ± atlanÄ±yor.")
                retriever_chain = RunnableLambda(retrieve_docs)
            else:
                # HyDE iÃ§in wrapper - model_name ve token_tracker'Ä± closure ile geÃ§ir
                def hyde_wrapper(question: str):
                    return create_hypothetical_document_for_query_wrapper(question, model_name, token_tracker)
                retriever_chain = (RunnableLambda(hyde_wrapper) | RunnableLambda(retrieve_docs))
            
            retrieved_chunks = retriever_chain.invoke(request.message)
            
            is_list_query = is_list_intent(request.message)
            if is_list_query:
                print("ðŸ” Liste talebi algÄ±landÄ±. Eksiksiz liste iÃ§in reranking ile en alakalÄ± chunk'lar seÃ§ilecek...")
                # Liste sorularÄ±nda da reranking yap ama daha fazla chunk seÃ§mesini iste
                is_champion_found = False
                # RRF score'a gÃ¶re sÄ±rala ve en iyi 300 chunk'Ä± reranking'e gÃ¶nder
                sorted_chunks = sorted(retrieved_chunks, key=lambda x: x.metadata.get('rrf_score', x.metadata.get('similarity_score', 0.0)), reverse=True)
                top_chunks_for_rerank = sorted_chunks[:300]  # Reranking iÃ§in en iyi 300 chunk
                
                # Cross-Encoder reranking dene (LocalGPT tarzÄ± - daha hÄ±zlÄ±)
                cross_encoder_result = rerank_chunks_with_cross_encoder(
                    top_chunks_for_rerank,
                    request.message,
                    top_k=200  # Liste sorularÄ± iÃ§in daha fazla
                )
                
                if cross_encoder_result is not None:
                    # Cross-Encoder baÅŸarÄ±lÄ±
                    final_chunks = cross_encoder_result
                    print(f"âœ… Cross-Encoder reranking kullanÄ±ldÄ±: {len(final_chunks)} chunk seÃ§ildi")
                else:
                    # Fallback: LLM reranking
                    final_chunks = rerank_chunks_with_llm_wrapper(top_chunks_for_rerank, request.message, model_name, token_tracker, is_list_query=True)
                    print(f"âœ… LLM reranking kullanÄ±ldÄ±: {len(final_chunks)} chunk seÃ§ildi")
                
                print(f"ðŸ“‹ Liste sorusu iÃ§in {len(final_chunks)} chunk kullanÄ±lacak (reranking sonrasÄ±).")
            else:
                potential_final_chunks, is_champion_found = identify_and_filter_high_confidence_document(retrieved_chunks, request.message)
                
                if is_single_file_context and is_champion_found:
                    print("ðŸ“„ Tek dosya baÄŸlamÄ± algÄ±landÄ±. En iyi sonucu saÄŸlamak iÃ§in yeniden sÄ±ralayÄ±cÄ± (reranker) zorunlu kÄ±lÄ±ndÄ±.")
                    is_champion_found = False

                if is_champion_found:
                    final_chunks = potential_final_chunks
                else:
                    # Cross-Encoder reranking dene (LocalGPT tarzÄ± - daha hÄ±zlÄ±)
                    if len(potential_final_chunks) > 50:
                        # Ã‡ok fazla chunk varsa Cross-Encoder kullan (daha hÄ±zlÄ±)
                        cross_encoder_result = rerank_chunks_with_cross_encoder(
                            potential_final_chunks,
                            request.message,
                            top_k=50
                        )
                        
                        if cross_encoder_result is not None:
                            # Cross-Encoder baÅŸarÄ±lÄ±
                            final_chunks = cross_encoder_result
                            print(f"âœ… Cross-Encoder reranking kullanÄ±ldÄ±: {len(final_chunks)} chunk seÃ§ildi")
                        else:
                            # Fallback: LLM reranking
                            final_chunks = rerank_chunks_with_llm_wrapper(potential_final_chunks, request.message, model_name, token_tracker)
                            print(f"âœ… LLM reranking kullanÄ±ldÄ±: {len(final_chunks)} chunk seÃ§ildi")
                    else:
                        # Az chunk varsa LLM reranking (daha esnek)
                        final_chunks = rerank_chunks_with_llm_wrapper(potential_final_chunks, request.message, model_name, token_tracker)
                        print(f"âœ… LLM reranking kullanÄ±ldÄ±: {len(final_chunks)} chunk seÃ§ildi")
            
            # DEBUG: Final chunk'larÄ±n iÃ§eriÄŸini kontrol et
            if final_chunks:
                print(f"DEBUG: Final chunks iÃ§eriÄŸi Ã¶rnekleri:")
                for i, chunk in enumerate(final_chunks[:3]):  # Ä°lk 3 chunk'Ä± gÃ¶ster
                    print(f"  Chunk {i+1}: {chunk.page_content[:200]}...")
            
            print("\n" + "="*50 + "\nADIM 3: YANIT ÃœRETÄ°MÄ° (GENERATION)\n" + "="*50)

            if is_champion_found and final_chunks:
                 print(f"âœ¨ ODAKLANMA MODU AKTÄ°F: YanÄ±t, sadece ÅŸampiyon belgeden gelen {len(final_chunks)} chunk ile oluÅŸturulacak.")
            
            if not final_chunks:
                 print("UYARI: YanÄ±t Ã¼retimi iÃ§in HÄ°Ã‡ chunk bulunamadÄ±. Muhtemelen alakasÄ±zdÄ±.")

            # RAG prompt template'i prompts.py'den import edildi
            # Llama modeli iÃ§in Ã¶zel kÄ±sa cevap talimatÄ± ekle
            rag_prompt_template_str = RAG_PROMPT_TEMPLATE
            
            # Llama modeli iÃ§in kÄ±sa ve Ã¶z cevap talimatÄ± ekle
            if model_name.lower() == "llama":
                llama_instruction = """

**LLAMA MODELÄ° Ä°Ã‡Ä°N Ã–ZEL TALÄ°MAT (Ã‡OK Ã–NEMLÄ°):**
- CEVAPLARINI MUTLAKA TÃœRKÃ‡E VER
- KÄ±sa, Ã¶z ve direkt cevap ver - gereksiz aÃ§Ä±klama yapma
- "I'm a corporate memory assistant" gibi Ä°ngilizce giriÅŸler YASAKTIR
- Soruyu tekrar yazma, direkt cevaba baÅŸla
- Ã–rnek: "Fatura tarihi nedir?" sorusuna â†’ "Fatura tarihi 11.01.2025'tir." gibi kÄ±sa cevap ver
- "nedir", "ne zaman", "kaÃ§" gibi basit sorulara tek cÃ¼mlelik cevap ver
- Liste sorularÄ±nda bile her Ã¶ÄŸeyi kÄ±sa tut
- ASLA Ä°ngilizce cevap verme, MUTLAKA TÃ¼rkÃ§e cevap ver
- Gereksiz detaylar, aÃ§Ä±klamalar, Ã¶rnekler verme - sadece sorulan soruya cevap ver

"""
                # Prompt'un sonuna ekle (KRÄ°TÄ°K CEVAP KURALLARI bÃ¶lÃ¼mÃ¼nden Ã¶nce)
                rag_prompt_template_str = rag_prompt_template_str.replace(
                    "**KRÄ°TÄ°K CEVAP KURALLARI:**",
                    llama_instruction + "**KRÄ°TÄ°K CEVAP KURALLARI:**"
                )
                print("ðŸ‡¹ðŸ‡· Llama modeli iÃ§in kÄ±sa ve Ã¶z TÃ¼rkÃ§e cevap talimatÄ± eklendi")
            
            rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template_str)
            
            def format_docs_for_prompt(docs: List[Document]) -> str:
                if not docs: return "KullanÄ±cÄ±nÄ±n sorusuyla ilgili spesifik bir belge bulunamadÄ±."
                
                # Liste sorularÄ± iÃ§in daha fazla chunk gÃ¶nder ama sÄ±nÄ±rlÄ± (eksiksiz liste iÃ§in)
                is_list_query = is_list_intent(request.message)
                question_lower = request.message.lower()
                has_company_name = any(word in question_lower for word in ['firma', 'ÅŸirket', 'tedarikÃ§i', 'mÃ¼ÅŸteri', 'supplier', 'vendor', 'company', 'client', 'customer'])
                has_document_type = any(word in question_lower for word in ['teklif', 'sÃ¶zleÅŸme', 'fatura', 'po', 'purchase order', 'offer', 'invoice', 'contract'])
                
                if is_list_query:
                    # TedarikÃ§i/firma sorularÄ± iÃ§in daha fazla chunk gÃ¶nder
                    is_supplier_query = has_company_name
                    is_name_list_query = any(word in question_lower for word in ['isimleri', 'isimler', 'kimler', 'hangi.*aday', 'hangi.*kisi', 'nedir.*isim'])
                    # Ä°sim listesi sorularÄ± iÃ§in daha fazla chunk gerekli (eksiksiz liste iÃ§in)
                    max_chunks = 300 if is_supplier_query else (250 if is_name_list_query else 200)  # Ä°sim listesi sorularÄ± iÃ§in max 250 chunk
                    chunks_to_send = docs[:max_chunks] if len(docs) > max_chunks else docs
                    print(f"ðŸ“‹ Liste sorusu algÄ±landÄ± - {len(chunks_to_send)} chunk gÃ¶nderiliyor (reranking sonrasÄ±, eksiksiz liste iÃ§in)...")
                elif has_company_name and has_document_type:
                    # Firma ismi ve belge tÃ¼rÃ¼ iÃ§eren detay sorularÄ± iÃ§in (Ã¶rn: "SILA firmasÄ±na verilen teklif detaylarÄ±")
                    max_chunks = 80  # Firma ismi ve belge tÃ¼rÃ¼ iÃ§eren sorular iÃ§in daha fazla chunk
                    chunks_to_send = docs[:max_chunks] if len(docs) > max_chunks else docs
                    print(f"ðŸ“„ Firma/belge detay sorusu algÄ±landÄ± - {len(chunks_to_send)} chunk gÃ¶nderiliyor...")
                elif has_company_name:
                    # Sadece firma ismi iÃ§eren sorular iÃ§in
                    max_chunks = 60  # Firma ismi iÃ§eren sorular iÃ§in
                    chunks_to_send = docs[:max_chunks] if len(docs) > max_chunks else docs
                    print(f"ðŸ“„ Firma detay sorusu algÄ±landÄ± - {len(chunks_to_send)} chunk gÃ¶nderiliyor...")
                else:
                    # "kaÃ§ adet", "toplamda kaÃ§" gibi sayÄ±sal sorular iÃ§in daha fazla chunk gerekli
                    is_count_query = any(word in question_lower for word in ['kac', 'toplam', 'adet', 'sayi', 'count', 'total', 'how many'])
                    max_chunks = 150 if is_count_query else 100  # SayÄ±sal sorular iÃ§in max 150 chunk
                    chunks_to_send = docs[:max_chunks] if len(docs) > max_chunks else docs
                    print(f"YanÄ±t Ã¼retimi iÃ§in LLM'e {len(chunks_to_send)} adet chunk gÃ¶nderiliyor...")
                
                # Her chunk'a numara ekle (LLM'in takip edebilmesi iÃ§in)
                formatted_chunks = []
                for idx, doc in enumerate(chunks_to_send, 1):
                    chunk_text = f"--- AlÄ±ntÄ± #{idx} (Kaynak: {doc.metadata.get('source_file_name', 'Bilinmiyor')}) ---\n{doc.page_content}"
                    formatted_chunks.append(chunk_text)
                
                return "\n\n".join(formatted_chunks)
            
            # Model seÃ§imine gÃ¶re LLM oluÅŸtur
            # SMART MODE: EÄŸer sorgu basitse ve kullanÄ±cÄ± Ã¶zel bir model zorlamadÄ±ysa (varsayÄ±lan gemini ise), ucuz modeli kullan
            is_simple = is_simple_query(request.message)
            if is_simple and model_name == "gemini":
                print(f"ðŸš€ Basit sorgu algÄ±landÄ±, maliyet optimizasyonu iÃ§in UCUZ MODEL (Gemini Flash) kullanÄ±lÄ±yor.")
                selected_llm = get_cheap_llm()
                # Metadata iÃ§in model adÄ±nÄ± gÃ¼ncelle (raporlama iÃ§in)
                if hasattr(selected_llm, 'model_name'):
                    model_name = f"{selected_llm.model_name} (Smart Mode)"
            else:
                selected_llm = get_llm_for_model(model_name)
            
            print(f"ðŸ”— Final RAG chain'i {model_name} modeli ile oluÅŸturuluyor...")
            
            # Chain'i oluÅŸtur - model seÃ§imine gÃ¶re
            rag_chain = ({"context": lambda x: format_docs_for_prompt(x["chunks"]), "question": lambda x: x["question"]} | rag_prompt | selected_llm)
            
            # Chain'i Ã§aÄŸÄ±r
            ai_full_response = rag_chain.invoke({"chunks": final_chunks, "question": request.message})
            
            # LLM yanÄ±tÄ±nÄ± logla (debug iÃ§in)
            ai_response_text = ai_full_response.content if hasattr(ai_full_response, 'content') and ai_full_response.content else ""
            print(f"DEBUG: LLM yanÄ±t iÃ§eriÄŸi (ilk 500 karakter): {ai_response_text[:500]}")
            
            # SayÄ±sal cevabÄ± kontrol et
            import re
            numbers_in_response = re.findall(r'\d+', ai_response_text)
            if numbers_in_response:
                print(f"DEBUG: LLM yanÄ±tÄ±nda bulunan sayÄ±lar: {numbers_in_response}")
            
            # Aday isimlerini kontrol et (basit bir kontrol)
            if "aday" in ai_response_text.lower():
                # "X aday" veya "Y adayla" gibi kalÄ±plarÄ± ara
                candidate_matches = re.findall(r'(\d+)\s*(?:farklÄ±\s*)?(?:aday|kiÅŸi|gÃ¶rÃ¼ÅŸ)', ai_response_text, re.IGNORECASE)
                if candidate_matches:
                    print(f"DEBUG: YanÄ±tta bulunan aday sayÄ±sÄ± referanslarÄ±: {candidate_matches}")
            
            # Final RAG Ã§aÄŸrÄ±sÄ± iÃ§in token tracking - metadata'dan al (prompt string'i gerekmez)
            input_tokens, output_tokens = extract_token_usage_from_response(ai_full_response, "Final RAG")
            estimated = not (hasattr(ai_full_response, 'usage_metadata') and ai_full_response.usage_metadata) and not (hasattr(ai_full_response, 'response_metadata') and ai_full_response.response_metadata and ('usage_metadata' in ai_full_response.response_metadata or 'token_usage' in ai_full_response.response_metadata))
            token_tracker.add_usage(
                input_tokens,
                output_tokens,
                "Final RAG (YanÄ±t Ãœretimi)",
                estimated=estimated,
                raw_metadata=ai_full_response.response_metadata if hasattr(ai_full_response, 'response_metadata') else None
            )
            
            ai_message_text, source_context_text = "", ""
            source_file_names = []  # Kaynak dosya adlarÄ±nÄ± sakla
            
            # Llama iÃ§in cevap temizleme - gereksiz baÅŸlÄ±k ve aÃ§Ä±klamalarÄ± kaldÄ±r
            def clean_llama_response(text, model_name, question=""):
                """Llama modelinin cevabÄ±ndan gereksiz kÄ±sÄ±mlarÄ± temizle ve kÄ±sa/Ã¶z hale getir"""
                if model_name.lower() != "llama":
                    return text
                
                import re
                
                # Ã–nce KAYNAKLAR bÃ¶lÃ¼mÃ¼nÃ¼ ayÄ±r
                main_text = text
                sources_text = ""
                if "KAYNAKLAR:" in text:
                    parts = text.split("KAYNAKLAR:", 1)
                    main_text = parts[0].strip()
                    sources_text = parts[1].strip()
                
                # Ä°ngilizce giriÅŸ bloklarÄ±nÄ± kaldÄ±r (daha agresif)
                # "I'm a corporate memory assistant! I'll help you..." gibi tÃ¼m bloklarÄ± kaldÄ±r
                main_text = re.sub(r"^I'm a corporate memory assistant[^.]*[.!?].*?To answer your question:", '', main_text, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)
                main_text = re.sub(r"^I'm a corporate memory assistant[^.]*[.!?].*?Please note that[^.]*[.!?]", '', main_text, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)
                
                # Ä°ngilizce giriÅŸ cÃ¼mlelerini kaldÄ±r (daha kapsamlÄ±)
                english_intros = [
                    r"^I'm a corporate memory assistant[^.!?]*[.!?]",
                    r"^I'll help you with[^.!?]*[.!?]",
                    r"^Please note that[^.!?]*[.!?]",
                    r"^Since there are multiple[^.!?]*[.!?]",
                    r"^Let me[^.!?]*[.!?]",
                    r"^I'll go through[^.!?]*[.!?]",
                    r"^The quote appears to be[^.!?]*[.!?]",
                    r"^This quote appears to be[^.!?]*[.!?]",
                    r"^Based on the provided[^.!?]*[.!?]",
                    r"^According to the[^.!?]*[.!?]",
                    r"^To answer your question[^.!?]*[.!?]",
                    r"^Here are the[^.!?]*[.!?]",
                    r"^Please let me know[^.!?]*[.!?]",
                ]
                for pattern in english_intros:
                    main_text = re.sub(pattern, '', main_text, flags=re.IGNORECASE | re.MULTILINE)
                
                # Soru tekrarÄ±nÄ± kaldÄ±r (baÅŸlÄ±k formatÄ±nda)
                main_text = re.sub(r'\*\*.*?sÄ±rala.*?\*\*', '', main_text, flags=re.IGNORECASE | re.MULTILINE)
                main_text = re.sub(r'\*\*.*?soru.*?\*\*', '', main_text, flags=re.IGNORECASE | re.MULTILINE)
                
                # "Here are the recent..." gibi aÃ§Ä±klama cÃ¼mlelerini kaldÄ±r
                main_text = re.sub(r'Here are the[^:]*:', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'Here are[^:]*:', '', main_text, flags=re.IGNORECASE)
                
                # "**AlÄ±ntÄ± #1**", "**AlÄ±ntÄ± #2**" gibi Ä°ngilizce baÅŸlÄ±klarÄ± kaldÄ±r
                main_text = re.sub(r'\*\*AlÄ±ntÄ±\s*#\d+\*\*', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'^AlÄ±ntÄ±\s*#\d+:', '', main_text, flags=re.IGNORECASE | re.MULTILINE)
                
                # Ä°ngilizce aÃ§Ä±klama cÃ¼mlelerini kaldÄ±r
                main_text = re.sub(r'The relevant information includes:', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'The relevant info:', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'Company name:', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'Tax Office:', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'Tax Number:', '', main_text, flags=re.IGNORECASE)
                
                # Ä°lk olarak, "**Cevap:**" gibi baÅŸlÄ±klarÄ± kaldÄ±r
                main_text = re.sub(r'^\*\*Cevap:\*\*\s*\n?', '', main_text, flags=re.IGNORECASE | re.MULTILINE)
                main_text = re.sub(r'^Cevap:\s*\n?', '', main_text, flags=re.IGNORECASE | re.MULTILINE)
                
                # "**Kaynak:**" veya "**Kaynaklar:**" baÅŸlÄ±klarÄ±nÄ± kaldÄ±r
                main_text = re.sub(r'\*\*Kaynak[lar]*:\*\*.*?(?=\n\n|KAYNAKLAR:|$)', '', main_text, flags=re.DOTALL | re.IGNORECASE)
                main_text = re.sub(r'Kaynak[lar]*:.*?(?=\n\n|KAYNAKLAR:|$)', '', main_text, flags=re.DOTALL | re.IGNORECASE)
                
                # Soru tekrarlarÄ±nÄ± ve parantez iÃ§i dosya adlarÄ±nÄ± kaldÄ±r
                main_text = re.sub(r'\([^)]*\.(?:pdf|docx?|xlsx?)\)', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'Fatura[^?]*detayÄ±nÄ±[^?]*yazar[^?]*mÄ±sÄ±n[^?]*\?', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'Fatura[^.]*detayÄ±nÄ±[^.]*yazmak[^.]*iÃ§in[^.]*\.', '', main_text, flags=re.IGNORECASE)
                
                # "Kaynak: ..." satÄ±rlarÄ±nÄ± kaldÄ±r
                main_text = re.sub(r'^Kaynak:\s*[^\n]*(?=\n|$)', '', main_text, flags=re.MULTILINE | re.IGNORECASE)
                main_text = re.sub(r'SADECE[^.]*cevabÄ±[^.]*veriyorum[^.]*\.', '', main_text, flags=re.IGNORECASE)
                main_text = re.sub(r'Direkt[^.]*cevaba[^.]*baÅŸlÄ±yorum[^.]*\.', '', main_text, flags=re.IGNORECASE)
                
                # "**KRÄ°TÄ°K CEVAP KURALLARI:**" baÅŸlÄ±ÄŸÄ± ve altÄ±ndaki tÃ¼m bloÄŸu kaldÄ±r
                main_text = re.sub(r'\*\*KRÄ°TÄ°K CEVAP KURALLARI:\*\*.*?(?=\n\n[^\s\-\*]|\n[^\s\-\*\n]|$)', '', main_text, flags=re.DOTALL | re.IGNORECASE)
                main_text = re.sub(r'KRÄ°TÄ°K CEVAP KURALLARI:.*?(?=\n\n[^\s\-\*]|\n[^\s\-\*\n]|$)', '', main_text, flags=re.DOTALL | re.IGNORECASE)
                
                # "**Ä°SÄ°M LÄ°STESÄ° SORULARI Ä°Ã‡Ä°N Ã–ZEL KURAL**" bloÄŸunu kaldÄ±r
                main_text = re.sub(r'\*\*Ä°SÄ°M LÄ°STESÄ°.*?(?=\n\n[^\s\-\*]|\n[^\s\-\*\n]|$)', '', main_text, flags=re.DOTALL | re.IGNORECASE)
                
                # "- SADECE cevabÄ± ver" gibi madde iÅŸaretli kurallarÄ± kaldÄ±r
                main_text = re.sub(r'^[\s\-*]*(?:SADECE|ASLA|MUTLAKA|Direkt|Soruyu|TÃœM alÄ±ntÄ±larÄ±|EÄŸer soru|Firma ismi).*$', '', main_text, flags=re.MULTILINE | re.IGNORECASE)
                
                # Basit sorular iÃ§in ilk cÃ¼mleyi al (kÄ±sa cevap iÃ§in)
                # "nedir", "ne zaman", "kaÃ§", "sÄ±rala", "listele" gibi sorular iÃ§in sadece ilk cÃ¼mleyi tut
                if question:
                    question_lower = question.lower()
                    is_simple_question = any(word in question_lower for word in ['nedir', 'ne zaman', 'kaÃ§', 'kim', 'nerede', 'hangi tarih', 'tarihi nedir', 'sÄ±rala', 'listele', 'gÃ¶ster'])
                    
                    if is_simple_question:
                        # Ä°lk cÃ¼mleyi bul (nokta, soru iÅŸareti veya Ã¼nlem ile biten)
                        # Veya liste formatÄ±nda ise ilk birkaÃ§ satÄ±rÄ± al
                        lines = main_text.split('\n')
                        cleaned_lines = []
                        for line in lines:
                            line = line.strip()
                            if not line:
                                continue
                            # Ä°ngilizce satÄ±rlarÄ± atla (TÃ¼rkÃ§e karakter kontrolÃ¼)
                            if re.match(r'^[A-Z][a-z].*[.!?]$', line) and not any(turkish_char in line for turkish_char in ['Ã§', 'ÄŸ', 'Ä±', 'Ã¶', 'ÅŸ', 'Ã¼', 'Ã‡', 'Äž', 'Ä°', 'Ã–', 'Åž', 'Ãœ']):
                                continue
                            # TÃ¼rkÃ§e iÃ§erik bulundu, ekle
                            cleaned_lines.append(line)
                            # Ä°lk 5-7 satÄ±rÄ± al (liste sorularÄ± iÃ§in)
                            if len(cleaned_lines) >= 7:
                                break
                        
                        if cleaned_lines:
                            main_text = '\n'.join(cleaned_lines)
                            print(f"ðŸ“ Basit soru algÄ±landÄ±, sadece ilk {len(cleaned_lines)} satÄ±r alÄ±ndÄ±")
                
                # Tekrar eden boÅŸ satÄ±rlarÄ± temizle
                main_text = re.sub(r'\n{3,}', '\n\n', main_text)
                
                # BaÅŸlangÄ±Ã§ ve son boÅŸluklarÄ± temizle
                main_text = main_text.strip()
                
                # EÄŸer baÅŸlangÄ±Ã§ta hala gereksiz bir baÅŸlÄ±k varsa kaldÄ±r
                if main_text.startswith("**"):
                    main_text = re.sub(r'^\*\*[^*]+\*\*\s*', '', main_text)
                
                # BaÅŸlangÄ±Ã§ ve son boÅŸluklarÄ± tekrar temizle
                main_text = main_text.strip()
                
                # KAYNAKLAR artÄ±k cevaba eklenmeyecek (ayrÄ± olarak gÃ¶sterilecek)
                return main_text
            
            # CevabÄ± temizle (Llama iÃ§in)
            cleaned_response = clean_llama_response(ai_full_response.content, model_name, request.message)
            
            if "KAYNAKLAR:" in cleaned_response:
                parts = cleaned_response.split("KAYNAKLAR:", 1)
                ai_message_text = parts[0].strip()
                source_context_text = parts[1].strip().replace("- ", "").replace("* ", "")
                # Kaynak dosya adlarÄ±nÄ± parse et (virgÃ¼l, satÄ±r baÅŸÄ± veya baÅŸka ayÄ±rÄ±cÄ±lardan)
                # Ã–nce satÄ±r baÅŸÄ±na gÃ¶re bÃ¶l, sonra virgÃ¼le gÃ¶re bÃ¶l
                source_file_names = []
                for line in source_context_text.split('\n'):
                    # Her satÄ±rÄ± kontrol et
                    line = line.strip()
                    if not line:
                        continue
                    # VirgÃ¼lle ayrÄ±lmÄ±ÅŸ ise bÃ¶l
                    if ',' in line:
                        for item in line.split(','):
                            cleaned = item.strip()
                            if cleaned:
                                source_file_names.append(cleaned)
                    else:
                        # VirgÃ¼l yoksa tÃ¼m satÄ±rÄ± ekle
                        source_file_names.append(line)
                
                # Debug iÃ§in
                print(f"DEBUG: Parse edilen kaynak dosyalarÄ±: {source_file_names}")
            else:
                ai_message_text = ai_full_response.content.strip()
                source_file_names = sorted(list({chunk.metadata['source_file_name'] for chunk in final_chunks if chunk.metadata.get('source_file_name')}))
                if source_file_names: source_context_text = ", ".join(source_file_names)
            
            # Token tracker'dan toplam token bilgisini al
            token_summary = token_tracker.get_summary()
            print("\n" + "="*70)
            print("ðŸ“Š TOPLAM TOKEN KULLANIM Ã–ZETÄ°")
            print("="*70)
            print(f"   Toplam GiriÅŸ Token: {token_summary['total_input_tokens']:,}")
            print(f"   Toplam Ã‡Ä±kÄ±ÅŸ Token: {token_summary['total_output_tokens']:,}")
            print(f"   TOPLAM TOKEN: {token_summary['total_tokens']:,}")
            print(f"   LLM Ã‡aÄŸrÄ± SayÄ±sÄ±: {token_summary['call_count']}")
            print(f"   Tahmini Maliyet (USD): ${token_summary['estimated_cost_usd']:.4f}")
            print(f"   Tahmini Maliyet (TL): {token_summary['estimated_cost_tl']:.2f} TL")
            print("="*70 + "\n")
            
            # Response iÃ§in token usage bilgisini token tracker'dan al
            token_usage = {
                "input_tokens": token_summary['total_input_tokens'],
                "output_tokens": token_summary['total_output_tokens'],
                "total_tokens": token_summary['total_tokens'],
                "breakdown": token_summary['breakdown'],
                "estimated_cost_usd": token_summary['estimated_cost_usd'],
                "estimated_cost_tl": token_summary['estimated_cost_tl']
            }

            # Token bilgilerini cevabÄ±n altÄ±na ekle (kullanÄ±cÄ±ya gÃ¶sterilecek format)
            # token_info_text = ... (KaldÄ±rÄ±ldÄ±)
            # KAYNAKLAR bilgisini cevap metninden kaldÄ±r - sadece source_context'te gÃ¶sterilecek
            # Cevaba sadece token bilgilerini ekle
            final_response_message = ai_message_text
            
            response_data = {
                "response_message": final_response_message, 
                "source_context": source_context_text or "Genel Bilgi", 
                "token_usage": token_usage,
                "source_file_names": source_file_names  # BaÄŸlama eklemek iÃ§in sakla
            }
    
    except Exception as e:
        print(f"LangChain RAG zinciri hatasÄ±: {e}\n{tb_module.format_exc()}")
        
        # Rate limit hatasÄ± iÃ§in Ã¶zel mesaj
        error_str = str(e)
        if "rate_limit" in error_str.lower() or "429" in error_str or "RateLimitError" in str(type(e)):
            error_message = "Yapay zeka servisi ÅŸu anda Ã§ok yoÄŸun. LÃ¼tfen birkaÃ§ saniye bekleyip tekrar deneyin. Alternatif olarak, daha az veri iÃ§eren bir soru sorabilir veya baÅŸka bir AI modeli seÃ§ebilirsiniz."
        else:
            error_message = f"Yapay zeka modelinden yanÄ±t alÄ±nÄ±rken bir hata oluÅŸtu: {str(e)[:200]}"
        
        # Hata durumunda bile token tracker'dan bilgi al
        if 'token_tracker' in locals():
            token_summary = token_tracker.get_summary()
            if token_summary['total_tokens'] > 0:
                print(f"âš ï¸ Hata oluÅŸtu, ancak hata Ã¶ncesi {token_summary['total_tokens']:,} token kullanÄ±ldÄ±.")
            # Hata durumunda da token bilgilerini ekle
            
            response_data = {
                "response_message": error_message, 
                "source_context": "Hata",
                "token_usage": {
                    "input_tokens": token_summary['total_input_tokens'],
                    "output_tokens": token_summary['total_output_tokens'],
                    "total_tokens": token_summary['total_tokens'],
                    "breakdown": token_summary['breakdown'],
                    "estimated_cost_usd": token_summary['estimated_cost_usd'],
                    "estimated_cost_tl": token_summary['estimated_cost_tl']
                },
                "source_file_names": []
            }
        else:
            response_data = {
                "response_message": error_message, 
                "source_context": "Hata", 
                "token_usage": {},
                "source_file_names": []
            }

    # --- DÃœZELTME: METADATA HESAPLAMASINI DB KAYDINDAN Ã–NCE YAP ---
    
    processing_time = time.monotonic() - t_start
    
    # Token kullanÄ±m Ã¶zeti (varsa)
    token_summary_final = token_tracker.get_summary() if 'token_tracker' in locals() else None
    token_usage_for_metadata = response_data.get("token_usage", {})
    
    # EÄŸer token_usage boÅŸsa ama token_tracker varsa, ondan al
    if not token_usage_for_metadata and token_summary_final:
        token_usage_for_metadata = {
            "input_tokens": token_summary_final['total_input_tokens'],
            "output_tokens": token_summary_final['total_output_tokens'],
            "total_tokens": token_summary_final['total_tokens'],
            "breakdown": token_summary_final['breakdown'],
            "estimated_cost_usd": token_summary_final['estimated_cost_usd'],
            "estimated_cost_tl": token_summary_final['estimated_cost_tl']
        }
    
    response_metadata = {
        "processing_time": round(processing_time, 2),
        "token_usage": token_usage_for_metadata,
        "source_context": response_data.get("source_context")
    }
    
    # --- KAYNAKLARI BAÄžLAMA EKLE ---
    new_context_items = []
    source_file_names = response_data.get("source_file_names", []) if 'response_data' in locals() else []
    if source_file_names and 'response_data' in locals() and response_data.get("response_message"):
        try:
            # Dosya adlarÄ±ndan dosya bilgilerini bul
            all_tenant_files = get_all_accessible_files_for_user(db, user)
            matched_files = []
            seen_file_ids = set()  # Duplicate kontrolÃ¼ iÃ§in
            
            for file_name in source_file_names:
                # Dosya adÄ±nÄ± normalize et (tÄ±rnak iÅŸaretleri, boÅŸluklar vb. temizle)
                original_file_name = file_name.strip().strip('"').strip("'")
                clean_file_name = original_file_name
                
                # Path'ten sadece dosya adÄ±nÄ± Ã§Ä±kar (Ã¶rn: "satÄ±nalma/mail trafiÄŸi/dosya.docx" -> "dosya.docx")
                path_parts = []
                if "/" in clean_file_name:
                    path_parts = clean_file_name.split("/")
                    clean_file_name = path_parts[-1]
                elif "\\" in clean_file_name:
                    path_parts = clean_file_name.split("\\")
                    clean_file_name = path_parts[-1]
                
                # Normalize: BaÅŸtaki/sondaki boÅŸluklarÄ± temizle
                clean_file_name = clean_file_name.strip()
                
                # Tam eÅŸleÅŸme Ã¶ncelikli (dosya adÄ±)
                matched = False
                for file in all_tenant_files:
                    if file.id in seen_file_ids:
                        continue  # Zaten eklenmiÅŸ, atla
                    
                    if file.name == clean_file_name:
                        matched_files.append(file)
                        seen_file_ids.add(file.id)
                        matched = True
                        print(f"âœ… Tam eÅŸleÅŸme bulundu: '{clean_file_name}' -> '{file.name}'")
                        break
                
                # Tam eÅŸleÅŸme yoksa, path'li dosya adÄ± ile eÅŸleÅŸme ara
                if not matched and path_parts:
                    original_path = original_file_name.replace("\\", "/")
                    file_name_from_path = path_parts[-1].strip() if path_parts else clean_file_name
                    path_folders = path_parts[:-1] if len(path_parts) > 1 else []
                    
                    for file in all_tenant_files:
                        if file.id in seen_file_ids:
                            continue
                        
                        # Dosya adÄ± eÅŸleÅŸiyorsa (tam veya kÄ±smi)
                        file_name_matches = (file.name == file_name_from_path or 
                                           file.name.lower() == file_name_from_path.lower() or
                                           file.name.endswith(file_name_from_path) or
                                           file_name_from_path in file.name)
                        
                        if file_name_matches:
                            # Path klasÃ¶rleri varsa, dosyanÄ±n klasÃ¶rÃ¼nÃ¼ kontrol et
                            if path_folders and file.folder_id:
                                folder = next((f for f in db.get_all_folders_for_tenant(user.tenant_id) if f.id == file.folder_id), None)
                                if folder:
                                    folder_name_lower = folder.name.lower()
                                    # Path'teki klasÃ¶r isimlerinden biri dosyanÄ±n klasÃ¶rÃ¼nde geÃ§iyor mu?
                                    path_match = any(part.lower() in folder_name_lower or folder_name_lower in part.lower() 
                                                   for part in path_folders)
                                    if path_match:
                                        matched_files.append(file)
                                        seen_file_ids.add(file.id)
                                        matched = True
                                        print(f"âœ… Path ile eÅŸleÅŸme bulundu: '{original_path}' -> '{file.name}' (KlasÃ¶r: {folder.name})")
                                        break
                            
                            # Path kontrolÃ¼ yapÄ±lamazsa veya path yoksa, sadece dosya adÄ± eÅŸleÅŸmesi yeterli
                            if not matched:
                                matched_files.append(file)
                                seen_file_ids.add(file.id)
                                matched = True
                                print(f"âœ… Dosya adÄ± eÅŸleÅŸmesi bulundu: '{file_name_from_path}' -> '{file.name}'")
                                break
                
                # Hala eÅŸleÅŸme yoksa, kÄ±smi eÅŸleÅŸme dene (son Ã§are)
                if not matched:
                    # Dosya adÄ±nÄ±n bÃ¼yÃ¼k bir kÄ±smÄ± eÅŸleÅŸiyorsa kabul et
                    # Ã–zellikle teklif, fatura, sÃ¶zleÅŸme gibi belgeler iÃ§in
                    clean_lower = clean_file_name.lower()
                    if len(clean_file_name) > 10:  # Yeterince uzun dosya adlarÄ± iÃ§in
                        for file in all_tenant_files:
                            if file.id in seen_file_ids:
                                continue
                            
                            file_lower = file.name.lower()
                            # KÄ±smi eÅŸleÅŸme kontrolÃ¼: dosya adÄ±nÄ±n Ã¶nemli kÄ±smÄ± eÅŸleÅŸiyor mu?
                            # Ã–rnek: "E-Posta Senaryosu SBYS Natural Rubber Teklifi" ile "E-Posta Senaryosu SBYS Natural Rubber TTeklifi" eÅŸleÅŸmeli
                            key_parts = [part.strip() for part in clean_lower.replace(".docx", "").replace(".pdf", "").split() 
                                       if len(part.strip()) > 3]  # 3 karakterden uzun kelimeler
                            
                            if key_parts:
                                # Dosya adÄ±nda bu kelimelerin Ã§oÄŸu geÃ§iyor mu?
                                matching_parts = sum(1 for part in key_parts if part in file_lower)
                                match_ratio = matching_parts / len(key_parts) if key_parts else 0
                                
                                # %70 veya daha fazla kelime eÅŸleÅŸiyorsa veya teklif/fatura gibi keyword varsa
                                has_keyword = any(kw in clean_lower for kw in ['teklif', 'fatura', 'invoice', 'sÃ¶zleÅŸme', 'agreement', 'contract', 'purchase', 'order'])
                                if match_ratio >= 0.7 or (has_keyword and match_ratio >= 0.5):
                                    matched_files.append(file)
                                    seen_file_ids.add(file.id)
                                    matched = True
                                    print(f"âœ… KÄ±smi eÅŸleÅŸme (son Ã§are): '{clean_file_name}' -> '{file.name}' (EÅŸleÅŸme: %{match_ratio*100:.0f})")
                                    break
                
                if not matched:
                    print(f"âš ï¸ Kaynak dosya bulunamadÄ±: '{original_file_name}' (temizlenmiÅŸ: '{clean_file_name}')")
            
            if matched_files:
                print(f"ðŸ” Kaynaklardan {len(matched_files)} dosya bulundu, baÄŸlama ekleniyor...")
                
                # ALGILAMA: KullanÄ±cÄ±nÄ±n sorusuna gÃ¶re sadece alakalÄ± dosyalarÄ± filtrele
                query_lower = request.message.lower()
                relevant_keywords = []
                
                # SÃ¶zleÅŸme/agreement sorularÄ± iÃ§in
                if any(word in query_lower for word in ['sÃ¶zleÅŸme', 'sÃ¶zleÅŸmem', 'agreement', 'contract']):
                    relevant_keywords.extend(['sÃ¶zleÅŸme', 'agreement', 'contract', 'satÄ±nalma', 'purchase', 'tedarikÃ§i', 'supplier', 'vendor'])
                
                # Fatura/invoice sorularÄ± iÃ§in
                if any(word in query_lower for word in ['fatura', 'invoice', 'Ã¶deme', 'payment']):
                    relevant_keywords.extend(['fatura', 'invoice', 'payment', 'Ã¶deme'])
                
                # Teklif sorularÄ± iÃ§in
                if any(word in query_lower for word in ['teklif', 'quote', 'proposal', 'offer']):
                    relevant_keywords.extend(['teklif', 'quote', 'proposal', 'offer'])
                
                # Purchase Order sorularÄ± iÃ§in
                if any(word in query_lower for word in ['satÄ±n alma', 'purchase', 'order', 'po', 'sipariÅŸ']):
                    relevant_keywords.extend(['purchase', 'order', 'po', 'satÄ±n alma', 'sipariÅŸ', 'satÄ±nalma'])
                
                # EÄŸer alakalÄ± keyword varsa, sadece alakalÄ± dosyalarÄ± filtrele
                filtered_files = matched_files
                if relevant_keywords:
                    filtered_files = []
                    for file in matched_files:
                        file_name_lower = file.name.lower()
                        # Dosya adÄ±nda veya klasÃ¶r adÄ±nda alakalÄ± kelime var mÄ±?
                        if any(keyword in file_name_lower for keyword in relevant_keywords):
                            filtered_files.append(file)
                        elif file.folder_id:
                            folder = next((f for f in db.get_all_folders_for_tenant(user.tenant_id) if f.id == file.folder_id), None)
                            if folder and any(keyword in folder.name.lower() for keyword in relevant_keywords):
                                filtered_files.append(file)
                    
                    if filtered_files:
                        print(f"âœ… {len(filtered_files)} alakalÄ± dosya filtrelendi ({len(matched_files)} toplam)")
                    else:
                        # Filtre Ã§ok katÄ± oldu, tÃ¼m dosyalarÄ± kullan
                        filtered_files = matched_files
                        print(f"âš ï¸ Filtre sonrasÄ± dosya kalmadÄ±, tÃ¼m {len(matched_files)} dosya kullanÄ±lacak")
                else:
                    print(f"â„¹ï¸ AlakalÄ± keyword bulunamadÄ±, tÃ¼m {len(matched_files)} dosya kullanÄ±lacak")
                
                # DosyalarÄ±n folder_id'lerini topla (filtrelenmiÅŸ dosyalardan)
                folder_ids = {file.folder_id for file in filtered_files if file.folder_id}
                
                if len(filtered_files) == 1:
                    # Tek dosya varsa, o dosyayÄ± ekle
                    file = filtered_files[0]
                    new_context_items.append(ActiveContextFile(
                        id=file.id,
                        name=file.name,
                        type="file"
                    ))
                    print(f"âœ… Tek dosya baÄŸlama eklendi: {file.name}")
                elif len(folder_ids) == 1:
                    # TÃ¼m dosyalar aynÄ± klasÃ¶rdeyse, klasÃ¶rÃ¼ ekle
                    folder_id = list(folder_ids)[0]
                    folder_found = False
                    for f in db.get_all_folders_for_tenant(user.tenant_id):
                        if f.id == folder_id:
                            new_context_items.append(ActiveContextFile(
                                id=f.id,
                                name=f.name,
                                type="folder"
                            ))
                            print(f"âœ… Tek klasÃ¶r baÄŸlama eklendi: {f.name}")
                            folder_found = True
                            break
                    if not folder_found:
                        # KlasÃ¶r bulunamazsa dosyalarÄ± ekle
                        for file in filtered_files:
                            new_context_items.append(ActiveContextFile(
                                id=file.id,
                                name=file.name,
                                type="file"
                            ))
                        print(f"âš ï¸ KlasÃ¶r bulunamadÄ±, {len(filtered_files)} dosya eklendi")
                elif len(filtered_files) <= 5:
                    # 5 veya daha az dosya varsa, dosyalarÄ± ekle (klasÃ¶r deÄŸil)
                    for file in filtered_files:
                        new_context_items.append(ActiveContextFile(
                            id=file.id,
                            name=file.name,
                            type="file"
                        ))
                    print(f"âœ… {len(filtered_files)} dosya baÄŸlama eklendi (az dosya olduÄŸu iÃ§in klasÃ¶r yerine)")
                else:
                    # Ã‡ok fazla dosya varsa, en yaygÄ±n 3-5 klasÃ¶rÃ¼ ekle (tÃ¼m klasÃ¶rleri deÄŸil!)
                    folder_counts = {}
                    for file in filtered_files:
                        if file.folder_id:
                            folder_counts[file.folder_id] = folder_counts.get(file.folder_id, 0) + 1
                    
                    # En Ã§ok dosya iÃ§eren klasÃ¶rleri sÄ±rala
                    sorted_folders = sorted(folder_counts.items(), key=lambda x: x[1], reverse=True)
                    # En fazla 3-5 klasÃ¶r ekle (veya dosyalarÄ±n %80'ini kapsayan klasÃ¶rler)
                    max_folders = min(5, len(sorted_folders))
                    total_files = len(filtered_files)
                    threshold = total_files * 0.8
                    
                    folders_added = set()
                    files_covered = 0
                    for folder_id, count in sorted_folders[:max_folders]:
                        if files_covered < threshold:
                            folder = next((f for f in db.get_all_folders_for_tenant(user.tenant_id) if f.id == folder_id), None)
                            if folder and folder_id not in folders_added:
                                new_context_items.append(ActiveContextFile(
                                    id=folder.id,
                                    name=folder.name,
                                    type="folder"
                                ))
                                folders_added.add(folder_id)
                                files_covered += count
                                print(f"âœ… KlasÃ¶r baÄŸlama eklendi: {folder.name} ({count} dosya)")
                    
                    # EÄŸer klasÃ¶r bulunamadÄ±ysa veya Ã§ok az dosya kapsandÄ±ysa, en Ã¶nemli dosyalarÄ± ekle
                    if not folders_added or files_covered < total_files * 0.5:
                        # En Ã§ok geÃ§en dosya isimlerine sahip dosyalarÄ± ekle
                        important_files = filtered_files[:min(10, len(filtered_files))]
                        for file in important_files:
                            new_context_items.append(ActiveContextFile(
                                id=file.id,
                                name=file.name,
                                type="file"
                            ))
                        print(f"âš ï¸ KlasÃ¶r yeterli deÄŸil, {len(important_files)} Ã¶nemli dosya eklendi")
                
                # Yeni context item'larÄ± mevcut baÄŸlama ekle
                if new_context_items:
                    existing_context = context_memory.get_context()
                    existing_ids = {item.id for item in existing_context}
                    # Sadece yeni olanlarÄ± ekle (duplicate kontrolÃ¼)
                    for item in new_context_items:
                        if item.id not in existing_ids:
                            existing_context.append(item)
                    context_memory.set_context(existing_context)
                    print(f"ðŸ“Ž Toplam {len(existing_context)} kalem baÄŸlama eklendi.")
        except Exception as e:
            print(f"âš ï¸ KaynaklarÄ± baÄŸlama eklerken hata: {e}\n{tb_module.format_exc()}")
    
    # --- DÃœZELTME: DB'YE MESAJI METADATA Ä°LE KAYDET ---
    db.save_chat_message(
        chat_id, 
        user.tenant_id, 
        ChatMessage(
            sender="ai", 
            text=response_data["response_message"], 
            metadata=response_metadata
        )
    )
    
    final_active_context = context_memory.get_context()

    return ChatResponse(
        response_message=response_data["response_message"], source_context=response_data.get("source_context"),
        chat_id=chat_id, active_context_files=final_active_context,
        response_type="answer", suggested_file=None,
        response_metadata=response_metadata
    )