# backend/app/services/chat_helpers.py
# Chat service yardÄ±mcÄ± fonksiyonlarÄ±
# LocalGPT tarzÄ± Cross-Encoder reranking desteÄŸi eklendi

import re
import unicodedata
import json
import os
from typing import List, Tuple
from collections import Counter
from functools import lru_cache

from langchain_core.documents import Document
from langchain_core.messages import SystemMessage, HumanMessage

from app.services.prompts import RERANK_SYSTEM_PROMPT, HYDE_SYSTEM_PROMPT
from app.services.llm_providers import get_llm_for_model, get_cheap_llm
from app.services.token_tracking import TokenTracker, extract_token_usage_from_response

# --- Cross-Encoder iÃ§in ---
try:
    from sentence_transformers import CrossEncoder
    CROSS_ENCODER_AVAILABLE = True
except ImportError:
    CROSS_ENCODER_AVAILABLE = False
    print("âš ï¸ sentence-transformers paketi yÃ¼klÃ¼ deÄŸil. Cross-Encoder reranking devre dÄ±ÅŸÄ±.")


def normalize_text_for_matching(text: str) -> str:
    """Metni normalleÅŸtir (TÃ¼rkÃ§e karakterleri temizle)."""
    text = text.lower()
    text = text.replace('Ä±', 'i').replace('ÄŸ', 'g').replace('Ã¼', 'u').replace('ÅŸ', 's').replace('Ã¶', 'o').replace('Ã§', 'c')
    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')


def calculate_filename_match_score(query: str, filename: str) -> float:
    """Dosya adÄ± ile sorgu arasÄ±ndaki eÅŸleÅŸme skorunu hesapla."""
    normalized_query = normalize_text_for_matching(query)
    normalized_filename = normalize_text_for_matching(filename.rsplit('.', 1)[0])
    query_words = set(re.findall(r'\b\w{3,}\b', normalized_query))
    filename_words = set(re.findall(r'\b\w+\b', normalized_filename))
    if not query_words or not filename_words:
        return 0.0
    intersection = query_words.intersection(filename_words)
    match_ratio = len(intersection) / len(query_words)
    if normalized_query in normalized_filename:
        match_ratio = 2.0
    return match_ratio


def identify_and_filter_high_confidence_document(chunks: List[Document], query: str) -> Tuple[List[Document], bool]:
    """Åampiyon belge tespiti yap (bir dosyadan gelen chunk'lar Ã§ok fazlaysa odaklan)."""
    if not chunks:
        return [], False
    
    # Her chunk'a hybrid_score ekle
    for chunk in chunks:
        vector_score = chunk.metadata.get('similarity_score', 0.0)
        chunk.metadata['hybrid_score'] = vector_score
    
    # SkorlarÄ±na gÃ¶re sÄ±rala
    chunks.sort(key=lambda x: x.metadata.get('hybrid_score', 0.0), reverse=True)
    top_chunks = chunks[:10]
    
    if not top_chunks:
        return chunks, False
    
    # En Ã¼stteki chunk'larda hangi dosya daha Ã§ok geÃ§iyor?
    top_file_ids_counts = Counter(
        chunk.metadata.get('source_file_id') for chunk in top_chunks if chunk.metadata.get('source_file_id')
    )
    
    if not top_file_ids_counts:
        return chunks, False
    
    most_common_file_id, count = top_file_ids_counts.most_common(1)[0]
    
    # EÄŸer en Ã¼stteki chunk'larda bir dosyadan 5 veya daha fazla chunk varsa, o dosyaya odaklan
    if count >= 5:
        champion_file_name = next(
            (chunk.metadata.get('source_file_name', 'Bilinmiyor') 
             for chunk in top_chunks 
             if chunk.metadata.get('source_file_id') == most_common_file_id), 
            'Bilinmiyor'
        )
        
        # KRÄ°TÄ°K: Dosya adÄ± ile soru arasÄ±nda uyum kontrolÃ¼ yap
        # EÄŸer dosya adÄ± ile soru uyuÅŸmuyorsa, ÅŸampiyon belge olarak kabul etme
        filename_match_score = calculate_filename_match_score(query, champion_file_name)
        
        # Dosya adÄ± ile soru arasÄ±nda yeterli uyum yoksa, ÅŸampiyon belge olarak kabul etme
        # Bu, yanlÄ±ÅŸ dosyalarÄ±n seÃ§ilmesini Ã¶nler (Ã¶rn: "aÃ§Ä±k rÄ±za metni" sorusu iÃ§in "hurda satÄ±ÅŸ prosedÃ¼rÃ¼" seÃ§ilmesi)
        if filename_match_score < 0.15:  # EÅŸik: %15 uyum gerekli
            print(f"âš ï¸ Åampiyon belge adayÄ± bulundu ama dosya adÄ± ile soru uyuÅŸmuyor (uyum skoru: {filename_match_score:.2f}). Reranking yapÄ±lacak.")
            print(f"   Dosya: '{champion_file_name}'")
            print(f"   Soru: '{query[:100]}...'")
            return chunks, False
        
        print(f"ğŸ† Åampiyon Belge Tespit Edildi! Odak: '{champion_file_name}' (Uyum skoru: {filename_match_score:.2f})")
        champion_chunks = [chunk for chunk in chunks if chunk.metadata.get('source_file_id') == most_common_file_id]
        return champion_chunks, True
    
    print(f"ğŸ“š Åampiyon belge bulunamadÄ±. VektÃ¶r skoruna gÃ¶re en iyi {len(chunks)} chunk yeniden sÄ±ralanacak.")
    return chunks, False


def is_list_intent(query: str) -> bool:
    """Sorgunun bir liste isteÄŸi olup olmadÄ±ÄŸÄ±nÄ± kontrol et."""
    q_lower = normalize_text_for_matching(query)
    # Liste sorularÄ± iÃ§in pattern'ler
    patterns = [
        r"liste", r"kimlere", r"kime", r"hangi", r"firmalar", r"musteriler", r"kisiler", r"prosedurler",
        r"isimleri", r"isimler", r"kimler", r"hangi.*isim", r"hangi.*aday", r"hangi.*kisi",
        r"nedir.*isim", r"nedir.*isimler", r"nedir.*isimleri", r"nedir.*kimler"
    ]
    return any(re.search(p, q_lower) for p in patterns)


@lru_cache(maxsize=1)
def get_reranker_model():
    """Cross-Encoder reranker modelini yÃ¼kle (LocalGPT tarzÄ±)."""
    if not CROSS_ENCODER_AVAILABLE:
        return None
    
    try:
        # LocalGPT'in Ã¶nerdiÄŸi modeller:
        # - 'BAAI/bge-reranker-base' (multilingual, iyi performans)
        # - 'cross-encoder/ms-marco-MiniLM-L-6-v2' (hÄ±zlÄ±)
        model_name = os.getenv("RERANKER_MODEL", "BAAI/bge-reranker-base")
        print(f"âš¡ Cross-Encoder reranker yÃ¼kleniyor: {model_name}")
        reranker = CrossEncoder(model_name)
        return reranker
    except Exception as e:
        print(f"âš ï¸ Cross-Encoder yÃ¼klenemedi: {e}")
        return None


def rerank_chunks_with_cross_encoder(
    docs: List[Document],
    question: str,
    top_k: int = 20
) -> List[Document]:
    """
    Cross-Encoder ile reranking (LocalGPT tarzÄ±).
    LLM reranking'den daha hÄ±zlÄ± ve genellikle daha doÄŸru.
    """
    if not docs:
        return []
    
    reranker = get_reranker_model()
    if not reranker:
        # Fallback: LLM reranking
        print("âš ï¸ Cross-Encoder yok, LLM reranking kullanÄ±lacak...")
        return None  # None dÃ¶ndÃ¼r, Ã§aÄŸÄ±ran fonksiyon LLM reranking yapsÄ±n
    
    try:
        # Cross-Encoder iÃ§in input hazÄ±rla: [query, document]
        # 512 token limit (performans iÃ§in)
        pairs = [[question, doc.page_content[:512]] for doc in docs]
        
        # SkorlarÄ± hesapla (batch processing)
        scores = reranker.predict(pairs, show_progress_bar=False)
        
        # Skorlara gÃ¶re sÄ±rala
        scored_docs = list(zip(docs, scores))
        scored_docs.sort(key=lambda x: x[1], reverse=True)
        
        # En iyi top_k chunk'Ä± seÃ§
        reranked = [doc for doc, score in scored_docs[:top_k]]
        
        print(f"âœ… Cross-Encoder reranking: {len(docs)} â†’ {len(reranked)} chunk (top_k={top_k})")
        
        return reranked
        
    except Exception as e:
        print(f"âŒ Cross-Encoder reranking hatasÄ±: {e}")
        # Fallback: Ä°lk top_k chunk'Ä± dÃ¶ndÃ¼r
        return docs[:top_k]


def rerank_chunks_with_llm_wrapper(docs: List[Document], question: str, model_name: str, token_tracker: TokenTracker = None, is_list_query: bool = False) -> List[Document]:
    """LLM kullanarak chunk'larÄ± yeniden sÄ±rala."""
    if not docs:
        return []
    
    # Soruda firma ismi ve belge tÃ¼rÃ¼ var mÄ± kontrol et
    question_lower = normalize_text_for_matching(question)
    has_company_name = any(word in question_lower for word in ['firma', 'sirket', 'tedarikci', 'musteri', 'supplier', 'vendor', 'company', 'client', 'customer'])
    has_document_type = any(word in question_lower for word in ['teklif', 'sozlesme', 'fatura', 'po', 'purchase order', 'offer', 'invoice', 'contract'])
    
    # Liste sorularÄ± iÃ§in daha fazla chunk iÅŸle
    if is_list_query:
        max_chunks = 300
    elif has_company_name and has_document_type:
        max_chunks = 200  # Firma ismi ve belge tÃ¼rÃ¼ iÃ§eren sorular iÃ§in daha fazla chunk
    elif has_company_name:
        max_chunks = 150  # Sadece firma ismi iÃ§eren sorular iÃ§in
    else:
        max_chunks = 150  # Normal sorular iÃ§in
    chunks_to_process = docs[:max_chunks]
    numbered_chunks = "".join(f"[[ALINTI {i+1}]]\n{doc.page_content}\n\n" for i, doc in enumerate(chunks_to_process))
    
    # Soruda firma ismi ve belge tÃ¼rÃ¼ var mÄ± kontrol et (liste olmasa bile)
    question_lower = normalize_text_for_matching(question)
    has_company_name = any(word in question_lower for word in ['firma', 'sirket', 'tedarikci', 'musteri', 'supplier', 'vendor', 'company', 'client', 'customer'])
    has_document_type = any(word in question_lower for word in ['teklif', 'sozlesme', 'fatura', 'po', 'purchase order', 'offer', 'invoice', 'contract'])
    
    # Liste sorularÄ± iÃ§in Ã¶zel talimat
    if is_list_query:
        is_supplier_query = has_company_name
        
        if is_supplier_query:
            selection_instruction = """
Bu soru bir TEDARÄ°KÃ‡Ä°/FÄ°RMA LÄ°STESÄ° sorusudur (Ã–rn: 'Hangi tedarikÃ§iler', 'Hangi firmalar'). 
GÃ–REVÄ°N:
1. Ä°Ã§inde SOMUT FÄ°RMA/TEDARÄ°KÃ‡Ä° Ä°SMÄ° geÃ§en alÄ±ntÄ±larÄ± seÃ§ (Ã¶rn: "ArlanX", "Futura Industrial", "HEPPS-Steel", "AGAR HOSE", "BOSABOX", "Omey", "SBSY", "SBYS", "Huasheng", "KordX").
2. SÃ¶zleÅŸme, PO (Purchase Order), teklif, fatura gibi belgelerle ilgili TÃœM alÄ±ntÄ±larÄ± seÃ§ - HER BÄ°RÄ°NÄ° kontrol et.
3. Sadece 'KVKK', 'prosedÃ¼r tanÄ±mÄ±', 'talimat' veya 'boÅŸ form' iÃ§eren genel metinleri ELE (SeÃ§me) - ama iÃ§inde firma ismi geÃ§iyorsa MUTLAKA seÃ§.
4. Eksiksiz liste iÃ§in en az 250-300 alakalÄ± alÄ±ntÄ± seÃ§meye Ã§alÄ±ÅŸ - FIRMA Ä°SMÄ° GEÃ‡EN TÃœM alÄ±ntÄ±larÄ± seÃ§.
5. TÃœM alakalÄ± alÄ±ntÄ±larÄ± seÃ§ - eksik bilgi vermemek iÃ§in Ã§ok geniÅŸ bir seÃ§im yap. "ÅÃ¼pheli" olanlarÄ± bile seÃ§ - daha sonra filtrelenebilir.
6. Bir alÄ±ntÄ±da sadece 1 firma ismi bile olsa, onu mutlaka seÃ§.
7. FarklÄ± alÄ±ntÄ±larda farklÄ± firmalar olabilir - HEPSÄ°NÄ° seÃ§.
8. Dosya adlarÄ±nda firma ismi geÃ§iyorsa o alÄ±ntÄ±yÄ± da seÃ§ (Ã¶rn: "XYZ_Purchase_Order.pdf" iÃ§eren alÄ±ntÄ±).
9. E-posta adreslerinde firma domain'i varsa o alÄ±ntÄ±yÄ± da seÃ§ (Ã¶rn: "sales@firma.com" iÃ§eren alÄ±ntÄ±).
"""
        else:
            # "isimleri nedir", "kimler", "hangi adaylar" gibi sorular iÃ§in Ã¶zel talimat
            is_name_list_query = any(word in question_lower for word in ['isimleri', 'isimler', 'kimler', 'hangi.*aday', 'hangi.*kisi', 'nedir.*isim'])
            
            if is_name_list_query:
                selection_instruction = """
Bu soru bir Ä°SÄ°M LÄ°STESÄ° sorusudur (Ã–rn: 'isimleri nedir', 'kimler', 'hangi adaylar'). 
GÃ–REVÄ°N:
1. Ä°Ã§inde SOMUT KÄ°ÅÄ° Ä°SMÄ°, ADAY Ä°SMÄ° veya FÄ°RMA Ä°SMÄ° geÃ§en TÃœM alÄ±ntÄ±larÄ± seÃ§ (Ã¶rn: "Ahmet YÄ±lmaz", "Elif Karadeniz", "Selin Demir", "Can Ã–ztÃ¼rk").
2. Aday Ã¶zeti, gÃ¶rÃ¼ÅŸme Ã¶zeti, CV, baÅŸvuru belgeleri gibi belgelerle ilgili TÃœM alÄ±ntÄ±larÄ± seÃ§ - HER BÄ°RÄ°NÄ° kontrol et.
3. Sadece 'prosedÃ¼r tanÄ±mÄ±', 'talimat' veya 'boÅŸ form' iÃ§eren genel metinleri ELE (SeÃ§me) - ama iÃ§inde isim geÃ§iyorsa MUTLAKA seÃ§.
4. Eksiksiz liste iÃ§in TÃœM isim iÃ§eren alÄ±ntÄ±larÄ± seÃ§ - bir alÄ±ntÄ±da sadece 1 isim bile olsa, onu mutlaka seÃ§.
5. FarklÄ± alÄ±ntÄ±larda farklÄ± isimler olabilir - HEPSÄ°NÄ° seÃ§.
6. Dosya adlarÄ±nda isim geÃ§iyorsa o alÄ±ntÄ±yÄ± da seÃ§ (Ã¶rn: "Aday GÃ¶rÃ¼ÅŸme Ã–zet _Elif Karadeniz.pdf" iÃ§eren alÄ±ntÄ±).
7. Eksik liste vermek KESÄ°NLÄ°KLE YANLIÅ - TÃœM isimleri bulana kadar TÃœM alÄ±ntÄ±larÄ± seÃ§.
"""
            else:
                selection_instruction = """
Bu soru bir LÄ°STE sorusudur (Ã–rn: 'Hangi firmalar', 'Kimler', 'Listele'). 
GÃ–REVÄ°N:
1. Ä°Ã§inde SOMUT Ä°SÄ°M, FÄ°RMA ADI, TEDARÄ°KÃ‡Ä° ADI veya VERÄ° geÃ§en alÄ±ntÄ±larÄ± seÃ§.
2. Sadece 'prosedÃ¼r tanÄ±mÄ±', 'talimat' veya 'boÅŸ form' iÃ§eren genel metinleri ELE (SeÃ§me).
3. Eksiksiz liste iÃ§in en az 120-150 alakalÄ± alÄ±ntÄ± seÃ§meye Ã§alÄ±ÅŸ (genel kalite iÃ§in artÄ±rÄ±ldÄ±).
4. TÃœM alakalÄ± alÄ±ntÄ±larÄ± seÃ§ - eksik bilgi vermemek iÃ§in geniÅŸ bir seÃ§im yap. "ÅÃ¼pheli" olanlarÄ± bile seÃ§.
"""
    elif has_company_name and has_document_type:
        # Firma ismi ve belge tÃ¼rÃ¼ iÃ§eren detay sorularÄ± iÃ§in (Ã¶rn: "SILA firmasÄ±na verilen teklif detaylarÄ±")
        selection_instruction = """
Bu soru bir FÄ°RMA/BELGE DETAY sorusudur (Ã–rn: "X firmasÄ±na verilen teklif", "Y firmasÄ± ile sÃ¶zleÅŸme"). 
GÃ–REVÄ°N:
1. Soruda geÃ§en FÄ°RMA Ä°SMÄ°NÄ° iÃ§eren TÃœM alÄ±ntÄ±larÄ± seÃ§ (Ã¶rn: soruda "SILA" geÃ§iyorsa, "SILA" iÃ§eren tÃ¼m alÄ±ntÄ±larÄ± seÃ§).
2. Soruda geÃ§en BELGE TÃœRÃœNÃœ iÃ§eren alÄ±ntÄ±larÄ± seÃ§ (teklif, sÃ¶zleÅŸme, fatura, PO, vb.).
3. Firma ismi ve belge tÃ¼rÃ¼ birlikte geÃ§en alÄ±ntÄ±larÄ± Ã–NCELÄ°KLE seÃ§.
4. Dosya adlarÄ±nda firma ismi veya belge tÃ¼rÃ¼ geÃ§iyorsa o alÄ±ntÄ±yÄ± da seÃ§.
5. E-posta adreslerinde firma domain'i varsa o alÄ±ntÄ±yÄ± da seÃ§.
6. Sadece 'KVKK', 'prosedÃ¼r tanÄ±mÄ±', 'talimat' veya 'boÅŸ form' iÃ§eren genel metinleri ELE (SeÃ§me) - ama iÃ§inde firma ismi veya belge tÃ¼rÃ¼ geÃ§iyorsa seÃ§.
7. Eksiksiz bilgi iÃ§in en az 50-80 alakalÄ± alÄ±ntÄ± seÃ§meye Ã§alÄ±ÅŸ - firma ismi ve belge tÃ¼rÃ¼ ile ilgili TÃœM alÄ±ntÄ±larÄ± seÃ§.
8. "ÅÃ¼pheli" olanlarÄ± bile seÃ§ - daha sonra filtrelenebilir.
"""
    elif has_company_name:
        # Sadece firma ismi iÃ§eren sorular iÃ§in
        selection_instruction = """
Bu soru bir FÄ°RMA DETAY sorusudur (Ã–rn: "X firmasÄ±", "Y ÅŸirketi"). 
GÃ–REVÄ°N:
1. Soruda geÃ§en FÄ°RMA Ä°SMÄ°NÄ° iÃ§eren TÃœM alÄ±ntÄ±larÄ± seÃ§ (Ã¶rn: soruda "SILA" geÃ§iyorsa, "SILA" iÃ§eren tÃ¼m alÄ±ntÄ±larÄ± seÃ§).
2. Dosya adlarÄ±nda firma ismi geÃ§iyorsa o alÄ±ntÄ±yÄ± da seÃ§.
3. E-posta adreslerinde firma domain'i varsa o alÄ±ntÄ±yÄ± da seÃ§.
4. Sadece 'KVKK', 'prosedÃ¼r tanÄ±mÄ±', 'talimat' veya 'boÅŸ form' iÃ§eren genel metinleri ELE (SeÃ§me) - ama iÃ§inde firma ismi geÃ§iyorsa seÃ§.
5. Eksiksiz bilgi iÃ§in en az 40-60 alakalÄ± alÄ±ntÄ± seÃ§meye Ã§alÄ±ÅŸ - firma ismi ile ilgili TÃœM alÄ±ntÄ±larÄ± seÃ§.
"""
    else:
        selection_instruction = "Sadece bu soruya en alakalÄ± olanlarÄ±n NUMARALARINI listele."
    
    user_prompt = f"""KullanÄ±cÄ±nÄ±n sorusu: "{question}"

AÅŸaÄŸÄ±da numaralandÄ±rÄ±lmÄ±ÅŸ alÄ±ntÄ±lar var. {selection_instruction}
Ã–rnek format: "1, 3, 7, 12, 15, 20, 25, ..."

AlÄ±ntÄ±lar:
{numbered_chunks}

Sorunun cevabÄ± iÃ§in alakalÄ± OLAN TÃœM alÄ±ntÄ±larÄ±n numaralarÄ±nÄ± (virgÃ¼lle ayÄ±rarak) yaz:"""
    
    try:
        # Reranking iÃ§in ucuz model kullan
        llm = get_cheap_llm()
        response = llm.invoke([
            SystemMessage(content=RERANK_SYSTEM_PROMPT),
            HumanMessage(content=user_prompt)
        ])
        
        # Token tracking
        if token_tracker:
            input_tokens, output_tokens = extract_token_usage_from_response(response, "Reranking", user_prompt)
            token_tracker.add_usage(input_tokens, output_tokens, "Reranking (Chunk Yeniden SÄ±ralama)", 
                                   estimated=(input_tokens == 0 and output_tokens == 0))
        
        # YanÄ±ttan numaralarÄ± Ã§Ä±kar
        response_text = response.content if hasattr(response, 'content') else str(response)
        numbers = re.findall(r'\d+', response_text)
        selected_indices = [int(n) - 1 for n in numbers if 1 <= int(n) <= len(chunks_to_process)]
        
        if not selected_indices:
            # Firma ismi iÃ§eren sorular iÃ§in daha fazla chunk dÃ¶ndÃ¼r
            question_lower = normalize_text_for_matching(question)
            has_company_name = any(word in question_lower for word in ['firma', 'sirket', 'tedarikci', 'musteri', 'supplier', 'vendor', 'company', 'client', 'customer'])
            has_document_type = any(word in question_lower for word in ['teklif', 'sozlesme', 'fatura', 'po', 'purchase order', 'offer', 'invoice', 'contract'])
            
            if is_list_query:
                fallback_count = 100
            elif has_company_name and has_document_type:
                fallback_count = 50  # Firma ismi ve belge tÃ¼rÃ¼ iÃ§eren sorular iÃ§in
            elif has_company_name:
                fallback_count = 30  # Sadece firma ismi iÃ§eren sorular iÃ§in
            else:
                fallback_count = 20
            print(f"âš ï¸ LLM hiÃ§bir alÄ±ntÄ± seÃ§emedi, ilk {fallback_count} chunk dÃ¶ndÃ¼rÃ¼lÃ¼yor (daha fazla bilgi iÃ§in).")
            return chunks_to_process[:fallback_count]
        
        reranked = [chunks_to_process[i] for i in selected_indices if 0 <= i < len(chunks_to_process)]
        
        # Minimum chunk sayÄ±sÄ± garantisi
        question_lower = normalize_text_for_matching(question)
        has_company_name = any(word in question_lower for word in ['firma', 'sirket', 'tedarikci', 'musteri', 'supplier', 'vendor', 'company', 'client', 'customer'])
        has_document_type = any(word in question_lower for word in ['teklif', 'sozlesme', 'fatura', 'po', 'purchase order', 'offer', 'invoice', 'contract'])
        
        if is_list_query:
            # Liste sorularÄ± iÃ§in minimum chunk garantisi
            is_supplier_query = has_company_name
            is_name_list_query = any(word in question_lower for word in ['isimleri', 'isimler', 'kimler', 'hangi.*aday', 'hangi.*kisi', 'nedir.*isim'])
            # Ä°sim listesi sorularÄ± iÃ§in daha fazla chunk gerekli (eksiksiz liste iÃ§in)
            min_chunks = 250 if is_supplier_query else (150 if is_name_list_query else 120)  # Ä°sim listesi sorularÄ± iÃ§in minimum 150 chunk
            
            if len(reranked) < min_chunks:
                # EÄŸer toplam chunk sayÄ±sÄ± minimum chunk sayÄ±sÄ±ndan azsa, tÃ¼m chunk'larÄ± gÃ¶nder
                if len(chunks_to_process) <= min_chunks:
                    print(f"âš ï¸ Liste sorusu iÃ§in toplam {len(chunks_to_process)} chunk var (minimum {min_chunks} gerekli). TÃ¼m chunk'lar gÃ¶nderiliyor...")
                    reranked = chunks_to_process
                else:
                    print(f"âš ï¸ Liste sorusu iÃ§in sadece {len(reranked)} chunk seÃ§ildi. En iyi {min_chunks} chunk'a tamamlanÄ±yor (genel kalite iÃ§in)...")
                    selected_set = set(selected_indices)
                    remaining_chunks = [(i, chunks_to_process[i]) for i in range(len(chunks_to_process)) if i not in selected_set]
                    remaining_chunks.sort(key=lambda x: x[1].metadata.get('similarity_score', 0.0), reverse=True)
                    # Toplam min_chunks chunk olana kadar ekle
                    for i, chunk in remaining_chunks[:min_chunks - len(reranked)]:
                        reranked.append(chunk)
        elif has_company_name and has_document_type:
            # Firma ismi ve belge tÃ¼rÃ¼ iÃ§eren detay sorularÄ± iÃ§in minimum chunk garantisi
            min_chunks = 50  # Firma ismi ve belge tÃ¼rÃ¼ iÃ§eren sorular iÃ§in minimum 50 chunk
            if len(reranked) < min_chunks:
                print(f"âš ï¸ Firma/belge detay sorusu iÃ§in sadece {len(reranked)} chunk seÃ§ildi. En iyi {min_chunks} chunk'a tamamlanÄ±yor...")
                selected_set = set(selected_indices)
                remaining_chunks = [(i, chunks_to_process[i]) for i in range(len(chunks_to_process)) if i not in selected_set]
                remaining_chunks.sort(key=lambda x: x[1].metadata.get('similarity_score', 0.0), reverse=True)
                # Toplam min_chunks chunk olana kadar ekle
                for i, chunk in remaining_chunks[:min_chunks - len(reranked)]:
                    reranked.append(chunk)
        elif has_company_name:
            # Sadece firma ismi iÃ§eren sorular iÃ§in minimum chunk garantisi
            min_chunks = 30  # Firma ismi iÃ§eren sorular iÃ§in minimum 30 chunk
            if len(reranked) < min_chunks:
                print(f"âš ï¸ Firma detay sorusu iÃ§in sadece {len(reranked)} chunk seÃ§ildi. En iyi {min_chunks} chunk'a tamamlanÄ±yor...")
                selected_set = set(selected_indices)
                remaining_chunks = [(i, chunks_to_process[i]) for i in range(len(chunks_to_process)) if i not in selected_set]
                remaining_chunks.sort(key=lambda x: x[1].metadata.get('similarity_score', 0.0), reverse=True)
                # Toplam min_chunks chunk olana kadar ekle
                for i, chunk in remaining_chunks[:min_chunks - len(reranked)]:
                    reranked.append(chunk)
        else:
            # Normal sorular iÃ§in minimum chunk garantisi
            # "kaÃ§ adet", "toplamda kaÃ§" gibi sayÄ±sal sorular iÃ§in daha fazla chunk gerekli
            is_count_query = any(word in question_lower for word in ['kac', 'toplam', 'adet', 'sayi', 'count', 'total', 'how many'])
            min_chunks = 50 if is_count_query else 20  # SayÄ±sal sorular iÃ§in minimum 50 chunk
            
            if len(reranked) < min_chunks:
                # EÄŸer toplam chunk sayÄ±sÄ± minimum chunk sayÄ±sÄ±ndan azsa, tÃ¼m chunk'larÄ± gÃ¶nder
                if len(chunks_to_process) <= min_chunks:
                    print(f"âš ï¸ Toplam {len(chunks_to_process)} chunk var (minimum {min_chunks} gerekli). TÃ¼m chunk'lar gÃ¶nderiliyor...")
                    reranked = chunks_to_process
                else:
                    print(f"âš ï¸ Sadece {len(reranked)} chunk seÃ§ildi. En iyi {min_chunks} chunk'a tamamlanÄ±yor (doÄŸruluk iÃ§in)...")
                    selected_set = set(selected_indices)
                    remaining_chunks = [(i, chunks_to_process[i]) for i in range(len(chunks_to_process)) if i not in selected_set]
                    remaining_chunks.sort(key=lambda x: x[1].metadata.get('similarity_score', 0.0), reverse=True)
                    # Toplam min_chunks chunk olana kadar ekle
                    for i, chunk in remaining_chunks[:min_chunks - len(reranked)]:
                        reranked.append(chunk)
        
        print(f"âœ… LLM {len(selected_indices)} alÄ±ntÄ± seÃ§ti. {len(reranked)} alÄ±ntÄ± yeniden sÄ±ralandÄ±.")
        return reranked
    except Exception as e:
        print(f"âŒ Reranking hatasÄ±: {e}. Ä°lk 20 chunk dÃ¶ndÃ¼rÃ¼lÃ¼yor.")
        return chunks_to_process[:20]


def create_hypothetical_document_for_query_wrapper(question: str, model_name: str, token_tracker: TokenTracker = None) -> str:
    """HyDE: Sorudan hipotetik bir belge oluÅŸtur (vektÃ¶r aramasÄ± iÃ§in)."""
    user_prompt = f"""Orijinal Soru: "{question}"

Bu soruya cevap verebilecek Ã¶rnek bir belge metni:"""
    
    try:
        # HyDE iÃ§in ucuz model kullan
        llm = get_cheap_llm()
        response = llm.invoke([
            SystemMessage(content=HYDE_SYSTEM_PROMPT),
            HumanMessage(content=user_prompt)
        ])
        
        # Token tracking
        if token_tracker:
            input_tokens, output_tokens = extract_token_usage_from_response(response, "HyDE (Hipotetik Belge OluÅŸturma)", user_prompt)
            token_tracker.add_usage(input_tokens, output_tokens, "HyDE (Hipotetik Belge OluÅŸturma)", 
                                   estimated=(input_tokens == 0 and output_tokens == 0))
        
        hyde_text = response.content if hasattr(response, 'content') else str(response)
        return hyde_text
    except Exception as e:
        print(f"HyDE oluÅŸturma hatasÄ±: {e}")
        return question  # Hata durumunda orijinal soruyu dÃ¶ndÃ¼r


# Basit in-memory cache (opsiyonel - performans iÃ§in)
_off_topic_cache: dict[str, bool] = {}
_help_query_cache: dict[str, bool] = {}
_greeting_cache: dict[str, bool] = {}


def is_off_topic_query(query: str, use_cache: bool = True) -> bool:
    """
    LLM kullanarak sorgunun genel sohbet/off-topic olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
    Bu tÃ¼r sorular dosyalarda taranmamalÄ± ve yanÄ±t verilmemelidir.
    
    Args:
        query: KullanÄ±cÄ±nÄ±n sorusu
        use_cache: Cache kullanÄ±lsÄ±n mÄ± (aynÄ± sorular iÃ§in tekrar LLM Ã§aÄŸrÄ±sÄ± yapÄ±lmasÄ±n)
    
    Returns:
        True eÄŸer sorgu off-topic ise (genel sohbet, hal hatÄ±r, spor, hava durumu vb.)
        False eÄŸer sorgu Knowvex ile ilgiliyse
    """
    if not query or not query.strip():
        return False
    
    # Cache kontrolÃ¼ (opsiyonel - performans iÃ§in)
    if use_cache:
        cache_key = query.lower().strip()
        cached_result = _off_topic_cache.get(cache_key)
        if cached_result is not None:
            return cached_result
    
    try:
        # Ucuz model kullan (classification iÃ§in yeterli)
        llm = get_cheap_llm()
        
        prompt = f"""Sen bir Knowvex asistanÄ±sÄ±n. KullanÄ±cÄ±larÄ±n sorularÄ±nÄ± analiz edip, bu sorularÄ±n platform ile ilgili olup olmadÄ±ÄŸÄ±nÄ± belirlemelisin.

KNOWVEX Ä°LE Ä°LGÄ°LÄ° SORULAR:
- Dosya, belge, rapor, proje, prosedÃ¼r, politika arama
- Mail iÃ§erikleri, kritik mailler, mail istatistikleri
- VeritabanÄ± sorgularÄ±, veri analizi
- Ä°ÅŸ sÃ¼reÃ§leri, kurumsal bilgiler
- Åirket iÃ§i dokÃ¼mantasyon, talimatlar
- Tarih, sayÄ±, istatistik sorgularÄ± (iÅŸ ile ilgili)
- Detay bilgi, fiyat, miktar, tutar sorgularÄ± (dosyalarda arama yapÄ±lmasÄ± gereken)
- "Detay bilgisi verir misin?", "fiyatÄ± nedir?", "tutar nedir?" gibi sorular (dosyalarda arama yapÄ±lmasÄ± gereken)
- Belge iÃ§eriÄŸi hakkÄ±nda sorular ("nedir", "ne kadar", "kaÃ§", "hangi", "kim")

OFF-TOPIC (GENEL SOHBET) SORULAR - YANIT VERÄ°LMEMELÄ°:
- Hava durumu, havalar nasÄ±l
- Spor, maÃ§ sonuÃ§larÄ±, futbol, basketbol
- Genel sohbet, ne haber, naber (selamlaÅŸma dÄ±ÅŸÄ±nda)
- KiÅŸisel sorular (sen kimsin, kaÃ§ yaÅŸÄ±ndasÄ±n)
- ManipÃ¼le edici sorular
- Platform dÄ±ÅŸÄ± genel bilgi sorularÄ±

NOT: SelamlaÅŸma ve hal hatÄ±r sorularÄ± ("merhaba", "nasÄ±lsÄ±n", "iyi gÃ¼nler") ayrÄ± bir kategori olarak iÅŸlenir ve nazik bir ÅŸekilde cevaplanÄ±r.

KULLANICI SORUSU: "{query}"

GÃ–REV: Bu soru Knowvex ile ilgili mi yoksa genel sohbet/off-topic mi?

YANIT FORMATI: Sadece JSON formatÄ±nda yanÄ±t ver:
{{
    "is_off_topic": true/false,
    "reason": "kÄ±sa aÃ§Ä±klama"
}}

Ã–RNEKLER:
- "BugÃ¼n kaÃ§ mail geldi?" â†’ {{"is_off_topic": false, "reason": "Mail istatistiÄŸi - platform ile ilgili"}}
- "NasÄ±lsÄ±n?" â†’ {{"is_off_topic": true, "reason": "Genel sohbet - hal hatÄ±r"}}
- "X projesi hakkÄ±nda bilgi ver" â†’ {{"is_off_topic": false, "reason": "Proje bilgisi - platform ile ilgili"}}
- "Havalar nasÄ±l?" â†’ {{"is_off_topic": true, "reason": "Hava durumu - off-topic"}}
- "Kritik mailleri listele" â†’ {{"is_off_topic": false, "reason": "Mail sorgusu - platform ile ilgili"}}
- "Åu maÃ§ ne oldu?" â†’ {{"is_off_topic": true, "reason": "Spor - off-topic"}}
- "Detay bilgisi verir misin? fatura fiyatÄ± nedir?" â†’ {{"is_off_topic": false, "reason": "Belge iÃ§eriÄŸi sorusu - dosyalarda arama yapÄ±lmasÄ± gereken"}}
- "FiyatÄ± nedir?" â†’ {{"is_off_topic": false, "reason": "Belge iÃ§eriÄŸi sorusu - dosyalarda arama yapÄ±lmasÄ± gereken"}}
- "Tutar nedir?" â†’ {{"is_off_topic": false, "reason": "Belge iÃ§eriÄŸi sorusu - dosyalarda arama yapÄ±lmasÄ± gereken"}}
- "Ne kadar?" â†’ {{"is_off_topic": false, "reason": "Belge iÃ§eriÄŸi sorusu - dosyalarda arama yapÄ±lmasÄ± gereken"}}

YANIT:"""

        response = llm.invoke(prompt)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # JSON'u parse et
        try:
            # JSON'u bul (```json ... ``` veya direkt JSON)
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                json_str = response_text[json_start:json_end].strip()
            elif "```" in response_text:
                json_start = response_text.find("```") + 3
                json_end = response_text.find("```", json_start)
                json_str = response_text[json_start:json_end].strip()
            else:
                json_str = response_text.strip()
            
            # Ä°lk { ve son } arasÄ±nÄ± al
            if "{" in json_str and "}" in json_str:
                json_start = json_str.find("{")
                json_end = json_str.rfind("}") + 1
                json_str = json_str[json_start:json_end]
            
            result = json.loads(json_str)
            is_off_topic = result.get("is_off_topic", False)
            reason = result.get("reason", "")
            
            print(f"ğŸ” Off-topic kontrolÃ¼: '{query[:50]}...' â†’ {'OFF-TOPIC' if is_off_topic else 'PLATFORM Ä°LE Ä°LGÄ°LÄ°'} ({reason})")
            
            # Cache'e kaydet
            if use_cache:
                cache_key = query.lower().strip()
                _off_topic_cache[cache_key] = is_off_topic
            
            return is_off_topic
            
        except json.JSONDecodeError as e:
            print(f"âš ï¸ LLM yanÄ±tÄ± JSON parse edilemedi: {e}")
            print(f"   Ham yanÄ±t: {response_text[:200]}")
            # Fallback: YanÄ±tta "true" veya "false" kelimesi var mÄ± kontrol et
            response_lower = response_text.lower()
            if "true" in response_lower and "is_off_topic" in response_lower:
                return True
            elif "false" in response_lower and "is_off_topic" in response_lower:
                return False
            # Belirsizse, gÃ¼venli tarafta kal (off-topic deÄŸil kabul et)
            return False
            
    except Exception as e:
        print(f"âš ï¸ Off-topic kontrolÃ¼ sÄ±rasÄ±nda hata: {e}")
        # Hata durumunda gÃ¼venli tarafta kal (off-topic deÄŸil kabul et)
        return False


def clear_off_topic_cache():
    """Off-topic cache'ini temizle (test veya gÃ¼ncelleme iÃ§in)"""
    global _off_topic_cache
    _off_topic_cache.clear()


def is_help_or_support_query(query: str, use_cache: bool = True) -> bool:
    """
    LLM kullanarak sorgunun teknik destek/yardÄ±m sorusu olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
    Bu tÃ¼r sorular dosya taramasÄ± gerektirmez, direkt cevaplanabilir.
    
    Args:
        query: KullanÄ±cÄ±nÄ±n sorusu
        use_cache: Cache kullanÄ±lsÄ±n mÄ± (aynÄ± sorular iÃ§in tekrar LLM Ã§aÄŸrÄ±sÄ± yapÄ±lmasÄ±n)
    
    Returns:
        True eÄŸer sorgu teknik destek/yardÄ±m sorusu ise (dosya taramasÄ± gerektirmez)
        False eÄŸer sorgu normal iÃ§erik arama sorusu ise (dosya taramasÄ± gerekir)
    """
    if not query or not query.strip():
        return False
    
    # Cache kontrolÃ¼ (opsiyonel - performans iÃ§in)
    if use_cache:
        cache_key = query.lower().strip()
        cached_result = _help_query_cache.get(cache_key)
        if cached_result is not None:
            return cached_result
    
    try:
        # Ucuz model kullan (classification iÃ§in yeterli)
        llm = get_cheap_llm()
        
        prompt = f"""Sen bir Knowvex asistanÄ±sÄ±n. KullanÄ±cÄ±larÄ±n sorularÄ±nÄ± analiz edip, bu sorularÄ±n teknik destek/yardÄ±m sorusu olup olmadÄ±ÄŸÄ±nÄ± belirlemelisin.

TEKNÄ°K DESTEK/YARDIM SORULARI (DOSYA TARAMASI GEREKTÄ°RMEZ - DÄ°REKT CEVAPLANABÄ°LÄ°R):
- Platform kullanÄ±mÄ± ile ilgili sorular ("nasÄ±l kullanÄ±rÄ±m", "nasÄ±l yapÄ±lÄ±r", "kullanÄ±m kÄ±lavuzu")
- Sistem hakkÄ±nda sorular ("dosyalarÄ± kaybettim", "dosyalar nerede", "nasÄ±l arama yaparÄ±m")
- YardÄ±m istekleri ("yardÄ±m", "destek", "ne yapmalÄ±yÄ±m", "ne yapacaÄŸÄ±m")
- Platform Ã¶zellikleri hakkÄ±nda sorular ("hangi Ã¶zellikler var", "ne yapabilirim")
- Teknik sorunlar ("Ã§alÄ±ÅŸmÄ±yor", "hata alÄ±yorum", "bulamÄ±yorum")
- KullanÄ±m talimatlarÄ± ("nasÄ±l", "hangi adÄ±mlar", "yÃ¶ntem")
- Genel arama istekleri ("dosya aramak istiyorum", "arama yapmak istiyorum", "nasÄ±l arama yapabilirim", "arama nasÄ±l yapÄ±lÄ±r")
- Platform kullanÄ±mÄ± hakkÄ±nda genel sorular ("ne yapabilirim", "hangi Ã¶zellikler var", "nasÄ±l kullanÄ±rÄ±m")

NORMAL Ä°Ã‡ERÄ°K ARAMA SORULARI (DOSYA TARAMASI GEREKTÄ°RÄ°R):
- Belirli bir dosya, belge, rapor, proje arama ("X projesi", "Y raporu", "Z belgesi")
- Mail iÃ§erikleri arama ("bugÃ¼n kaÃ§ mail", "kritik mailler")
- Veri sorgulama ("hangi firmalar", "kaÃ§ kiÅŸi", "toplam")
- Ä°ÅŸ sÃ¼reÃ§leri, kurumsal bilgiler ("tedarikÃ§iler", "mÃ¼ÅŸteriler", "sÃ¶zleÅŸmeler")
- Belirli konu/konu arama ("X konusunda", "Y hakkÄ±nda")

KULLANICI SORUSU: "{query}"

GÃ–REV: Bu soru teknik destek/yardÄ±m sorusu mu yoksa normal iÃ§erik arama sorusu mu?

YANIT FORMATI: Sadece JSON formatÄ±nda yanÄ±t ver:
{{
    "is_help_query": true/false,
    "reason": "kÄ±sa aÃ§Ä±klama"
}}

Ã–RNEKLER:
- "DosyalarÄ± kaybettim ne yapacaÄŸÄ±m?" â†’ {{"is_help_query": true, "reason": "Teknik destek - dosya taramasÄ± gerektirmez"}}
- "NasÄ±l arama yaparÄ±m?" â†’ {{"is_help_query": true, "reason": "Platform kullanÄ±mÄ± - dosya taramasÄ± gerektirmez"}}
- "Dosya aramak istiyorum" â†’ {{"is_help_query": true, "reason": "Genel arama isteÄŸi - dosya taramasÄ± gerektirmez, kullanÄ±m talimatÄ± verilmeli"}}
- "Arama yapmak istiyorum" â†’ {{"is_help_query": true, "reason": "Genel arama isteÄŸi - dosya taramasÄ± gerektirmez, kullanÄ±m talimatÄ± verilmeli"}}
- "X projesi hakkÄ±nda bilgi ver" â†’ {{"is_help_query": false, "reason": "Ä°Ã§erik arama - dosya taramasÄ± gerekir"}}
- "BugÃ¼n kaÃ§ mail geldi?" â†’ {{"is_help_query": false, "reason": "Mail sorgusu - dosya taramasÄ± gerekir"}}
- "YardÄ±m istiyorum" â†’ {{"is_help_query": true, "reason": "YardÄ±m isteÄŸi - dosya taramasÄ± gerektirmez"}}
- "Kritik mailleri listele" â†’ {{"is_help_query": false, "reason": "Mail sorgusu - dosya taramasÄ± gerekir"}}
- "NasÄ±l kullanÄ±rÄ±m bu platformu?" â†’ {{"is_help_query": true, "reason": "KullanÄ±m sorusu - dosya taramasÄ± gerektirmez"}}

YANIT:"""

        response = llm.invoke(prompt)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # JSON'u parse et
        try:
            # JSON'u bul (```json ... ``` veya direkt JSON)
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                json_str = response_text[json_start:json_end].strip()
            elif "```" in response_text:
                json_start = response_text.find("```") + 3
                json_end = response_text.find("```", json_start)
                json_str = response_text[json_start:json_end].strip()
            else:
                json_str = response_text.strip()
            
            # Ä°lk { ve son } arasÄ±nÄ± al
            if "{" in json_str and "}" in json_str:
                json_start = json_str.find("{")
                json_end = json_str.rfind("}") + 1
                json_str = json_str[json_start:json_end]
            
            result = json.loads(json_str)
            is_help_query = result.get("is_help_query", False)
            reason = result.get("reason", "")
            
            print(f"ğŸ” YardÄ±m/destek kontrolÃ¼: '{query[:50]}...' â†’ {'YARDIM/DESTEK' if is_help_query else 'NORMAL ARAMA'} ({reason})")
            
            # Cache'e kaydet
            if use_cache:
                cache_key = query.lower().strip()
                _help_query_cache[cache_key] = is_help_query
            
            return is_help_query
            
        except json.JSONDecodeError as e:
            print(f"âš ï¸ LLM yanÄ±tÄ± JSON parse edilemedi: {e}")
            print(f"   Ham yanÄ±t: {response_text[:200]}")
            # Fallback: YanÄ±tta "true" veya "false" kelimesi var mÄ± kontrol et
            response_lower = response_text.lower()
            if "true" in response_lower and "is_help_query" in response_lower:
                return True
            elif "false" in response_lower and "is_help_query" in response_lower:
                return False
            # Belirsizse, gÃ¼venli tarafta kal (yardÄ±m sorusu deÄŸil kabul et)
            return False
            
    except Exception as e:
        print(f"âš ï¸ YardÄ±m/destek kontrolÃ¼ sÄ±rasÄ±nda hata: {e}")
        # Hata durumunda gÃ¼venli tarafta kal (yardÄ±m sorusu deÄŸil kabul et)
        return False


def get_help_response(query: str) -> str:
    """
    Teknik destek/yardÄ±m sorularÄ± iÃ§in uygun cevabÄ± oluÅŸturur.
    LLM kullanarak kullanÄ±cÄ±ya yardÄ±mcÄ± bir cevap Ã¼retir.
    """
    try:
        llm = get_cheap_llm()
        
        prompt = f"""Sen bir Knowvex asistanÄ±sÄ±n. KullanÄ±cÄ±ya Knowvex hakkÄ±nda yardÄ±mcÄ± bilgiler veriyorsun.

KULLANICI SORUSU: "{query}"

GÃ–REV: KullanÄ±cÄ±nÄ±n sorusuna yardÄ±mcÄ±, samimi ve bilgilendirici bir cevap ver. Knowvex Ã¶zelliklerini aÃ§Ä±kla ve kullanÄ±cÄ±ya rehberlik et.

Ã–NEMLÄ°: EÄŸer kullanÄ±cÄ± "dosya aramak istiyorum", "arama yapmak istiyorum" gibi genel bir arama isteÄŸi belirtiyorsa, ona NASIL arama yapacaÄŸÄ±nÄ± aÃ§Ä±kla. Ã–rnekler ver ve spesifik sorular sormasÄ±nÄ± Ã¶ner.

KNOWVEX Ã–ZELLÄ°KLERÄ°:
- Dosya ve belge arama: "X konusunu ara", "Y projesi hakkÄ±nda bilgi ver" gibi spesifik sorular sorabilirsiniz
- Mail yÃ¶netimi: "BugÃ¼n kaÃ§ mail geldi?", "Kritik mailleri listele" gibi mail sorgularÄ± yapabilirsiniz
- Veri analizi: "Hangi firmalar", "KaÃ§ kiÅŸi", "Toplam" gibi istatistiksel sorular sorabilirsiniz
- Belge Ã¶zetleme: "X raporunu Ã¶zetle", "Y belgesinin Ã¶zeti" gibi isteklerde bulunabilirsiniz

YANIT: KullanÄ±cÄ±ya yardÄ±mcÄ± olacak ÅŸekilde, samimi ve anlaÅŸÄ±lÄ±r bir dille cevap ver. Knowvex Ã¶zelliklerini Ã¶rneklerle aÃ§Ä±kla. EÄŸer kullanÄ±cÄ± genel bir arama isteÄŸi belirtiyorsa, ona spesifik sorular sormasÄ±nÄ± Ã¶ner."""

        response = llm.invoke(prompt)
        answer = response.content if hasattr(response, 'content') else str(response)
        
        return answer.strip()
        
    except Exception as e:
        print(f"âš ï¸ YardÄ±m cevabÄ± oluÅŸturulurken hata: {e}")
        # Fallback cevap - kullanÄ±cÄ±nÄ±n sorusuna gÃ¶re Ã¶zelleÅŸtirilmiÅŸ
        query_lower = query.lower() if query else ""
        if any(word in query_lower for word in ["dosya aramak", "arama yapmak", "arama istiyorum", "nasÄ±l arama"]):
            return """Knowvex'te dosya aramak iÃ§in spesifik sorular sorabilirsiniz:

**Ã–rnek arama sorularÄ±:**
â€¢ "X projesi hakkÄ±nda bilgi ver"
â€¢ "Y raporunu Ã¶zetle"
â€¢ "Z konusunu ara"
â€¢ "Fatura ile ilgili dosyalarÄ± bul"
â€¢ "SÃ¶zleÅŸme belgelerini listele"

**NasÄ±l arama yapÄ±lÄ±r:**
1. AradÄ±ÄŸÄ±nÄ±z konu, proje veya belge hakkÄ±nda spesifik bir soru sorun
2. Ã–rneÄŸin: "Fatura fiyatÄ± nedir?" yerine "X firmasÄ±na verilen fatura fiyatÄ± nedir?" gibi
3. Mail aramak iÃ§in: "BugÃ¼n kaÃ§ mail geldi?", "Kritik mailleri listele" gibi sorular sorabilirsiniz

**DiÄŸer Ã¶zellikler:**
â€¢ Mail yÃ¶netimi: "BugÃ¼n kaÃ§ mail geldi?", "Kritik mailleri listele"
â€¢ Veri analizi: "Hangi firmalar", "KaÃ§ kiÅŸi", "Toplam"
â€¢ Belge Ã¶zetleme: "X raporunu Ã¶zetle", "Y belgesinin Ã¶zeti"

Hangi konuda arama yapmak istiyorsunuz? Size yardÄ±mcÄ± olabilirim."""
        else:
            return """Knowvex'te ÅŸunlarÄ± yapabilirsiniz:

â€¢ **Dosya ve belge arama**: "X konusunu ara", "Y projesi hakkÄ±nda bilgi ver" gibi sorular sorabilirsiniz
â€¢ **Mail yÃ¶netimi**: "BugÃ¼n kaÃ§ mail geldi?", "Kritik mailleri listele" gibi mail sorgularÄ± yapabilirsiniz  
â€¢ **Veri analizi**: "Hangi firmalar", "KaÃ§ kiÅŸi", "Toplam" gibi istatistiksel sorular sorabilirsiniz
â€¢ **Belge Ã¶zetleme**: "X raporunu Ã¶zetle", "Y belgesinin Ã¶zeti" gibi isteklerde bulunabilirsiniz

DosyalarÄ±nÄ±zÄ± kaybetmiÅŸseniz, lÃ¼tfen sistem yÃ¶neticinizle iletiÅŸime geÃ§in. Knowvex iÃ§indeki dosyalarÄ± aramak iÃ§in "X dosyasÄ±nÄ± ara" veya "Y belgesini bul" gibi sorular sorabilirsiniz."""


def clear_help_query_cache():
    """YardÄ±m sorgusu cache'ini temizle (test veya gÃ¼ncelleme iÃ§in)"""
    global _help_query_cache
    _help_query_cache.clear()


def is_greeting_query(query: str, use_cache: bool = True) -> bool:
    """
    LLM kullanarak sorgunun selamlaÅŸma/hal hatÄ±r sorusu olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
    Bu tÃ¼r sorulara nazik bir ÅŸekilde cevap verilmelidir.
    
    Args:
        query: KullanÄ±cÄ±nÄ±n sorusu
        use_cache: Cache kullanÄ±lsÄ±n mÄ± (aynÄ± sorular iÃ§in tekrar LLM Ã§aÄŸrÄ±sÄ± yapÄ±lmasÄ±n)
    
    Returns:
        True eÄŸer sorgu selamlaÅŸma/hal hatÄ±r sorusu ise
        False eÄŸer sorgu baÅŸka bir tÃ¼r soru ise
    """
    if not query or not query.strip():
        return False
    
    # Cache kontrolÃ¼ (opsiyonel - performans iÃ§in)
    if use_cache:
        cache_key = query.lower().strip()
        cached_result = _greeting_cache.get(cache_key)
        if cached_result is not None:
            return cached_result
    
    try:
        # Ucuz model kullan (classification iÃ§in yeterli)
        llm = get_cheap_llm()
        
        prompt = f"""Sen bir Knowvex asistanÄ±sÄ±n. KullanÄ±cÄ±larÄ±n sorularÄ±nÄ± analiz edip, bu sorularÄ±n selamlaÅŸma/hal hatÄ±r sorusu olup olmadÄ±ÄŸÄ±nÄ± belirlemelisin.

SELAMLAÅMA/HAL HATIR SORULARI (NAZÄ°K CEVAP VERÄ°LMELÄ°):
- SelamlaÅŸma: "merhaba", "selam", "gÃ¼naydÄ±n", "iyi gÃ¼nler", "iyi akÅŸamlar", "iyi geceler"
- Hal hatÄ±r: "nasÄ±lsÄ±n", "nasÄ±lsÄ±nÄ±z", "nasÄ±lsÄ±n?", "nasÄ±lsÄ±nÄ±z?"
- KÄ±sa nezaket ifadeleri: "naber", "ne haber", "ne var ne yok"
- Sadece selamlaÅŸma iÃ§eren kÄ±sa mesajlar

DÄ°ÄER SORULAR (SELAMLAÅMA DEÄÄ°L):
- Ä°Ã§erik arama sorularÄ±: "X projesi", "Y raporu", "bugÃ¼n kaÃ§ mail"
- YardÄ±m sorularÄ±: "nasÄ±l kullanÄ±rÄ±m", "yardÄ±m", "destek"
- Off-topic sorular: "havalar nasÄ±l", "maÃ§ ne oldu", "spor"
- Teknik sorular: "dosyalarÄ± kaybettim", "hata alÄ±yorum"

KULLANICI SORUSU: "{query}"

GÃ–REV: Bu soru selamlaÅŸma/hal hatÄ±r sorusu mu?

YANIT FORMATI: Sadece JSON formatÄ±nda yanÄ±t ver:
{{
    "is_greeting": true/false,
    "reason": "kÄ±sa aÃ§Ä±klama"
}}

Ã–RNEKLER:
- "Merhaba" â†’ {{"is_greeting": true, "reason": "SelamlaÅŸma"}}
- "NasÄ±lsÄ±n?" â†’ {{"is_greeting": true, "reason": "Hal hatÄ±r sorusu"}}
- "GÃ¼naydÄ±n" â†’ {{"is_greeting": true, "reason": "SelamlaÅŸma"}}
- "Ä°yi gÃ¼nler" â†’ {{"is_greeting": true, "reason": "SelamlaÅŸma"}}
- "X projesi hakkÄ±nda bilgi ver" â†’ {{"is_greeting": false, "reason": "Ä°Ã§erik arama sorusu"}}
- "BugÃ¼n kaÃ§ mail geldi?" â†’ {{"is_greeting": false, "reason": "Mail sorgusu"}}
- "NasÄ±l kullanÄ±rÄ±m?" â†’ {{"is_greeting": false, "reason": "YardÄ±m sorusu"}}
- "Havalar nasÄ±l?" â†’ {{"is_greeting": false, "reason": "Off-topic soru"}}

YANIT:"""

        response = llm.invoke(prompt)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # JSON'u parse et
        try:
            # JSON'u bul (```json ... ``` veya direkt JSON)
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                json_str = response_text[json_start:json_end].strip()
            elif "```" in response_text:
                json_start = response_text.find("```") + 3
                json_end = response_text.find("```", json_start)
                json_str = response_text[json_start:json_end].strip()
            else:
                json_str = response_text.strip()
            
            # Ä°lk { ve son } arasÄ±nÄ± al
            if "{" in json_str and "}" in json_str:
                json_start = json_str.find("{")
                json_end = json_str.rfind("}") + 1
                json_str = json_str[json_start:json_end]
            
            result = json.loads(json_str)
            is_greeting = result.get("is_greeting", False)
            reason = result.get("reason", "")
            
            print(f"ğŸ‘‹ SelamlaÅŸma kontrolÃ¼: '{query[:50]}...' â†’ {'SELAMLAÅMA' if is_greeting else 'DÄ°ÄER'} ({reason})")
            
            # Cache'e kaydet
            if use_cache:
                cache_key = query.lower().strip()
                _greeting_cache[cache_key] = is_greeting
            
            return is_greeting
            
        except json.JSONDecodeError as e:
            print(f"âš ï¸ LLM yanÄ±tÄ± JSON parse edilemedi: {e}")
            print(f"   Ham yanÄ±t: {response_text[:200]}")
            # Fallback: YanÄ±tta "true" veya "false" kelimesi var mÄ± kontrol et
            response_lower = response_text.lower()
            if "true" in response_lower and "is_greeting" in response_lower:
                return True
            elif "false" in response_lower and "is_greeting" in response_lower:
                return False
            # Belirsizse, gÃ¼venli tarafta kal (selamlaÅŸma deÄŸil kabul et)
            return False
            
    except Exception as e:
        print(f"âš ï¸ SelamlaÅŸma kontrolÃ¼ sÄ±rasÄ±nda hata: {e}")
        # Hata durumunda gÃ¼venli tarafta kal (selamlaÅŸma deÄŸil kabul et)
        return False


def get_greeting_response(query: str) -> str:
    """
    SelamlaÅŸma/hal hatÄ±r sorularÄ± iÃ§in nazik bir cevap oluÅŸturur.
    """
    query_lower = query.lower().strip()
    
    # SelamlaÅŸma tÃ¼rÃ¼ne gÃ¶re uygun cevap
    if any(word in query_lower for word in ["gÃ¼naydÄ±n", "good morning", "morning"]):
        greeting = "GÃ¼naydÄ±n! ğŸ˜Š"
    elif any(word in query_lower for word in ["iyi akÅŸamlar", "good evening", "evening"]):
        greeting = "Ä°yi akÅŸamlar! ğŸ˜Š"
    elif any(word in query_lower for word in ["iyi geceler", "good night", "night"]):
        greeting = "Ä°yi geceler! ğŸ˜Š"
    elif any(word in query_lower for word in ["iyi gÃ¼nler", "good day", "have a nice day"]):
        greeting = "Ä°yi gÃ¼nler! ğŸ˜Š"
    elif any(word in query_lower for word in ["merhaba", "selam", "hello", "hi", "hey"]):
        greeting = "Merhaba! ğŸ˜Š"
    else:
        greeting = "Merhaba! ğŸ˜Š"
    
    # Hal hatÄ±r sorusu varsa
    if any(word in query_lower for word in ["nasÄ±lsÄ±n", "nasÄ±lsÄ±nÄ±z", "how are you", "how are"]):
        response = f"""{greeting} Ben iyiyim, teÅŸekkÃ¼r ederim! Size nasÄ±l yardÄ±mcÄ± olabilirim?

Knowvex'te ÅŸunlarÄ± yapabilirsiniz:
â€¢ Dosya ve belge arama: "X konusunu ara", "Y projesi hakkÄ±nda bilgi ver"
â€¢ Mail yÃ¶netimi: "BugÃ¼n kaÃ§ mail geldi?", "Kritik mailleri listele"
â€¢ Veri analizi: "Hangi firmalar", "KaÃ§ kiÅŸi", "Toplam"
â€¢ Belge Ã¶zetleme: "X raporunu Ã¶zetle", "Y belgesinin Ã¶zeti"

Size nasÄ±l yardÄ±mcÄ± olabilirim?"""
    else:
        response = f"""{greeting} Size nasÄ±l yardÄ±mcÄ± olabilirim?

Knowvex'te ÅŸunlarÄ± yapabilirsiniz:
â€¢ Dosya ve belge arama: "X konusunu ara", "Y projesi hakkÄ±nda bilgi ver"
â€¢ Mail yÃ¶netimi: "BugÃ¼n kaÃ§ mail geldi?", "Kritik mailleri listele"
â€¢ Veri analizi: "Hangi firmalar", "KaÃ§ kiÅŸi", "Toplam"
â€¢ Belge Ã¶zetleme: "X raporunu Ã¶zetle", "Y belgesinin Ã¶zeti"

Hangi konuda yardÄ±ma ihtiyacÄ±nÄ±z var?"""
    
    return response


def clear_greeting_cache():
    """SelamlaÅŸma cache'ini temizle (test veya gÃ¼ncelleme iÃ§in)"""
    global _greeting_cache
    _greeting_cache.clear()

