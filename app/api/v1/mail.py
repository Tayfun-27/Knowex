# backend/app/api/v1/mail.py - GÃœNCELLENDÄ° (SSE ve RAM Optimizasyonlu)

from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File, Form
# --- YENÄ° Ä°MPORTLAR ---
from fastapi.responses import StreamingResponse
import asyncio
import json
# --- YENÄ° Ä°MPORTLAR BÄ°TTÄ° ---
from pydantic import BaseModel
from typing import Optional, List, Dict, Any, Tuple
from collections import Counter
from datetime import datetime, timedelta, timezone
from app.schemas.user import UserInDB
from app.dependencies import get_current_user, get_db_repository, get_storage_adapter
from app.repositories.base import BaseRepository
from app.storage_adapters.base import BaseStorageAdapter
from app.services.llm_providers import get_llm_for_model
from app.services import vector_service
from app.services.chat_helpers import is_off_topic_query, is_help_or_support_query, get_help_response, is_greeting_query, get_greeting_response
from app.core.config import GEMINI_API_KEY
from app.core import parsers
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from google.cloud import firestore
from google.cloud.firestore_v1.base_query import FieldFilter
import uuid
import imaplib
import time
import io
import mimetypes

router = APIRouter()

# UTC+3 (TÃ¼rkiye saati) iÃ§in timezone helper fonksiyonlarÄ±
TURKEY_TIMEZONE = timezone(timedelta(hours=3))

def get_today_start_utc3() -> datetime:
    """UTC+3 (TÃ¼rkiye saati) iÃ§in bugÃ¼nÃ¼n baÅŸlangÄ±cÄ±nÄ± dÃ¶ndÃ¼rÃ¼r (00:00:00 UTC+3)."""
    now_utc3 = datetime.now(TURKEY_TIMEZONE)
    today_start_utc3 = datetime(now_utc3.year, now_utc3.month, now_utc3.day, tzinfo=TURKEY_TIMEZONE)
    # UTC'ye Ã§evir (Firestore UTC kullanÄ±r)
    return today_start_utc3.astimezone(timezone.utc).replace(tzinfo=None)

def get_now_utc3() -> datetime:
    """UTC+3 (TÃ¼rkiye saati) iÃ§in ÅŸu anki zamanÄ± UTC olarak dÃ¶ndÃ¼rÃ¼r."""
    now_utc3 = datetime.now(TURKEY_TIMEZONE)
    return now_utc3.astimezone(timezone.utc).replace(tzinfo=None)

# --- Åemalar (DeÄŸiÅŸiklik yok) ---
class MailSummary(BaseModel):
    id: str
    tenant_id: str
    sender: str
    subject: str
    body: Optional[str] = None  # Process-in-RAM: body=None, fetch on-demand
    has_full_content: bool = False  # Indicates if body needs to be fetched from IMAP
    summary: str
    is_critical: bool = False
    is_answered: bool = False
    attachments: List[str] = []
    attachment_summaries: Dict[str, str] = {}  # {filename: summary}
    potential_tasks: List[str] = []
    critical_dates: Dict[str, Any] = {}
    created_at: datetime
    received_at: datetime

class MailCreate(BaseModel):
    sender: str
    subject: str
    body: str
    received_at: Optional[datetime] = None

class MailQueryRequest(BaseModel):
    query: str
    date_range: Optional[str] = None  # "daily", "weekly", "custom"
    start_date: Optional[datetime] = None
    end_date: Optional[datetime] = None

class MailStats(BaseModel):
    total_mails: int
    critical_mails: int
    unanswered_mails: int
    unread_mails: int  # OkunmamÄ±ÅŸ mail sayÄ±sÄ±

# --- Servis FonksiyonlarÄ± (DeÄŸiÅŸiklik yok) ---
# ... (process_thread_with_llm, process_mail_with_llm, 
#      process_attachment_with_llm, save_mail_attachments fonksiyonlarÄ±
#      hiÃ§bir deÄŸiÅŸiklik olmadan buraya gelecek) ...

def get_mail_collection(db: firestore.Client):
    return db.collection("mails")

def process_thread_with_llm(thread_mails: List[Dict[str, Any]], model_name: str = "gemini") -> Dict[str, Any]:
    """Bir mailleÅŸme zincirini (thread) Ã¶zetler. TÃ¼m mailleri kronolojik sÄ±raya gÃ¶re birleÅŸtirip Ã¶zetler."""
    if not thread_mails or len(thread_mails) == 0:
        return {"summary": "", "is_critical": False, "potential_tasks": [], "critical_dates": {}}
    
    # Tek mail ise normal iÅŸleme yap
    if len(thread_mails) == 1:
        mail = thread_mails[0]
        # Process-in-RAM: body might be None, use summary instead for LLM
        mail_body = mail.get("body") or mail.get("summary", "")
        return process_mail_with_llm(
            mail_body,
            mail.get("subject", ""),
            mail.get("sender", ""),
            mail.get("attachment_summaries"),
            model_name
        )
    
    # TÃ¼m mailleri kronolojik sÄ±raya gÃ¶re birleÅŸtir
    sorted_mails = sorted(thread_mails, key=lambda x: x.get("received_at", datetime.now()))
    
    # Thread iÃ§eriÄŸini oluÅŸtur
    thread_content = ""
    all_attachment_summaries = {}
    for idx, mail in enumerate(sorted_mails):
        received_at = mail.get("received_at", datetime.now())
        if isinstance(received_at, str):
            try:
                received_at = datetime.fromisoformat(received_at.replace('Z', '+00:00'))
            except:
                received_at = datetime.now()
        date_str = received_at.strftime("%Y-%m-%d %H:%M")
        
        # Process-in-RAM: body might be None, use summary instead
        mail_body = mail.get('body') or mail.get('summary', 'Ä°Ã§erik mevcut deÄŸil (on-demand fetch gerekli)')
        
        thread_content += f"\n\n--- Mail {idx + 1} ({date_str}) ---\n"
        thread_content += f"GÃ¶nderen: {mail.get('sender', 'Bilinmiyor')}\n"
        thread_content += f"Konu: {mail.get('subject', 'Konu yok')}\n"
        thread_content += f"Ä°Ã§erik:\n{mail_body}\n"
        
        # Attachment Ã¶zetlerini birleÅŸtir
        mail_attachments = mail.get("attachment_summaries", {})
        if mail_attachments:
            for filename, summary in mail_attachments.items():
                all_attachment_summaries[f"{date_str}_{filename}"] = summary
    
    # LLM ile thread'i Ã¶zetle
    llm = get_llm_for_model(model_name)
    
    attachment_text = ""
    if all_attachment_summaries:
        attachment_text = "\n\nEk Ã–zetleri:\n"
        for filename, summary in all_attachment_summaries.items():
            attachment_text += f"- {filename}: {summary}\n"
    
    # Ä°lk mailin subject'ini kullan (thread subject'i)
    thread_subject = sorted_mails[0].get("subject", "")
    # Re:, Fwd: gibi Ã¶nekleri temizle
    while thread_subject.lower().startswith(('re:', 'fwd:', 'fw:')):
        if thread_subject.lower().startswith('re:'):
            thread_subject = thread_subject[3:].strip()
        elif thread_subject.lower().startswith('fwd:'):
            thread_subject = thread_subject[4:].strip()
        elif thread_subject.lower().startswith('fw:'):
            thread_subject = thread_subject[3:].strip()
    
    prompt = f"""AÅŸaÄŸÄ±daki mailleÅŸme zincirini (thread) analiz et ve JSON formatÄ±nda yanÄ±t ver.
Bu bir mailleÅŸme zinciridir, yani birden fazla mail birbiriyle ilgili ve bir konuÅŸma oluÅŸturuyor.
TÃ¼m mail geÃ§miÅŸini dikkate alarak, konuÅŸmanÄ±n tamamÄ±nÄ± Ã¶zetle ve gÃ¶revleri Ã§Ä±kar.

CevaplarÄ±nÄ±zÄ± mÃ¼mkÃ¼n olduÄŸunca kÄ±sa, Ã¶z ve net tutun. Gereksiz aÃ§Ä±klamalardan kaÃ§Ä±nÄ±n.

{{
  "summary": "TÃ¼m mailleÅŸme zincirinin kÄ±sa Ã¶zeti (max 150 kelime). KonuÅŸmanÄ±n baÅŸlangÄ±cÄ±ndan sonuna kadar ne konuÅŸuldu, hangi kararlar alÄ±ndÄ±, hangi sorunlar Ã§Ã¶zÃ¼ldÃ¼?",
  "is_critical": true/false,
  "potential_tasks": ["gÃ¶rev1", "gÃ¶rev2"],
  "critical_dates": {{"contract_renewal": "tarih", "delivery": "tarih", "meeting": "tarih", "deadline": "tarih"}}
}}

MailleÅŸme Zinciri (Kronolojik SÄ±ra):
Konu: {thread_subject}
{thread_content[:4000]}{attachment_text}"""
    
    try:
        response = llm.invoke(prompt)
        content = response.content if hasattr(response, 'content') else str(response)
        # JSON parse
        json_start = content.find('{')
        json_end = content.rfind('}') + 1
        if json_start >= 0 and json_end > json_start:
            result = json.loads(content[json_start:json_end])
        else:
            # Fallback: Ä°lk mailin Ã¶zetini kullan
            result = process_mail_with_llm(
                sorted_mails[0].get("body", ""),
                thread_subject,
                sorted_mails[0].get("sender", ""),
                sorted_mails[0].get("attachment_summaries"),
                model_name
            )
    except Exception as e:
        print(f"âš ï¸ Thread Ã¶zetleme hatasÄ±: {e}")
        # Fallback: Ä°lk mailin Ã¶zetini kullan
        result = process_mail_with_llm(
            sorted_mails[0].get("body", ""),
            thread_subject,
            sorted_mails[0].get("sender", ""),
            sorted_mails[0].get("attachment_summaries"),
            model_name
        )
    
    return result

def process_mail_with_llm(mail_body: str, subject: str, sender: str, attachment_summaries: Dict[str, str] = None, model_name: str = "gemini") -> Dict[str, Any]:
    """Mail iÃ§eriÄŸini LLM ile iÅŸleyerek Ã¶zet, gÃ¶revler ve kritik tarihleri Ã§Ä±karÄ±r."""
    llm = get_llm_for_model(model_name)
    
    attachment_text = ""
    if attachment_summaries:
        attachment_text = "\n\nEk Ã–zetleri:\n"
        for filename, summary in attachment_summaries.items():
            attachment_text += f"- {filename}: {summary}\n"
    
    prompt = f"""AÅŸaÄŸÄ±daki maili analiz et ve JSON formatÄ±nda yanÄ±t ver:

CevaplarÄ±nÄ±zÄ± mÃ¼mkÃ¼n olduÄŸunca kÄ±sa, Ã¶z ve net tutun. Gereksiz aÃ§Ä±klamalardan kaÃ§Ä±nÄ±n.

{{
  "summary": "Mailin kÄ±sa Ã¶zeti (max 100 kelime)",
  "is_critical": true/false,
  "potential_tasks": ["gÃ¶rev1", "gÃ¶rev2"],
  "critical_dates": {{"contract_renewal": "tarih", "delivery": "tarih", "meeting": "tarih", "deadline": "tarih"}}
}}

Ã–NEMLÄ°: critical_dates iÃ§in tarihleri YYYY-MM-DD formatÄ±nda ver (Ã¶rn: "2024-12-25"). 
EÄŸer tam tarih belirtilmemiÅŸse ve sadece "yarÄ±n", "gelecek hafta" gibi ifadeler varsa, bugÃ¼nÃ¼n tarihi {datetime.now().strftime('%Y-%m-%d')} olduÄŸunu dikkate alarak hesapla ve YYYY-MM-DD formatÄ±nda yaz.
EÄŸer hiÃ§ tarih bilgisi yoksa o alanÄ± boÅŸ bÄ±rak.

Mail:
GÃ¶nderen: {sender}
Konu: {subject}
Ä°Ã§erik: {mail_body[:2000]}{attachment_text}"""
    
    try:
        response = llm.invoke(prompt)
        content = response.content if hasattr(response, 'content') else str(response)
        # JSON parse
        json_start = content.find('{')
        json_end = content.rfind('}') + 1
        if json_start >= 0 and json_end > json_start:
            result = json.loads(content[json_start:json_end])
        else:
            result = {"summary": content[:200], "is_critical": False, "potential_tasks": [], "critical_dates": {}}
    except:
        result = {"summary": f"{subject} - {mail_body[:200]}", "is_critical": False, "potential_tasks": [], "critical_dates": {}}
    
    return result

def process_attachment_with_llm(attachment_content: str, filename: str, model_name: str = "gemini") -> tuple[str, List[Dict[str, Any]]]:
    """Ek iÃ§eriÄŸini LLM ile Ã¶zetler. Fiyat, tarih ve Ã¶nemli bilgileri iÃ§erir. Tablo verilerini de dÃ¶ndÃ¼rÃ¼r."""
    if not attachment_content or len(attachment_content.strip()) < 10:
        print(f"âš ï¸ Ek iÃ§eriÄŸi Ã§ok kÄ±sa: {filename} - {len(attachment_content) if attachment_content else 0} karakter")
        return "Ek iÃ§eriÄŸi okunamadÄ± veya Ã§ok kÄ±sa.", []
    
    print(f"ğŸ¤– LLM ile ek Ã¶zeti oluÅŸturuluyor: {filename} ({len(attachment_content)} karakter)")
    print(f"ğŸ“„ Ä°Ã§erik Ã¶nizleme (ilk 500 karakter): {attachment_content[:500]}")
    
    llm = get_llm_for_model(model_name)
    
    # Daha fazla iÃ§erik oku (fiyat ve detaylar iÃ§in) - PDF'ler iÃ§in daha fazla karakter
    # TÃ¼m iÃ§eriÄŸi analiz et (limit artÄ±rÄ±ldÄ±)
    content_to_analyze = attachment_content[:15000] if len(attachment_content) > 10000 else attachment_content
    
    prompt = f"""AÅŸaÄŸÄ±daki ek dosyasÄ±nÄ±n ({filename}) detaylÄ± Ã¶zetini Ã§Ä±kar ve JSON formatÄ±nda yanÄ±t ver.

CevaplarÄ±nÄ±zÄ± mÃ¼mkÃ¼n olduÄŸunca kÄ±sa, Ã¶z ve net tutun. Gereksiz aÃ§Ä±klamalardan kaÃ§Ä±nÄ±n.

JSON formatÄ±:
{{
  "summary": "DoÄŸal, akÄ±cÄ± bir metin Ã¶zeti. ÃœrÃ¼n isimleri, miktarlar, fiyatlar, tarihler ve diÄŸer Ã¶nemli bilgileri iÃ§erir.",
  "table_data": [
    {{
      "Ã¼rÃ¼n": "ÃœrÃ¼n adÄ±",
      "miktar": "Miktar ve birim (Ã¶rn: 100 kg)",
      "birim_fiyat": "Birim fiyat (Ã¶rn: 50 TL)",
      "toplam": "Toplam tutar (Ã¶rn: 5000 TL)"
    }}
  ]
}}

Ã–NEMLÄ°:
- EÄŸer dosyada tablo verileri varsa (Ã¼rÃ¼n listesi, fiyat listesi vb.), bunlarÄ± table_data array'ine ekle
- Her satÄ±r iÃ§in Ã¼rÃ¼n, miktar, birim_fiyat ve toplam bilgilerini dahil et
- EÄŸer tablo verisi yoksa, table_data boÅŸ array [] olsun
- summary'de tÃ¼m Ã¶nemli bilgileri (tarihler, koÅŸullar, notlar vb.) doÄŸal bir ÅŸekilde anlat
- SayÄ±larÄ±, fiyatlarÄ± ve tarihleri aÃ§Ä±kÃ§a belirt

Dosya iÃ§eriÄŸi:
{content_to_analyze}"""
    
    try:
        response = llm.invoke(prompt)
        result_text = response.content if hasattr(response, 'content') else str(response)
        
        # JSON'u parse et
        import json
        try:
            # JSON'u bul (```json ... ``` veya direkt JSON)
            if "```json" in result_text:
                json_start = result_text.find("```json") + 7
                json_end = result_text.find("```", json_start)
                json_str = result_text[json_start:json_end].strip()
            elif "```" in result_text:
                json_start = result_text.find("```") + 3
                json_end = result_text.find("```", json_start)
                json_str = result_text[json_start:json_end].strip()
            else:
                # Direkt JSON olabilir
                json_str = result_text.strip()
            
            # Ä°lk { ve son } arasÄ±nÄ± al
            if "{" in json_str and "}" in json_str:
                json_start = json_str.find("{")
                json_end = json_str.rfind("}") + 1
                json_str = json_str[json_start:json_end]
            
            result = json.loads(json_str)
            summary = result.get("summary", result_text[:1000])
            table_data = result.get("table_data", [])
            
            print(f"âœ… LLM Ã¶zeti oluÅŸturuldu: {filename} - {len(summary)} karakter")
            print(f"ğŸ“Š Tablo verisi: {len(table_data)} satÄ±r")
            if table_data:
                print(f"ğŸ“„ Tablo Ã¶nizleme: {table_data[0] if table_data else 'Yok'}")
            
            return summary[:1000].strip(), table_data
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON parse hatasÄ±, sadece metin Ã¶zeti kullanÄ±lÄ±yor: {e}")
            print(f"   Ham yanÄ±t: {result_text[:500]}")
            return result_text[:1000].strip(), []
    except Exception as e:
        print(f"âŒ LLM Ã¶zeti oluÅŸturma hatasÄ±: {filename} - {str(e)}")
        import traceback
        print(traceback.format_exc())
        return f"Ek Ã¶zeti oluÅŸturulamadÄ±: {str(e)}", []

async def save_mail_attachments(attachments: List[UploadFile], tenant_id: str, mail_id: str, storage: BaseStorageAdapter) -> List[str]:
    """Mail eklerini kaydeder ve storage path'lerini dÃ¶ndÃ¼rÃ¼r."""
    saved_paths = []
    for att in attachments:
        unique_name = f"{uuid.uuid4()}_{att.filename}"
        path = storage.upload_file(att.file, tenant_id, f"mail_attachments/{mail_id}/{unique_name}")
        saved_paths.append(path)
    return saved_paths


# --- API Endpoint'leri ---

# --- BELLEK OPTÄ°MÄ°ZASYONU SABÄ°TLERÄ° ---
MAX_ATTACHMENT_SIZE = 10 * 1024 * 1024  # 10MB limit - daha bÃ¼yÃ¼k attachment'lar atlanacak
MAX_ATTACHMENT_SIZE_FOR_PROCESSING = 5 * 1024 * 1024  # 5MB - daha bÃ¼yÃ¼k attachment'lar sadece kaydedilecek, LLM iÅŸleme yapÄ±lmayacak
MAX_MAILS_PER_BATCH = 50  # Her 50 mail'de bir bellek temizliÄŸi yapÄ±lacak

# --- GÃœNCELLEME BURADA: /fetch endpoint'i SSE kullanacak ÅŸekilde deÄŸiÅŸtirildi ---
@router.post("/fetch")
async def fetch_and_process_mails(
    limit: int = 1000,  # TÃ¼m mailleri Ã§ekmek iÃ§in yÃ¼ksek limit
    since_date: Optional[str] = None,  # Tarih filtresi (YYYY-MM-DD formatÄ±nda)
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository),
    storage: BaseStorageAdapter = Depends(get_storage_adapter)
):
    """IMAP'ten mailleri Ã§eker ve iÅŸler (SSE ile anlÄ±k akÄ±ÅŸ saÄŸlar)."""
    
    # --- YENÄ°: Asenkron Generator Fonksiyonu ---
    # TÃ¼m mail Ã§ekme mantÄ±ÄŸÄ± bu fonksiyonun iÃ§inde Ã§alÄ±ÅŸacak
    # ve her adÄ±mÄ± 'yield' ile dÄ±ÅŸarÄ±ya (frontend'e) gÃ¶nderecek.
    async def event_stream_generator():
        from app.services.mail_service import fetch_mails
        
        # Sadece admin mail Ã§ekebilir
        if current_user.role != "Admin":
            error_data = {"step": 0, "message": "Sadece admin kullanÄ±cÄ±lar mail Ã§ekebilir.", "status": "error"}
            yield f"data: {json.dumps(error_data)}\n\n"
            return
        
        firestore_db = firestore.Client()
        settings_doc = firestore_db.collection("mail_settings").document(current_user.tenant_id).get()
        if not settings_doc.exists:
            error_data = {"step": 0, "message": "Mail ayarlarÄ± bulunamadÄ±.", "status": "error"}
            yield f"data: {json.dumps(error_data)}\n\n"
            return
        
        settings = settings_doc.to_dict()
        email_address = settings.get("email_address", "")
        password = settings.get("password", "")
        imap_server = settings.get("imap_server", "")
        imap_port = settings.get("imap_port", 993)
        fetch_unread_only_setting = settings.get("fetch_unread_only", True)
        
        print(f"ğŸ” Firestore'dan alÄ±nan fetch_unread_only deÄŸeri: {fetch_unread_only_setting} (tip: {type(fetch_unread_only_setting).__name__})")
        
        if isinstance(fetch_unread_only_setting, bool):
            fetch_unread_only = fetch_unread_only_setting
        elif isinstance(fetch_unread_only_setting, str):
            fetch_unread_only = fetch_unread_only_setting.lower() in ['true', '1', 'yes']
        elif fetch_unread_only_setting is None:
            fetch_unread_only = True
        else:
            fetch_unread_only = bool(fetch_unread_only_setting)
        
        print(f"ğŸ“§ Mail Ã§ekme modu: {'Sadece okunmamÄ±ÅŸ' if fetch_unread_only else 'TÃ¼m mailler'} (fetch_unread_only={fetch_unread_only})")
        
        # KullanÄ±cÄ±ya bilgi ver
        step_data = {"step": 0.5, "message": f"ğŸ“§ Mail Ã§ekme modu: {'Sadece okunmamÄ±ÅŸ mailler' if fetch_unread_only else 'TÃ¼m mailler (okunmuÅŸ + okunmamÄ±ÅŸ)'}", "status": "info"}
        yield f"data: {json.dumps(step_data)}\n\n"
        await asyncio.sleep(0.01)
        
        if not email_address or not password:
            error_data = {"step": 0, "message": "Mail ayarlarÄ± eksik.", "status": "error"}
            yield f"data: {json.dumps(error_data)}\n\n"
            return
        
        # 'steps' listesi kaldÄ±rÄ±ldÄ±, artÄ±k her adÄ±mda 'yield' kullanÄ±lacak.
        try:
            step_data = {"step": 1, "message": "IMAP sunucusuna baÄŸlanÄ±lÄ±yor...", "status": "info"}
            yield f"data: {json.dumps(step_data)}\n\n"
            await asyncio.sleep(0.01) # Event loop'a nefes aldÄ±r
            
            since_datetime = None
            if since_date:
                try:
                    since_datetime = datetime.strptime(since_date, "%Y-%m-%d")
                    step_data = {"step": 1.5, "message": f"ğŸ“… Tarih filtresi: {since_date} tarihinden itibaren mailler Ã§ekilecek...", "status": "info"}
                    yield f"data: {json.dumps(step_data)}\n\n"
                    await asyncio.sleep(0.01)
                except ValueError:
                    step_data = {"step": 1.5, "message": f"âš ï¸ GeÃ§ersiz tarih formatÄ±: {since_date}, tÃ¼m mailler Ã§ekilecek", "status": "warning"}
                    yield f"data: {json.dumps(step_data)}\n\n"
                    await asyncio.sleep(0.01)
            
            fetched_mails_generator = fetch_mails(email_address, password, imap_server, imap_port, limit, fetch_unread_only, since_datetime)
            
            step_data = {"step": 2, "message": "Mail listesi alÄ±ndÄ±, iÅŸleme baÅŸlanÄ±yor...", "status": "info"}
            yield f"data: {json.dumps(step_data)}\n\n"
            await asyncio.sleep(0.01)
            
            processed_count = 0
            skipped_count = 0
            errors = []
            mail_col = get_mail_collection(firestore_db)
            total_start_time = time.time()
            mail_processing_times = []
            total_fetched = 0
            processed_in_batch = 0  # Batch sayacÄ±
            
            print(f"ğŸ“¬ Mail iÅŸleme dÃ¶ngÃ¼sÃ¼ baÅŸlÄ±yor...")
            for mail_data in fetched_mails_generator:
                total_fetched += 1
                mail_start_time = time.time()
                try:
                    message_id = mail_data.get("message_id", "")
                    email_id = mail_data.get("email_id", "")
                    in_reply_to = mail_data.get("in_reply_to", "")
                    
                    thread_id = message_id
                    if in_reply_to:
                        parent_query = (
                            mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
                            .where(filter=FieldFilter("message_id", "==", in_reply_to))
                            .limit(1)
                        )
                        parent_docs = list(parent_query.stream())
                        if parent_docs:
                            parent_data = parent_docs[0].to_dict()
                            thread_id = parent_data.get("thread_id") or parent_data.get("message_id") or in_reply_to
                            print(f"ğŸ”— Mail thread'e eklendi (parent: {in_reply_to}, thread_id: {thread_id})")
                        else:
                            thread_id = in_reply_to
                            print(f"ğŸ”— Parent mail henÃ¼z kaydedilmemiÅŸ, thread_id: {thread_id}")
                    
                    if message_id:
                        existing_query = (
                            mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
                            .where(filter=FieldFilter("message_id", "==", message_id))
                            .limit(1)
                        )
                        existing_docs = list(existing_query.stream())
                        if existing_docs:
                            skipped_count += 1
                            mail_processing_times.append(time.time() - mail_start_time)
                            subject_short = mail_data.get('subject', 'Bilinmiyor')[:50]
                            step_data = {"step": 3 + processed_count + skipped_count, "message": f"â­ï¸ AtlandÄ± (zaten iÅŸlenmiÅŸ): {subject_short}...", "status": "skip"}
                            yield f"data: {json.dumps(step_data)}\n\n"
                            await asyncio.sleep(0.01)
                            print(f"â­ï¸ Mail zaten iÅŸlenmiÅŸ (Message-ID: {message_id}), atlandÄ±: {mail_data.get('subject', 'Bilinmiyor')}")
                            continue
                    
                    if not message_id or message_id.startswith("imap_uid_"):
                        if email_id:
                            existing_query = (
                                mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
                                .where(filter=FieldFilter("email_id", "==", email_id))
                                .limit(1)
                            )
                            existing_docs = list(existing_query.stream())
                            if existing_docs:
                                skipped_count += 1
                                mail_processing_times.append(time.time() - mail_start_time)
                                subject_short = mail_data.get('subject', 'Bilinmiyor')[:50]
                                step_data = {"step": 3 + processed_count + skipped_count, "message": f"â­ï¸ AtlandÄ± (zaten iÅŸlenmiÅŸ): {subject_short}...", "status": "skip"}
                                yield f"data: {json.dumps(step_data)}\n\n"
                                await asyncio.sleep(0.01)
                                print(f"â­ï¸ Mail zaten iÅŸlenmiÅŸ (IMAP UID: {email_id}), atlandÄ±: {mail_data.get('subject', 'Bilinmiyor')}")
                                continue
                    
                    doc_ref = mail_col.document()
                    mail_id = doc_ref.id
                    
                    subject_short = mail_data.get('subject', 'Bilinmiyor')[:50]
                    current_step = 3 + processed_count + skipped_count + 1
                    
                    step_data = {"step": current_step, "message": f"ğŸ“§ Ä°ÅŸleniyor (Mail {processed_count + skipped_count + 1}): {subject_short}...", "status": "processing"}
                    yield f"data: {json.dumps(step_data)}\n\n"
                    await asyncio.sleep(0.01) # AkÄ±ÅŸ iÃ§in bekle
                    
                    # --- Process-in-RAM: Ekleri RAM'de iÅŸle, dosyayÄ± kaydetme ---
                    attachment_summaries = {}
                    attachment_tables = {}
                    saved_attachment_filenames = []  # Sadece dosya adlarÄ± (path deÄŸil)
                    attachment_count = len(mail_data.get("attachments", []))
                    
                    if attachment_count > 0:
                        step_data = {"step": current_step + 0.1, "message": f"   ğŸ“ {attachment_count} ek dosyasÄ± bulundu, RAM'de iÅŸleniyor...", "status": "info"}
                        yield f"data: {json.dumps(step_data)}\n\n"
                        await asyncio.sleep(0.01)
                        
                        # --- HAFIZA OPTÄ°MÄ°ZASYONU: KOPYA LÄ°STE ---
                        attachments_to_process = list(mail_data.get("attachments", []))

                        for att in attachments_to_process:
                            filename = att.get("filename", "")
                            payload = att.get("payload")  # payload'u al
                            content_type = att.get("content_type", "")
                            
                            # BOYUT KONTROLÃœ - Ã‡ok bÃ¼yÃ¼k attachment'larÄ± atla (>10MB)
                            if payload and len(payload) > MAX_ATTACHMENT_SIZE:
                                step_data = {"step": current_step + 0.2, "message": f"   âš ï¸ Ek Ã§ok bÃ¼yÃ¼k, atlanÄ±yor: {filename} ({len(payload) / 1024 / 1024:.1f}MB > 10MB)", "status": "warning"}
                                yield f"data: {json.dumps(step_data)}\n\n"
                                await asyncio.sleep(0.01)
                                # Payload'Ä± hemen temizle
                                if 'payload' in att:
                                    att['payload'] = None
                                    del att['payload']
                                del payload
                                import gc
                                gc.collect()
                                continue
                            
                            if payload and filename:
                                try:
                                    payload_size = len(payload) if payload else 0
                                    print(f"ğŸ“ Ek RAM'de iÅŸleniyor: {filename} (tip: {content_type}, boyut: {payload_size / 1024 / 1024:.2f}MB)")
                                    
                                    # Process-in-RAM: DosyayÄ± kaydetme, direkt RAM'de iÅŸle
                                    # Sadece kÃ¼Ã§Ã¼k attachment'lar iÃ§in iÅŸleme yap (5MB limit)
                                    if payload_size <= MAX_ATTACHMENT_SIZE_FOR_PROCESSING:
                                        # Truncate very large text before extraction to avoid OOM
                                        if payload_size > 5 * 1024 * 1024:  # 5MB
                                            payload = payload[:5 * 1024 * 1024]
                                            print(f"âš ï¸ Ek 5MB'den bÃ¼yÃ¼k, ilk 5MB iÅŸlenecek: {filename}")
                                        
                                        # Extract text from bytes immediately (in RAM)
                                        attachment_text = parsers.extract_text_from_file(
                                            file_bytes=payload,
                                            file_name=filename,
                                            mime_type=content_type
                                        )
                                        print(f"ğŸ“„ Ek iÃ§eriÄŸi Ã§Ä±karÄ±ldÄ±: {len(attachment_text) if attachment_text else 0} karakter")
                                        
                                        # Immediately discard payload to free RAM
                                        del payload
                                        import gc
                                        gc.collect()
                                        
                                        if attachment_text and len(attachment_text.strip()) > 10 and not attachment_text.strip().startswith("["):
                                            step_data = {"step": current_step + 0.2, "message": f"   ğŸ¤– Ek Ã¶zeti oluÅŸturuluyor: {filename}...", "status": "info"}
                                            yield f"data: {json.dumps(step_data)}\n\n"
                                            await asyncio.sleep(0.01)
                                            
                                            # Process attachment with LLM to get summary
                                            att_summary, att_table = process_attachment_with_llm(attachment_text, filename)
                                            attachment_summaries[filename] = att_summary
                                            if att_table:
                                                attachment_tables[filename] = att_table
                                            
                                            step_data = {"step": current_step + 0.3, "message": f"   âœ… Ek Ã¶zeti oluÅŸturuldu: {filename}", "status": "success"}
                                            yield f"data: {json.dumps(step_data)}\n\n"
                                            await asyncio.sleep(0.01)
                                            print(f"âœ… Ek Ã¶zeti oluÅŸturuldu: {filename} - {att_summary[:100]}")
                                            
                                            # Attachment text'i temizle
                                            del attachment_text
                                            import gc
                                            gc.collect()
                                        else:
                                            error_msg = f"Ek iÃ§eriÄŸi okunamadÄ± veya Ã§ok kÄ±sa: {filename}"
                                            print(f"âš ï¸ {error_msg}")
                                            step_data = {"step": current_step + 0.2, "message": f"   âš ï¸ Ek iÃ§eriÄŸi okunamadÄ±: {filename}", "status": "warning"}
                                            yield f"data: {json.dumps(step_data)}\n\n"
                                            await asyncio.sleep(0.01)
                                    
                                    # Dosya adÄ±nÄ± kaydet (path deÄŸil, sadece filename)
                                    saved_attachment_filenames.append(filename)
                                    
                                    # --- HAFIZA TEMÄ°ZLEME (Kritik) - Daha agresif ---
                                    if 'payload' in att:
                                        att['payload'] = None
                                        del att['payload']
                                    if 'payload' in locals():
                                        del payload
                                    import gc
                                    gc.collect()
                                    # --- TEMÄ°ZLEME BÄ°TTÄ° ---

                                except Exception as e:
                                    print(f"âš ï¸ Ek iÅŸleme hatasÄ± ({filename}): {e}")
                                    saved_attachment_filenames.append(filename)  # Hata durumunda da filename'i kaydet
                                    # Hata durumunda da temizle
                                    if 'payload' in att:
                                        att['payload'] = None
                                        del att['payload']
                                    if 'payload' in locals():
                                        del payload
                                    import gc
                                    gc.collect()
                        
                        # --- HAFIZA TEMÄ°ZLEME (DÃ¶ngÃ¼ sonrasÄ±) ---
                        if 'attachments' in mail_data:
                            mail_data['attachments'] = []
                        del attachments_to_process
                        import gc
                        gc.collect()

                    # --- LLM ile Ä°ÅŸleme ---
                    step_data = {"step": current_step + 0.5, "message": f"   ğŸ¤– Mail iÃ§eriÄŸi analiz ediliyor (LLM)...", "status": "info"}
                    yield f"data: {json.dumps(step_data)}\n\n"
                    await asyncio.sleep(0.01)
                    
                    processed = process_mail_with_llm(
                        mail_data["body"], 
                        mail_data["subject"], 
                        mail_data["sender"],
                        attachment_summaries if attachment_summaries else None
                    )
                    
                    step_data = {"step": current_step + 0.6, "message": f"   âœ… Mail analizi tamamlandÄ± (Ã¶zet, gÃ¶revler, kritik tarihler Ã§Ä±karÄ±ldÄ±)", "status": "success"}
                    yield f"data: {json.dumps(step_data)}\n\n"
                    await asyncio.sleep(0.01)
                    
                    # Process-in-RAM: body=None, has_full_content=False, attachments=filenames only
                    mail_record = {
                        "tenant_id": current_user.tenant_id,
                        "sender": mail_data["sender"],
                        "subject": mail_data["subject"],
                        "body": None,  # Privacy/Space optimization - body not saved
                        "has_full_content": False,  # Indicates body must be fetched on-demand
                        "message_id": message_id,
                        "email_id": email_id,
                        "in_reply_to": in_reply_to,
                        "thread_id": thread_id,
                        "summary": processed.get("summary", ""),
                        "is_critical": processed.get("is_critical", False),
                        "is_answered": False,
                        "is_read": False,
                        "attachments": saved_attachment_filenames,  # Only filenames, not paths
                        "attachment_summaries": attachment_summaries,  # {filename: summary}
                        "attachment_tables": attachment_tables,
                        "potential_tasks": processed.get("potential_tasks", []),
                        "critical_dates": processed.get("critical_dates", {}),
                        "created_at": datetime.now(),
                        "received_at": mail_data["received_at"]
                    }
                    
                    mail_record["id"] = mail_id
                    doc_ref.set(mail_record)
                    
                    # --- VektÃ¶r VeritabanÄ± ---
                    try:
                        step_data = {"step": current_step + 0.7, "message": f"   ğŸ” VektÃ¶r veritabanÄ±na ekleniyor (soru-cevap iÃ§in)...", "status": "info"}
                        yield f"data: {json.dumps(step_data)}\n\n"
                        await asyncio.sleep(0.01)
                        
                        embedding_model = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=GEMINI_API_KEY)
                        
                        # Construct chunk_text with attachment summaries for vector search
                        attachment_summaries_text = ""
                        if attachment_summaries:
                            attachment_summaries_text = "\n\nEk Ã–zetleri:\n"
                            for filename, summary in attachment_summaries.items():
                                attachment_summaries_text += f"- {filename}: {summary}\n"
                        
                        mail_text = f"GÃ¶nderen: {mail_data['sender']}\nKonu: {mail_data['subject']}\nMail Ã–zeti: {processed.get('summary', '')}{attachment_summaries_text}"
                        embedding = embedding_model.embed_documents([mail_text])[0]
                        if embedding:
                            chunk_data = {
                                "tenant_id": current_user.tenant_id,
                                "file_id": f"mail_{mail_id}",
                                "file_name": f"Mail: {mail_data['subject']}",
                                "chunk_number": 0,
                                "chunk_text": mail_text,
                                "embedding": embedding,
                                "mail_id": mail_id
                            }
                            db.add_text_chunks_batch([chunk_data])
                            step_data = {"step": current_step + 0.8, "message": f"   âœ… VektÃ¶r veritabanÄ±na eklendi", "status": "success"}
                            yield f"data: {json.dumps(step_data)}\n\n"
                            await asyncio.sleep(0.01)
                    except Exception as e:
                        print(f"VektÃ¶r ekleme hatasÄ±: {e}")
                        errors.append(f"VektÃ¶r ekleme hatasÄ± (Mail: {mail_data['subject']}): {str(e)}")
                        step_data = {"step": current_step + 0.8, "message": f"   âš ï¸ VektÃ¶r ekleme hatasÄ±: {str(e)[:50]}", "status": "error"}
                        yield f"data: {json.dumps(step_data)}\n\n"
                        await asyncio.sleep(0.01)
                    
                    processed_count += 1
                    processed_in_batch += 1
                    mail_processing_time = time.time() - mail_start_time
                    mail_processing_times.append(mail_processing_time)
                    
                    step_data = {"step": current_step + 1, "message": f"âœ… Mail baÅŸarÄ±yla iÅŸlendi ({mail_processing_time:.2f}s)", "status": "success"}
                    yield f"data: {json.dumps(step_data)}\n\n"
                    await asyncio.sleep(0.01)
                    print(f"âœ… Mail iÅŸlendi ({processed_count}): {mail_data.get('subject', 'Bilinmiyor')[:50]}... ({mail_processing_time:.2f}s)")
                    
                    # Her 50 mail'de bir bellek temizliÄŸi yap
                    if processed_in_batch >= MAX_MAILS_PER_BATCH:
                        import gc
                        gc.collect()
                        processed_in_batch = 0
                        step_data = {"step": current_step + 1.1, "message": f"   ğŸ§¹ Bellek temizliÄŸi yapÄ±ldÄ± ({processed_count} mail iÅŸlendi)", "status": "info"}
                        yield f"data: {json.dumps(step_data)}\n\n"
                        await asyncio.sleep(0.01)
                
                except Exception as e:
                    mail_processing_time = time.time() - mail_start_time
                    mail_processing_times.append(mail_processing_time)
                    error_msg = f"Mail iÅŸleme hatasÄ± (Konu: {mail_data.get('subject', 'Bilinmiyor')}): {str(e)}"
                    subject_short = mail_data.get('subject', 'Bilinmiyor')[:50]
                    current_step = 3 + processed_count + skipped_count + 1
                    step_data = {"step": current_step, "message": f"âŒ Hata: {subject_short}... - {str(e)[:100]}", "status": "error"}
                    yield f"data: {json.dumps(step_data)}\n\n"
                    await asyncio.sleep(0.01)
                    print(error_msg)
                    errors.append(error_msg)
                
                finally:
                    # --- HAFIZA TEMÄ°ZLEME (Ana dÃ¶ngÃ¼ sonu) ---
                    if 'mail_data' in locals():
                        # Mail data iÃ§indeki bÃ¼yÃ¼k objeleri temizle
                        if 'body' in mail_data:
                            mail_data['body'] = None
                        if 'attachments' in mail_data:
                            mail_data['attachments'] = []
                        del mail_data
                    import gc
                    gc.collect()
            
            # --- DÃ¶ngÃ¼ Sonu ---
            if total_fetched == 0:
                step_data = {"step": 4, "message": "HiÃ§ mail bulunamadÄ±.", "status": "warning"}
                yield f"data: {json.dumps(step_data)}\n\n"
                await asyncio.sleep(0.01)
                return # Generator'Ä± bitir
            
            # --- Ä°statistikleri Hesapla ve GÃ¶nder ---
            total_time = time.time() - total_start_time
            avg_processing_time = sum(mail_processing_times) / len(mail_processing_times) if mail_processing_times else 0
            
            # EÄŸer mailler bulundu ama hepsi duplicate ise, Ã¶zel mesaj gÃ¶ster
            if total_fetched > 0 and processed_count == 0 and skipped_count > 0:
                summary_steps = [
                    {"step": 999, "message": "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”", "status": "info"},
                    {"step": 1000, "message": f"ğŸ“Š Ä°ÅŸleme TamamlandÄ±", "status": "success"},
                    {"step": 1001, "message": f"   â€¢ Toplam mail: {total_fetched}", "status": "info"},
                    {"step": 1002, "message": f"   â€¢ Ä°ÅŸlenen: {processed_count}", "status": "info"},
                    {"step": 1003, "message": f"   â€¢ Atlanan (zaten iÅŸlenmiÅŸ): {skipped_count}", "status": "skip"},
                    {"step": 1004, "message": f"   â€¢ TÃ¼m mailler zaten iÅŸlenmiÅŸ, yeni mail yok.", "status": "info"},
                    {"step": 1005, "message": f"   â€¢ Toplam sÃ¼re: {total_time:.2f} saniye", "status": "info"}
                ]
            else:
                summary_steps = [
                    {"step": 999, "message": "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”", "status": "info"},
                    {"step": 1000, "message": f"ğŸ“Š Ä°ÅŸleme TamamlandÄ±", "status": "success"},
                    {"step": 1001, "message": f"   â€¢ Toplam mail: {total_fetched}", "status": "info"},
                    {"step": 1002, "message": f"   â€¢ Ä°ÅŸlenen: {processed_count}", "status": "success"},
                    {"step": 1003, "message": f"   â€¢ Atlanan (duplicate): {skipped_count}", "status": "skip"},
                    {"step": 1004, "message": f"   â€¢ Hata: {len(errors)}", "status": "error" if len(errors) > 0 else "info"},
                    {"step": 1005, "message": f"   â€¢ Toplam sÃ¼re: {total_time:.2f} saniye", "status": "info"},
                    {"step": 1006, "message": f"   â€¢ Ortalama iÅŸleme sÃ¼resi: {avg_processing_time:.2f} saniye/mail", "status": "info"}
                ]

            for step in summary_steps:
                yield f"data: {json.dumps(step)}\n\n"
                await asyncio.sleep(0.01)
            
            print(f"\nğŸ“Š Mail Ä°ÅŸleme Ã–zeti (SSE AkÄ±ÅŸÄ± TamamlandÄ±):")
            print(f"   - Toplam mail: {total_fetched}")
            print(f"   - Ä°ÅŸlenen: {processed_count}")
            # ... (diÄŸer print loglarÄ±)
            
        except imaplib.IMAP4.error as e:
            error_detail = f"IMAP baÄŸlantÄ± hatasÄ±: {str(e)}. LÃ¼tfen mail ayarlarÄ±nÄ±zÄ± kontrol edin."
            print(f"Mail Ã§ekme IMAP hatasÄ±: {e}")
            step_data = {"step": 999, "message": f"âŒ IMAP baÄŸlantÄ± hatasÄ±: {str(e)}", "status": "error"}
            yield f"data: {json.dumps(step_data)}\n\n"
        
        except Exception as e:
            import traceback
            error_detail = f"Mail Ã§ekme hatasÄ±: {str(e)}"
            print(f"Mail Ã§ekme hatasÄ±: {e}\n{traceback.format_exc()}")
            step_data = {"step": 999, "message": f"âŒ Genel hata: {str(e)}", "status": "error"}
            yield f"data: {json.dumps(step_data)}\n\n"
    
    # --- Ana Fonksiyonun DÃ¶nÃ¼ÅŸÃ¼ ---
    # Generator'Ä± Ã§aÄŸÄ±r ve StreamingResponse olarak frontend'e dÃ¶ndÃ¼r.
    return StreamingResponse(event_stream_generator(), media_type="text/event-stream")
# --- /fetch endpoint GÃœNCELLEMESÄ° BÄ°TTÄ° ---

@router.get("/live-content/{message_id}")
async def get_mail_live_content(
    message_id: str,
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository)
):
    """
    Mail body iÃ§eriÄŸini IMAP'ten on-demand olarak Ã§eker.
    Mail DB'de body=None olarak kaydedilmiÅŸse, bu endpoint kullanÄ±lÄ±r.
    """
    from app.services.mail_service import fetch_single_mail_body
    
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    
    # Mail kaydÄ±nÄ± bul
    mail_query = (
        mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
        .where(filter=FieldFilter("message_id", "==", message_id))
        .limit(1)
    )
    mail_docs = list(mail_query.stream())
    
    if not mail_docs:
        raise HTTPException(status_code=404, detail="Mail bulunamadÄ±")
    
    mail_data = mail_docs[0].to_dict()
    
    # Mail ayarlarÄ±nÄ± al
    settings_doc = firestore_db.collection("mail_settings").document(current_user.tenant_id).get()
    if not settings_doc.exists:
        raise HTTPException(status_code=404, detail="Mail ayarlarÄ± bulunamadÄ±")
    
    settings = settings_doc.to_dict()
    email_address = settings.get("email_address", "")
    password = settings.get("password", "")
    imap_server = settings.get("imap_server", "")
    imap_port = settings.get("imap_port", 993)
    
    if not email_address or not password:
        raise HTTPException(status_code=400, detail="Mail ayarlarÄ± eksik")
    
    # IMAP'ten body'yi Ã§ek
    body_content = fetch_single_mail_body(
        email_address=email_address,
        password=password,
        imap_server=imap_server,
        imap_port=imap_port,
        message_id=message_id
    )
    
    if body_content is None:
        raise HTTPException(status_code=404, detail="Mail iÃ§eriÄŸi IMAP'ten Ã§ekilemedi")
    
    return {
        "message_id": message_id,
        "body": body_content
    }

# --- Kalan endpoint'ler (process, get_mail_summaries, get_mail_stats, query_mails, vb.) ---
# --- Bu fonksiyonlarda bir deÄŸiÅŸiklik yapÄ±lmadÄ±. ---

@router.post("/process", response_model=MailSummary)
async def process_mail(
    sender: str = Form(...),
    subject: str = Form(...),
    body: str = Form(...),
    received_at: Optional[datetime] = Form(None),
    attachments: List[UploadFile] = File([]),
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository),
    storage: BaseStorageAdapter = Depends(get_storage_adapter)
):
    """Gelen maili iÅŸler, Ã¶zetini Ã§Ä±karÄ±r ve ekleri kaydeder."""
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    
    # LLM ile mail iÅŸleme
    processed = process_mail_with_llm(body, subject, sender)
    
    # Mail kaydÄ± oluÅŸtur
    mail_data = {
        "tenant_id": current_user.tenant_id,
        "sender": sender,
        "subject": subject,
        "body": body,
        "summary": processed.get("summary", ""),
        "is_critical": processed.get("is_critical", False),
        "is_answered": False,
        "attachments": [],
        "potential_tasks": processed.get("potential_tasks", []),
        "critical_dates": processed.get("critical_dates", {}),
        "created_at": datetime.now(),
        "received_at": received_at or datetime.now()
    }
    
    doc_ref = mail_col.document()
    mail_id = doc_ref.id
    mail_data["id"] = mail_id
    doc_ref.set(mail_data)
    
    # Ekleri kaydet
    if attachments:
        saved_paths = await save_mail_attachments(attachments, current_user.tenant_id, mail_id, storage)
        doc_ref.update({"attachments": saved_paths})
        mail_data["attachments"] = saved_paths
    
    # Mail iÃ§eriÄŸini vektÃ¶r veritabanÄ±na ekle (soru-cevap iÃ§in)
    try:
        embedding_model = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=GEMINI_API_KEY)
        mail_text = f"GÃ¶nderen: {sender}\nKonu: {subject}\nÄ°Ã§erik: {body}"
        embedding = embedding_model.embed_documents([mail_text])[0]
        if embedding:
            chunk_data = {
                "tenant_id": current_user.tenant_id,
                "file_id": f"mail_{mail_id}",
                "file_name": f"Mail: {subject}",
                "chunk_number": 0,
                "chunk_text": mail_text,
                "embedding": embedding,
                "mail_id": mail_id
            }
            db.add_text_chunks_batch([chunk_data])
    except Exception as e:
        print(f"Mail vektÃ¶r ekleme hatasÄ±: {e}")
    
    return MailSummary(**mail_data)

@router.get("/summaries", response_model=List[MailSummary])
def get_mail_summaries(
    period: str = "daily",  # "daily", "weekly", "custom"
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository)
):
    """Mail Ã¶zetlerini getirir."""
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    
    query = mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
    
    # UTC+3 (TÃ¼rkiye saati) kullanarak bugÃ¼nÃ¼n baÅŸlangÄ±cÄ±nÄ± hesapla
    if period == "daily":
        start = get_today_start_utc3()
        print(f"ğŸ“… GÃ¼nlÃ¼k Ã¶zet - BugÃ¼nÃ¼n baÅŸlangÄ±cÄ± (UTC+3'e gÃ¶re): {start}")
        query = query.where(filter=FieldFilter("received_at", ">=", start))
    elif period == "weekly":
        now_utc3 = get_now_utc3()
        start = now_utc3 - timedelta(days=7)
        print(f"ğŸ“… HaftalÄ±k Ã¶zet - 7 gÃ¼n Ã¶ncesi (UTC+3'e gÃ¶re): {start}")
        query = query.where(filter=FieldFilter("received_at", ">=", start))
    elif period == "custom" and start_date and end_date:
        try:
            # String tarihleri datetime'a Ã§evir (YYYY-MM-DD formatÄ±)
            if isinstance(start_date, str):
                start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            else:
                start_dt = start_date
            if isinstance(end_date, str):
                end_dt = datetime.strptime(end_date, "%Y-%m-%d")
                # BitiÅŸ tarihine gÃ¼nÃ¼n sonunu ekle (23:59:59)
                end_dt = end_dt.replace(hour=23, minute=59, second=59)
            else:
                end_dt = end_date
            print(f"ğŸ“… Custom tarih filtresi: {start_dt} - {end_dt}")
            query = query.where(filter=FieldFilter("received_at", ">=", start_dt))
            query = query.where(filter=FieldFilter("received_at", "<=", end_dt))
        except Exception as e:
            print(f"âŒ Tarih parse hatasÄ±: {e}")
            raise HTTPException(status_code=400, detail=f"GeÃ§ersiz tarih formatÄ±: {str(e)}")
    
    # Firestore'da order_by kullanÄ±rken, Ã¶nce where filtreleri, sonra order_by gelmeli
    # AyrÄ±ca composite index gerekebilir, ama Ã¶nce deneyelim
    try:
        query = query.order_by("received_at", direction=firestore.Query.DESCENDING).limit(50)
    except Exception as e:
        # EÄŸer composite index yoksa, order_by olmadan dene
        print(f"âš ï¸ Order_by hatasÄ± (composite index gerekebilir): {e}")
        query = query.limit(50)
    
    # TÃ¼m mailleri topla ve thread'lere gÃ¶re grupla
    all_mails = []
    for doc in query.stream():
        data = doc.to_dict()
        # Tarih kontrolÃ¼ - Firestore timestamp'ini datetime'a Ã§evir
        received_at = data.get("received_at")
        if received_at:
            # Firestore timestamp ise datetime'a Ã§evir
            if hasattr(received_at, 'timestamp'):
                received_at = datetime.fromtimestamp(received_at.timestamp())
            elif not isinstance(received_at, datetime):
                # String veya baÅŸka bir format ise parse et
                try:
                    if isinstance(received_at, str):
                        received_at = datetime.fromisoformat(received_at.replace('Z', '+00:00'))
                    else:
                        received_at = datetime.now()
                except:
                    received_at = datetime.now()
            
            # Custom period iÃ§in tarih kontrolÃ¼ (ekstra gÃ¼venlik)
            if period == "custom" and start_date and end_date:
                try:
                    if isinstance(start_date, str):
                        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
                    else:
                        start_dt = start_date
                    if isinstance(end_date, str):
                        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
                        end_dt = end_dt.replace(hour=23, minute=59, second=59)
                    else:
                        end_dt = end_date
                    
                    # Tarih aralÄ±ÄŸÄ±nda deÄŸilse atla
                    if received_at < start_dt or received_at > end_dt:
                        continue
                except Exception as e:
                    print(f"âš ï¸ Tarih kontrolÃ¼ hatasÄ±: {e}")
        
        data["id"] = doc.id
        all_mails.append(data)
    
    # Thread'lere gÃ¶re grupla
    threads = {}  # {thread_id: [mail1, mail2, ...]}
    for mail in all_mails:
        thread_id = mail.get("thread_id") or mail.get("message_id") or mail.get("id")
        if thread_id not in threads:
            threads[thread_id] = []
        threads[thread_id].append(mail)
    
    # Her thread iÃ§in Ã¶zet oluÅŸtur
    result_mails = []
    for thread_id, thread_mails in threads.items():
        if len(thread_mails) == 1:
            # Tek mail ise direkt ekle
            result_mails.append(MailSummary(**thread_mails[0]))
        else:
            # Birden fazla mail varsa thread Ã¶zeti oluÅŸtur
            print(f"ğŸ”— Thread Ã¶zeti oluÅŸturuluyor: {thread_id} ({len(thread_mails)} mail)")
            try:
                # Thread Ã¶zeti oluÅŸtur
                thread_summary = process_thread_with_llm(thread_mails)
                
                # En son mailin bilgilerini kullan (thread'in temsilcisi olarak)
                def get_received_at(mail):
                    received_at = mail.get("received_at", datetime.now())
                    if isinstance(received_at, str):
                        try:
                            return datetime.fromisoformat(received_at.replace('Z', '+00:00'))
                        except:
                            return datetime.now()
                    elif hasattr(received_at, 'timestamp'):
                        return datetime.fromtimestamp(received_at.timestamp())
                    return received_at if isinstance(received_at, datetime) else datetime.now()
                
                latest_mail = max(thread_mails, key=get_received_at)
                
                # Thread Ã¶zeti ile birleÅŸtirilmiÅŸ mail oluÅŸtur
                latest_body = latest_mail.get("body") or ""
                thread_mail_data = {
                    "id": thread_id,  # Thread ID'yi mail ID olarak kullan
                    "tenant_id": latest_mail.get("tenant_id"),
                    "sender": latest_mail.get("sender"),
                    "subject": latest_mail.get("subject", ""),
                    "body": f"[Thread: {len(thread_mails)} mail] " + latest_body if latest_body else None,
                    "has_full_content": latest_mail.get("has_full_content", False),
                    "summary": thread_summary.get("summary", ""),
                    "is_critical": thread_summary.get("is_critical", False),
                    "is_answered": latest_mail.get("is_answered", False),
                    "is_read": all(m.get("is_read", False) for m in thread_mails),  # TÃ¼mÃ¼ okunmuÅŸsa okunmuÅŸ
                    "attachments": [],  # Thread'teki tÃ¼m attachment'larÄ± birleÅŸtir
                    "attachment_summaries": {},  # Thread'teki tÃ¼m attachment Ã¶zetlerini birleÅŸtir
                    "attachment_tables": {},  # Thread'teki tÃ¼m tablo verilerini birleÅŸtir
                    "potential_tasks": thread_summary.get("potential_tasks", []),
                    "critical_dates": thread_summary.get("critical_dates", {}),
                    "created_at": latest_mail.get("created_at", datetime.now()),
                    "received_at": max(get_received_at(m) for m in thread_mails)  # En son mailin tarihi
                }
                
                # Attachment'larÄ± birleÅŸtir
                for mail in thread_mails:
                    thread_mail_data["attachments"].extend(mail.get("attachments", []))
                    thread_mail_data["attachment_summaries"].update(mail.get("attachment_summaries", {}))
                    thread_mail_data["attachment_tables"].update(mail.get("attachment_tables", {}))
                
                result_mails.append(MailSummary(**thread_mail_data))
                print(f"âœ… Thread Ã¶zeti oluÅŸturuldu: {thread_id}")
            except Exception as e:
                print(f"âš ï¸ Thread Ã¶zeti oluÅŸturma hatasÄ± ({thread_id}): {e}")
                # Hata durumunda en son maili ekle
                result_mails.append(MailSummary(**max(thread_mails, key=lambda x: x.get("received_at", datetime.now()))))
    
    # Tarihe gÃ¶re sÄ±rala (en yeni Ã¶nce)
    result_mails.sort(key=lambda x: x.received_at if isinstance(x.received_at, datetime) else datetime.now(), reverse=True)
    
    print(f"ğŸ“Š {len(all_mails)} mail, {len(threads)} thread bulundu (period: {period}, custom: {period == 'custom'})")
    return result_mails[:50]  # En fazla 50 thread gÃ¶ster

@router.get("/stats", response_model=MailStats)
def get_mail_stats(
    period: str = "daily",
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository)
):
    """Mail istatistiklerini getirir."""
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    
    query = mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
    
    # UTC+3 (TÃ¼rkiye saati) kullanarak tarih filtreleme
    if period == "daily":
        start = get_today_start_utc3()
        print(f"ğŸ“… Mail istatistikleri - GÃ¼nlÃ¼k Ã¶zet - BugÃ¼nÃ¼n baÅŸlangÄ±cÄ± (UTC+3'e gÃ¶re): {start}")
        query = query.where(filter=FieldFilter("received_at", ">=", start))
    elif period == "weekly":
        now_utc3 = get_now_utc3()
        start = now_utc3 - timedelta(days=7)
        print(f"ğŸ“… Mail istatistikleri - HaftalÄ±k Ã¶zet - 7 gÃ¼n Ã¶ncesi (UTC+3'e gÃ¶re): {start}")
        query = query.where(filter=FieldFilter("received_at", ">=", start))
    elif period == "custom" and start_date and end_date:
        try:
            if isinstance(start_date, str):
                start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            else:
                start_dt = start_date
            if isinstance(end_date, str):
                end_dt = datetime.strptime(end_date, "%Y-%m-%d")
                end_dt = end_dt.replace(hour=23, minute=59, second=59)
            else:
                end_dt = end_date
            query = query.where(filter=FieldFilter("received_at", ">=", start_dt))
            query = query.where(filter=FieldFilter("received_at", "<=", end_dt))
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"GeÃ§ersiz tarih formatÄ±: {str(e)}")
    
    total = critical = unanswered = unread = 0
    for doc in query.stream():
        data = doc.to_dict()
        total += 1
        if data.get("is_critical"): critical += 1
        if not data.get("is_answered"): unanswered += 1
        # OkunmamÄ±ÅŸ mail: is_read field'Ä± yoksa veya false ise okunmamÄ±ÅŸ sayÄ±lÄ±r
        if not data.get("is_read", False): unread += 1
    
    return MailStats(total_mails=total, critical_mails=critical, unanswered_mails=unanswered, unread_mails=unread)

@router.post("/query")
def query_mails(
    request: MailQueryRequest,
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository)
):
    """Mailler iÃ§inde soru-cevap arama yapar."""
    
    # SelamlaÅŸma/hal hatÄ±r kontrolÃ¼ (en Ã¶nce - nazik cevap verilmeli)
    if is_greeting_query(request.query):
        print(f"ğŸ‘‹ SelamlaÅŸma mail sorgusu tespit edildi: '{request.query}' - Nazik cevap verilecek")
        greeting_response = get_greeting_response(request.query)
        return {
            "answer": greeting_response,
            "mails": []
        }
    
    # Off-topic sorgu kontrolÃ¼ (mail taramasÄ± yapmadan Ã¶nce)
    if is_off_topic_query(request.query):
        print(f"âš ï¸ Off-topic mail sorgusu tespit edildi: '{request.query}' - Mail taramasÄ± yapÄ±lmayacak")
        return {
            "answer": "ÃœzgÃ¼nÃ¼m, bu tÃ¼r genel sohbet sorularÄ±nÄ± yanÄ±tlayamam. LÃ¼tfen mail iÃ§erikleri ile ilgili sorular sorun. Ã–rneÄŸin: 'BugÃ¼n kaÃ§ mail geldi?', 'Kritik mailleri listele', 'X konusunda gelen mailleri gÃ¶ster' gibi.",
            "mails": []
        }
    
    # YardÄ±m/destek sorgu kontrolÃ¼ (mail taramasÄ± yapmadan Ã¶nce)
    if is_help_or_support_query(request.query):
        print(f"â„¹ï¸ YardÄ±m/destek mail sorgusu tespit edildi: '{request.query}' - Mail taramasÄ± yapÄ±lmayacak, direkt cevap verilecek")
        help_response = get_help_response(request.query)
        return {
            "answer": help_response,
            "mails": []
        }
    
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    
    # Soruyu analiz et ve otomatik tarih filtresi uygula
    query_lower_for_date = request.query.lower()
    today_keywords = ['bugÃ¼n', 'today', 'bugÃ¼nkÃ¼', 'bugÃ¼nÃ¼n', 'bugÃ¼ne', 'bugÃ¼nde']
    week_keywords = ['bu hafta', 'this week', 'haftalÄ±k', 'weekly']
    month_keywords = ['bu ay', 'this month', 'aylÄ±k', 'monthly']
    one_month_keywords = ['1 ay', 'bir ay', 'one month', '1 month', 'son 1 ay', 'son bir ay', 'last month']
    
    # EÄŸer soru tarih iÃ§eriyorsa ve date_range "all" ise, otomatik olarak tarih filtresi uygula
    auto_date_range = None
    if request.date_range == "all" or not request.date_range:
        if any(keyword in query_lower_for_date for keyword in today_keywords):
            auto_date_range = "daily"
            print(f"ğŸ” Soru analizi: 'bugÃ¼n' kelimesi tespit edildi, otomatik 'daily' filtresi uygulanÄ±yor")
        elif any(keyword in query_lower_for_date for keyword in week_keywords):
            auto_date_range = "weekly"
            print(f"ğŸ” Soru analizi: 'bu hafta' kelimesi tespit edildi, otomatik 'weekly' filtresi uygulanÄ±yor")
        elif any(keyword in query_lower_for_date for keyword in one_month_keywords):
            auto_date_range = "one_month"
            print(f"ğŸ” Soru analizi: '1 ay' kelimesi tespit edildi, otomatik 'one_month' filtresi uygulanÄ±yor")
        elif any(keyword in query_lower_for_date for keyword in month_keywords):
            auto_date_range = "monthly"
            print(f"ğŸ” Soru analizi: 'bu ay' kelimesi tespit edildi, otomatik 'monthly' filtresi uygulanÄ±yor")
    
    # Tarih filtresi iÃ§in tarih aralÄ±ÄŸÄ±nÄ± hesapla (UTC+3 timezone'a gÃ¶re)
    date_filter_start = None
    date_filter_end = None
    effective_date_range = auto_date_range if auto_date_range else request.date_range
    if effective_date_range and effective_date_range != "all":
        now_utc3 = datetime.now(TURKEY_TIMEZONE)
        now_utc = get_now_utc3()  # UTC'ye Ã§evrilmiÅŸ ÅŸu anki zaman
        
        if effective_date_range == "daily":
            # BugÃ¼nÃ¼n baÅŸlangÄ±cÄ± (UTC+3'te 00:00:00, UTC'ye Ã§evrilmiÅŸ)
            date_filter_start = get_today_start_utc3()
            date_filter_end = datetime(now_utc3.year, now_utc3.month, now_utc3.day, 23, 59, 59, 999999)
        elif effective_date_range == "weekly":
            # Son 7 gÃ¼n
            date_filter_start = now_utc - timedelta(days=7)
            date_filter_end = now_utc  # Åu ana kadar
        elif effective_date_range == "one_month":
            # Son 1 ay (30 gÃ¼n)
            date_filter_start = now_utc - timedelta(days=30)
            date_filter_end = now_utc  # Åu ana kadar
        elif effective_date_range == "monthly":
            # Bu ayÄ±n baÅŸÄ± (UTC+3'te)
            month_start_utc3 = datetime(now_utc3.year, now_utc3.month, 1, tzinfo=TURKEY_TIMEZONE)
            date_filter_start = month_start_utc3.astimezone(timezone.utc).replace(tzinfo=None)
            date_filter_end = now_utc  # Åu ana kadar
        elif effective_date_range == "custom" and request.start_date and request.end_date:
            try:
                if isinstance(request.start_date, str):
                    date_filter_start = datetime.strptime(request.start_date, "%Y-%m-%d")
                else:
                    date_filter_start = request.start_date
                if isinstance(request.end_date, str):
                    date_filter_end = datetime.strptime(request.end_date, "%Y-%m-%d")
                    date_filter_end = date_filter_end.replace(hour=23, minute=59, second=59)
                else:
                    date_filter_end = request.end_date
            except Exception as e:
                print(f"âš ï¸ Tarih parse hatasÄ±: {e}")
    
    # Soru iÃ§inde "ek", "attachment", "dosya" gibi kelimeler varsa direkt Firestore'dan arama yap
    query_lower = query_lower_for_date
    attachment_keywords = ['ek', 'attachment', 'dosya', 'file', 'ekli', 'ekte', 'ekler']
    is_attachment_query = any(keyword in query_lower for keyword in attachment_keywords)
    
    # Ä°statistik sorularÄ±nÄ± tespit et (sender istatistiÄŸi, en Ã§ok, en az, toplam vb.)
    statistics_keywords = ['en Ã§ok', 'en az', 'en fazla', 'en az', 'toplam', 'kaÃ§', 'kimden', 'gÃ¶nderen', 'sender', 
                          'istatistik', 'statistics', 'sayÄ±', 'count', 'hangi', 'kim', 'en yÃ¼ksek', 'en dÃ¼ÅŸÃ¼k']
    sender_statistics_keywords = ['kimden', 'gÃ¶nderen', 'sender', 'kim', 'hangi kiÅŸi', 'hangi kiÅŸiden', 
                                 'en Ã§ok mail', 'en fazla mail', 'mail sayÄ±sÄ±', 'mail count']
    is_statistics_query = any(keyword in query_lower for keyword in statistics_keywords)
    is_sender_statistics_query = is_statistics_query and any(keyword in query_lower for keyword in sender_statistics_keywords)
    
    if is_sender_statistics_query:
        print(f"ğŸ“Š Sender istatistik sorgusu tespit edildi: '{request.query}' - TÃ¼m mailler analiz edilecek")
    
    # Soru iÃ§inde "kritik" kelimesi varsa kritik mail filtresi uygula
    # YazÄ±m hatalarÄ±na tolerans iÃ§in fuzzy matching
    import re
    critical_keywords = ['kritik', 'critical', 'acil', 'urgent', 'Ã¶nemli', 'important']
    # YaygÄ±n yazÄ±m hatalarÄ± - direkt kontrol
    critical_typos = ['ktirik', 'kirtik', 'kritik', 'kritik', 'kritik', 'kritik']
    
    is_critical_query = any(keyword in query_lower for keyword in critical_keywords)
    
    # YazÄ±m hatasÄ± kontrolÃ¼: "ktirik", "kirtik" gibi yaygÄ±n hatalarÄ± da kontrol et
    if not is_critical_query:
        # "ktirik" gibi yazÄ±m hatalarÄ±nÄ± kontrol et (kritik kelimesinin harfleri karÄ±ÅŸmÄ±ÅŸ)
        # Basit kontrol: "k" ile baÅŸlayan ve "t", "r", "i", "k" harflerini iÃ§eren 5-6 harfli kelimeler
        words = query_lower.split()
        for word in words:
            # "ktirik" gibi kelimeleri yakala (k ile baÅŸlayan, t, r, i, k iÃ§eren, 5-6 harfli)
            word_clean = word.strip('.,!?;:')
            if len(word_clean) >= 5 and len(word_clean) <= 6:
                if word_clean.startswith('k') and 't' in word_clean and 'r' in word_clean and 'i' in word_clean and word_clean.endswith('k'):
                    # "kritik" kelimesinin harflerini iÃ§eriyor mu kontrol et
                    word_chars = set(word_clean)
                    kritik_chars = set('kritik')
                    if len(word_chars & kritik_chars) >= 4:  # En az 4 harf eÅŸleÅŸiyorsa
                        is_critical_query = True
                        print(f"ğŸ” Kritik mail sorgusu tespit edildi: YazÄ±m hatasÄ± dÃ¼zeltildi ('{word_clean}' -> 'kritik')")
                        break
    
    if is_critical_query:
        matched_keyword = [kw for kw in critical_keywords if kw in query_lower]
        if matched_keyword:
            print(f"ğŸ” Kritik mail sorgusu tespit edildi: '{matched_keyword[0]}' kelimesi bulundu")
        else:
            print(f"ğŸ” Kritik mail sorgusu tespit edildi: YazÄ±m hatasÄ± dÃ¼zeltildi")
    else:
        print(f"ğŸ” Kritik mail sorgusu tespit edilmedi. Soru: '{request.query}' (lowercase: '{query_lower}')")
    
    mail_ids = set()
    results = []
    
    # Ã–nce tarih filtresine uyan mail ID'lerini topla (tarih filtresi varsa)
    # EÄŸer kritik mail sorgusu varsa, kritik mail filtresini de ekle
    filtered_mail_ids = None
    if date_filter_start or date_filter_end or is_critical_query:
        print(f"ğŸ“… Tarih filtresi uygulanÄ±yor: {date_filter_start} - {date_filter_end}")
        if is_critical_query:
            print(f"ğŸ”´ Kritik mail filtresi uygulanÄ±yor")
        
        date_query = mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
        if date_filter_start:
            date_query = date_query.where(filter=FieldFilter("received_at", ">=", date_filter_start))
        if date_filter_end:
            date_query = date_query.where(filter=FieldFilter("received_at", "<=", date_filter_end))
        if is_critical_query:
            date_query = date_query.where(filter=FieldFilter("is_critical", "==", True))
        
        filtered_mail_ids = set()
        critical_count_in_filter = 0
        for doc in date_query.stream():
            filtered_mail_ids.add(doc.id)
            # Kritik mail sayÄ±sÄ±nÄ± kontrol et
            if is_critical_query:
                data = doc.to_dict()
                if data.get("is_critical", False):
                    critical_count_in_filter += 1
        print(f"ğŸ“Š Tarih/kritik filtresine uyan {len(filtered_mail_ids)} mail bulundu")
        if is_critical_query:
            print(f"ğŸ”´ FiltrelenmiÅŸ maillerden {critical_count_in_filter} tanesi kritik (is_critical=True)")
    
    if is_attachment_query:
        # Direkt Firestore'dan attachment'Ä± olan mailleri getir
        print(f"ğŸ“ Attachment sorgusu tespit edildi, Firestore'dan direkt arama yapÄ±lÄ±yor...")
        query = mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
        
        # Tarih filtresi ekle
        if date_filter_start:
            query = query.where(filter=FieldFilter("received_at", ">=", date_filter_start))
        if date_filter_end:
            query = query.where(filter=FieldFilter("received_at", "<=", date_filter_end))
        
        # Limit uygula (Ã§ok fazla sonuÃ§ olmasÄ±n)
        try:
            query = query.limit(100)
        except:
            pass
        
        # Kritik mail filtresi ekle
        if is_critical_query:
            query = query.where(filter=FieldFilter("is_critical", "==", True))
        
        # Attachment'Ä± olan mailleri bul
        for doc in query.stream():
            data = doc.to_dict()
            attachments = data.get("attachments", [])
            if attachments and len(attachments) > 0:
                # Kritik mail sorgusu varsa, sadece kritik mailleri ekle
                if is_critical_query:
                    if data.get("is_critical", False):
                        mail_ids.add(doc.id)
                else:
                    mail_ids.add(doc.id)
    elif is_sender_statistics_query:
        # Sender istatistik sorgusu iÃ§in tÃ¼m mailleri Firestore'dan Ã§ek
        print(f"ğŸ“Š Sender istatistik sorgusu - TÃ¼m mailler Firestore'dan Ã§ekiliyor...")
        stats_query = mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
        
        # Tarih filtresi ekle
        if date_filter_start:
            stats_query = stats_query.where(filter=FieldFilter("received_at", ">=", date_filter_start))
        if date_filter_end:
            stats_query = stats_query.where(filter=FieldFilter("received_at", "<=", date_filter_end))
        
        # TÃ¼m mailleri Ã§ek
        for doc in stats_query.stream():
            mail_ids.add(doc.id)
        print(f"ğŸ“Š Sender istatistik iÃ§in {len(mail_ids)} mail bulundu")
    else:
        # Normal vektÃ¶r aramasÄ±
        # EÄŸer kritik mail sorgusu varsa ve tarih filtresi varsa, direkt Firestore'dan Ã§ek (daha hÄ±zlÄ± ve doÄŸru)
        if is_critical_query and filtered_mail_ids:
            print(f"ğŸ”´ Kritik mail sorgusu + tarih filtresi tespit edildi, direkt Firestore'dan Ã§ekiliyor...")
            # filtered_mail_ids zaten kritik ve tarih filtresine uyan mailleri iÃ§eriyor
            mail_ids.update(filtered_mail_ids)
            print(f"ğŸ“Š Firestore'dan {len(filtered_mail_ids)} kritik mail ID'si mail_ids set'ine eklendi (toplam mail_ids: {len(mail_ids)})")
        elif filtered_mail_ids and (any(keyword in query_lower_for_date for keyword in ['bugÃ¼n', 'today', 'bugÃ¼nkÃ¼', 'bugÃ¼nÃ¼n', 'bugÃ¼ne', 'bugÃ¼nde', 'Ã¶zet', 'Ã¶zetle', 'Ã¶zetler']) or len(request.query.split()) <= 5):
            # EÄŸer tarih filtresi varsa ve sorgu "bugÃ¼n" gibi genel bir sorguysa veya Ã§ok kÄ±sa bir sorguysa,
            # vektÃ¶r aramasÄ± yapmadan direkt tarih filtresine uyan mailleri getir
            print(f"ğŸ“… Tarih filtresi + genel sorgu tespit edildi, direkt Firestore'dan Ã§ekiliyor...")
            mail_ids.update(filtered_mail_ids)
            print(f"ğŸ“Š Firestore'dan {len(filtered_mail_ids)} mail ID'si mail_ids set'ine eklendi (toplam mail_ids: {len(mail_ids)})")
        else:
            # VektÃ¶r aramasÄ± yap
            chunks = vector_service.search_similar_chunks(
                tenant_id=current_user.tenant_id,
                query=request.query,
                db=db,
                limit=50,
                filter_file_ids=None
            )
            
            # Mail ID'lerini topla (file_id'den mail_id Ã§Ä±kar)
            # EÄŸer tarih/kritik filtresi varsa, sadece filtrelenmiÅŸ mailleri dahil et
            print(f"ğŸ” VektÃ¶r aramasÄ±: {len(chunks)} chunk bulundu")
            print(f"ğŸ” Kritik mail sorgusu: {is_critical_query}, filtered_mail_ids: {len(filtered_mail_ids) if filtered_mail_ids else 'None'}")
            vector_mail_count = 0
            for chunk in chunks:
                file_id = chunk.get("source_file_id", "")
                if file_id.startswith("mail_"):
                    mail_id = file_id.replace("mail_", "")
                    # Tarih filtresi veya kritik mail filtresi varsa, sadece filtrelenmiÅŸ mailleri dahil et
                    if filtered_mail_ids is None:
                        # Filtre yoksa, tÃ¼m vektÃ¶r aramasÄ± sonuÃ§larÄ±nÄ± ekle
                        mail_ids.add(mail_id)
                        vector_mail_count += 1
                    elif mail_id in filtered_mail_ids:
                        # Filtre varsa, sadece filtrelenmiÅŸ mailleri ekle
                        mail_ids.add(mail_id)
                        vector_mail_count += 1
                    else:
                        # Filtre var ama bu mail filtrelenmiÅŸ set'te yok
                        if is_critical_query:
                            print(f"âš ï¸ VektÃ¶r aramasÄ± sonucu {mail_id} kritik mail filtresine uymuyor, eklenmedi")
            
            # EÄŸer vektÃ¶r aramasÄ± sonucu yoksa ama tarih filtresi varsa, direkt tarih filtresine uyan mailleri kullan
            if vector_mail_count == 0 and filtered_mail_ids and len(filtered_mail_ids) > 0:
                print(f"âš ï¸ VektÃ¶r aramasÄ± sonucu bulunamadÄ±, tarih filtresine uyan {len(filtered_mail_ids)} mail kullanÄ±lÄ±yor...")
                mail_ids.update(filtered_mail_ids)
            
            print(f"ğŸ“Š VektÃ¶r aramasÄ±ndan {vector_mail_count} mail mail_ids set'ine eklendi (toplam mail_ids: {len(mail_ids)})")
        
        # NOT: Tarih filtresi varsa, sadece vektÃ¶r aramasÄ± sonuÃ§larÄ±nÄ± kullan
        # Tarih filtresine uyan tÃ¼m mailleri eklemek yanlÄ±ÅŸ sonuÃ§lara yol aÃ§ar
        # (Ã¶rn: "bugÃ¼n kaÃ§ mail geldi" sorusunda bugÃ¼n olmayan mailleri de gÃ¶sterir)
    
    # Mail detaylarÄ±nÄ± getir ve filtrele (tarih ve kritik mail filtresi)
    print(f"ğŸ“‹ {len(mail_ids)} mail ID'si iÃ§in detay Ã§ekiliyor...")
    filtered_out_count = 0
    for mail_id in list(mail_ids):
        doc = mail_col.document(mail_id).get()
        if doc.exists:
            data = doc.to_dict()
            if data.get("tenant_id") != current_user.tenant_id:
                filtered_out_count += 1
                continue
            
            # received_at timestamp'ini datetime'a Ã§evir
            received_at = None
            if "received_at" in data:
                received_at_raw = data["received_at"]
                if hasattr(received_at_raw, 'timestamp'):
                    received_at = datetime.fromtimestamp(received_at_raw.timestamp())
                elif isinstance(received_at_raw, str):
                    try:
                        received_at = datetime.fromisoformat(received_at_raw.replace('Z', '+00:00'))
                    except:
                        pass
                elif isinstance(received_at_raw, datetime):
                    received_at = received_at_raw
            
            # Tarih filtresi doÄŸrulama (zaten filtrelenmiÅŸ olmalÄ± ama gÃ¼venlik iÃ§in)
            # received_at None ise de filtrele (tarih bilgisi olmayan mailleri hariÃ§ tut)
            if date_filter_start:
                if not received_at or received_at < date_filter_start:
                    filtered_out_count += 1
                    print(f"âš ï¸ Mail {mail_id} tarih filtresine uymuyor (received_at={received_at}, filter_start={date_filter_start})")
                    continue
            if date_filter_end:
                if not received_at or received_at > date_filter_end:
                    filtered_out_count += 1
                    print(f"âš ï¸ Mail {mail_id} tarih filtresine uymuyor (received_at={received_at}, filter_end={date_filter_end})")
                    continue
            
            # Kritik mail filtresi doÄŸrulama (MUTLAKA uygulanmalÄ±)
            if is_critical_query:
                is_critical = data.get("is_critical", False)
                # FarklÄ± formatlarÄ± kontrol et (bool, string, int)
                if isinstance(is_critical, str):
                    is_critical = is_critical.lower() in ['true', '1', 'yes', 'evet']
                elif isinstance(is_critical, int):
                    is_critical = bool(is_critical)
                
                if not is_critical:
                    filtered_out_count += 1
                    print(f"âš ï¸ Mail {mail_id} kritik deÄŸil, filtreleniyor (is_critical={data.get('is_critical')} -> {is_critical})")
                    continue
            
            data["id"] = doc.id
            data["received_at"] = received_at
            results.append(MailSummary(**data))
    
    if filtered_out_count > 0:
        print(f"ğŸš« {filtered_out_count} mail filtrelendi, {len(results)} mail sonuÃ§ olarak dÃ¶ndÃ¼rÃ¼lÃ¼yor")
    
    # Kritik mail sorgusu varsa, sonuÃ§larÄ± bir kez daha filtrele (gÃ¼venlik iÃ§in)
    if is_critical_query:
        original_count = len(results)
        results = [m for m in results if m.is_critical]
        if len(results) != original_count:
            print(f"ğŸ”´ Kritik mail filtresi: {original_count} mail'den {len(results)} kritik mail kaldÄ± ({original_count - len(results)} mail filtrelendi)")
    
    print(f"âœ… Toplam {len(results)} mail sonuÃ§ olarak dÃ¶ndÃ¼rÃ¼lÃ¼yor")
    
    # LLM ile cevap oluÅŸtur
    llm = get_llm_for_model("gemini")
    
    # Tarih aralÄ±ÄŸÄ± bilgisini hazÄ±rla
    date_range_info = ""
    if date_filter_start and date_filter_end:
        months_tr = {
            1: "Ocak", 2: "Åubat", 3: "Mart", 4: "Nisan",
            5: "MayÄ±s", 6: "Haziran", 7: "Temmuz", 8: "AÄŸustos",
            9: "EylÃ¼l", 10: "Ekim", 11: "KasÄ±m", 12: "AralÄ±k"
        }
        start_str = f"{date_filter_start.day} {months_tr.get(date_filter_start.month, date_filter_start.strftime('%B'))} {date_filter_start.year}"
        end_str = f"{date_filter_end.day} {months_tr.get(date_filter_end.month, date_filter_end.strftime('%B'))} {date_filter_end.year}"
        if start_str == end_str:
            date_range_info = f"Tarih aralÄ±ÄŸÄ±: {start_str}"
        else:
            date_range_info = f"Tarih aralÄ±ÄŸÄ±: {start_str} - {end_str}"
    elif date_filter_start:
        months_tr = {
            1: "Ocak", 2: "Åubat", 3: "Mart", 4: "Nisan",
            5: "MayÄ±s", 6: "Haziran", 7: "Temmuz", 8: "AÄŸustos",
            9: "EylÃ¼l", 10: "Ekim", 11: "KasÄ±m", 12: "AralÄ±k"
        }
        start_str = f"{date_filter_start.day} {months_tr.get(date_filter_start.month, date_filter_start.strftime('%B'))} {date_filter_start.year}"
        date_range_info = f"Tarih aralÄ±ÄŸÄ±: {start_str} ve sonrasÄ±"
    
    # Mail tarihlerini de context'e ekle (tÃ¼m sonuÃ§larÄ± ekle, sadece ilk 5'i deÄŸil)
    context_parts = []
    for m in results:
        # Tarih bilgisini formatla
        received_date = m.received_at
        if received_date:
            if isinstance(received_date, datetime):
                # TÃ¼rkÃ§e ay isimleri
                months_tr = {
                    1: "Ocak", 2: "Åubat", 3: "Mart", 4: "Nisan",
                    5: "MayÄ±s", 6: "Haziran", 7: "Temmuz", 8: "AÄŸustos",
                    9: "EylÃ¼l", 10: "Ekim", 11: "KasÄ±m", 12: "AralÄ±k"
                }
                date_str = f"{received_date.day} {months_tr.get(received_date.month, received_date.strftime('%B'))} {received_date.year}, {received_date.strftime('%H:%M')}"
            elif isinstance(received_date, str):
                try:
                    dt = datetime.fromisoformat(received_date.replace('Z', '+00:00'))
                    months_tr = {
                        1: "Ocak", 2: "Åubat", 3: "Mart", 4: "Nisan",
                        5: "MayÄ±s", 6: "Haziran", 7: "Temmuz", 8: "AÄŸustos",
                        9: "EylÃ¼l", 10: "Ekim", 11: "KasÄ±m", 12: "AralÄ±k"
                    }
                    date_str = f"{dt.day} {months_tr.get(dt.month, dt.strftime('%B'))} {dt.year}, {dt.strftime('%H:%M')}"
                except:
                    date_str = received_date
            else:
                date_str = str(received_date)
        else:
            date_str = "Tarih bilgisi yok"
        
        # Kritik mail bilgisini ekle
        critical_mark = "ğŸ”´ KRÄ°TÄ°K" if m.is_critical else ""
        context_parts.append(f"ğŸ“… {date_str} - GÃ¶nderen: {m.sender}\nKonu: {m.subject}\nÃ–zet: {m.summary}{' ' + critical_mark if critical_mark else ''}")
    
    context = "\n\n".join(context_parts)
    
    # Kritik mail sayÄ±sÄ±nÄ± hesapla
    critical_count = sum(1 for m in results if m.is_critical)
    
    # Sender istatistik sorgusu iÃ§in sender sayÄ±larÄ±nÄ± hesapla
    sender_statistics = ""
    if is_sender_statistics_query and results:
        sender_counts = Counter(m.sender for m in results if m.sender)
        # En Ã§ok mail gÃ¶nderenleri sÄ±rala
        top_senders = sender_counts.most_common(10)  # Ä°lk 10 gÃ¶nderen
        
        sender_statistics = "\n\nGÃ–NDEREN Ä°STATÄ°STÄ°KLERÄ°:\n"
        for sender, count in top_senders:
            sender_statistics += f"- {sender}: {count} mail\n"
        
        print(f"ğŸ“Š Sender istatistikleri hesaplandÄ±: {len(sender_counts)} farklÄ± gÃ¶nderen, toplam {len(results)} mail")
    
    # Prompt'a toplam mail sayÄ±sÄ± ve tarih aralÄ±ÄŸÄ± bilgisini ekle
    total_count_info = f"Toplam {len(results)} mail bulundu."
    if critical_count > 0:
        total_count_info += f" Bunlardan {critical_count} tanesi kritik mail (is_critical=true)."
    if date_range_info:
        total_count_info += f" {date_range_info}."
    
    # Kritik mail sorgusu iÃ§in Ã¶zel bilgi ekle
    critical_info = ""
    if is_critical_query:
        critical_info = "\n\nÃ–NEMLÄ°: Soru 'kritik mail' hakkÄ±ndaysa, sadece is_critical=true olan mailleri say. Mail Ã¶zetlerinde 'ğŸ”´ KRÄ°TÄ°K' iÅŸareti olan mailler kritik maillerdir."
    
    # Sender istatistik sorgusu iÃ§in Ã¶zel talimat
    sender_info = ""
    if is_sender_statistics_query:
        sender_info = "\n\nÃ–NEMLÄ°: Soru 'en Ã§ok mail kimden', 'hangi gÃ¶nderen', 'sender istatistiÄŸi' gibi bir soruysa, yukarÄ±daki GÃ–NDEREN Ä°STATÄ°STÄ°KLERÄ° bÃ¶lÃ¼mÃ¼ndeki bilgileri kullan. En Ã§ok mail gÃ¶nderen kiÅŸiyi ve sayÄ±sÄ±nÄ± belirt."
    
    # Soru tipini tespit et: "var mÄ±", "kaÃ§" gibi sorular iÃ§in sadece sayÄ±, "listele", "gÃ¶ster" iÃ§in detaylÄ± liste
    query_lower_for_type = request.query.lower()
    is_count_only_query = any(keyword in query_lower_for_type for keyword in ['var mÄ±', 'var mi', 'var mÄ±?', 'var mi?', 'kaÃ§ tane', 'kaÃ§ adet', 'kaÃ§ mail', 'toplam kaÃ§'])
    is_list_query = any(keyword in query_lower_for_type for keyword in ['listele', 'gÃ¶ster', 'hangi mailler', 'hangi mail', 'mailleri gÃ¶ster', 'mailleri listele', 'detay', 'detaylÄ±'])
    
    # Sender istatistik sorgusu iÃ§in context'i kÄ±salt (Ã§ok fazla mail varsa)
    if is_sender_statistics_query and len(context_parts) > 50:
        # Sadece sender istatistiklerini gÃ¶ster, tÃ¼m mail listesini gÃ¶sterme
        context_for_prompt = f"Toplam {len(results)} mail analiz edildi. DetaylÄ± mail listesi Ã§ok uzun olduÄŸu iÃ§in gÃ¶sterilmiyor.{sender_statistics}"
    elif is_count_only_query and not is_list_query:
        # "Var mÄ±", "kaÃ§ tane" gibi sorular iÃ§in sayÄ± + ilgili maillerin Ã¶zeti
        if len(results) > 0:
            # Ä°lk birkaÃ§ mailin Ã¶zetini gÃ¶ster (max 10 - daha fazla Ã¶rnek gÃ¶ster)
            max_samples = min(10, len(results))
            sample_mails = context_parts[:max_samples]
            sample_text = "\n\n".join(sample_mails)
            if len(results) > max_samples:
                context_for_prompt = f"Toplam {len(results)} mail bulundu. Ä°lk {max_samples} mail:\n\n{sample_text}\n\n(Not: Toplam {len(results)} mail var, ilk {max_samples} tanesi gÃ¶steriliyor)"
            else:
                context_for_prompt = f"Bulunan {len(results)} mail:\n\n{sample_text}"
        else:
            context_for_prompt = "HiÃ§ mail bulunamadÄ±."
    else:
        # "Listele", "gÃ¶ster" gibi sorular iÃ§in tÃ¼m mail listesi
        context_for_prompt = context if context else "HiÃ§ mail bulunamadÄ±."
    
    # Soru tipine gÃ¶re Ã¶zel talimat
    query_type_instruction = ""
    if is_count_only_query and not is_list_query:
        query_type_instruction = f"\n\nÃ–NEMLÄ°: Soru 'var mÄ±', 'kaÃ§ tane', 'kaÃ§ adet' gibi bir soruysa:\n1. Ã–nce sayÄ±yÄ± ve kÄ±sa bir bilgi ver (Ã¶rn: 'Evet, {len(results)} adet toplantÄ± ile ilgili mail bulundu.' veya 'HayÄ±r, toplantÄ± ile ilgili mail bulunamadÄ±.')\n2. Sonra bulunan maillerin kÄ±sa bir Ã¶zetini listele. Her mail iÃ§in gÃ¶nderen ve konu bilgisini iÃ§er.\n3. TÃ¼m mailleri detaylÄ± olarak yazma, sadece Ã¶zet bilgi ver."
    elif is_list_query:
        query_type_instruction = "\n\nÃ–NEMLÄ°: Soru 'listele', 'gÃ¶ster', 'hangi mailler' gibi bir soruysa, bulunan maillerin detaylÄ± listesini ver. Her mail iÃ§in gÃ¶nderen, konu ve Ã¶zet bilgisini iÃ§er."
    
    prompt = f"""AÅŸaÄŸÄ±daki mail Ã¶zetlerine gÃ¶re soruyu cevapla. {total_count_info}
Her mail iÃ§in tarih bilgisi ve kritik mail durumu (is_critical) verilmiÅŸtir. Kritik mailler 'ğŸ”´ KRÄ°TÄ°K' iÅŸaretiyle belirtilmiÅŸtir.
EÄŸer soru mail sayÄ±sÄ± hakkÄ±ndaysa, sadece verilen mail sayÄ±sÄ±nÄ± sÃ¶yle.{critical_info}{sender_info}{query_type_instruction}

{sender_statistics if sender_statistics else ""}

{context_for_prompt}

Soru: {request.query}
Cevap:"""
    
    try:
        response = llm.invoke(prompt)
        answer = response.content if hasattr(response, 'content') else str(response)
        
        # LLM'in cevabÄ±ndan ilgili mailleri filtrele
        # EÄŸer LLM belirli sayÄ±da mail belirtiyorsa, hangi maillerin ilgili olduÄŸunu sor
        import re
        count_matches = re.findall(r'(\d+)\s*(?:adet|tane|mail)', answer.lower())
        
        if count_matches and len(results) > 0:
            llm_count = int(count_matches[0])
            # EÄŸer LLM'in belirttiÄŸi sayÄ±, bulunan mail sayÄ±sÄ±ndan azsa, hangi maillerin ilgili olduÄŸunu sor
            if llm_count < len(results) and llm_count > 0:
                print(f"ğŸ” LLM {llm_count} mail belirtti, {len(results)} mail bulundu. Ä°lgili mailleri filtreliyorum...")
                
                # Hangi maillerin ilgili olduÄŸunu belirlemek iÃ§in ikinci bir LLM Ã§aÄŸrÄ±sÄ±
                mail_list_text = ""
                for i, mail in enumerate(results[:20], 1):  # Ä°lk 20 maili gÃ¶ster (Ã§ok fazla olmasÄ±n)
                    mail_list_text += f"{i}. Konu: {mail.subject}\n   GÃ¶nderen: {mail.sender}\n\n"
                
                filter_prompt = f"""AÅŸaÄŸÄ±daki mail listesinden, kullanÄ±cÄ±nÄ±n sorusuna gerÃ§ekten ilgili olan mailleri seÃ§.

KULLANICI SORUSU: "{request.query}"

LLM CEVABI: "{answer}"

MAIL LÄ°STESÄ°:
{mail_list_text}

GÃ–REV: LLM cevabÄ±nda belirtilen sayÄ±da mail ({llm_count} adet) gerÃ§ekten ilgili olan mailleri seÃ§.

YANIT FORMATI: Sadece JSON formatÄ±nda yanÄ±t ver:
{{
    "relevant_mail_indices": [1, 3, 5]
}}

Sadece ilgili maillerin numaralarÄ±nÄ± (indices) listele. Ã–rnek: EÄŸer 1, 3 ve 5 numaralÄ± mailler ilgiliyse, [1, 3, 5] dÃ¶ndÃ¼r.

YANIT:"""
                
                try:
                    filter_response = llm.invoke(filter_prompt)
                    filter_text = filter_response.content if hasattr(filter_response, 'content') else str(filter_response)
                    
                    # JSON'u parse et
                    if "```json" in filter_text:
                        json_start = filter_text.find("```json") + 7
                        json_end = filter_text.find("```", json_start)
                        json_str = filter_text[json_start:json_end].strip()
                    elif "```" in filter_text:
                        json_start = filter_text.find("```") + 3
                        json_end = filter_text.find("```", json_start)
                        json_str = filter_text[json_start:json_end].strip()
                    else:
                        json_str = filter_text.strip()
                    
                    if "{" in json_str and "}" in json_str:
                        json_start = json_str.find("{")
                        json_end = json_str.rfind("}") + 1
                        json_str = json_str[json_start:json_end]
                    
                    filter_result = json.loads(json_str)
                    relevant_indices = filter_result.get("relevant_mail_indices", [])
                    
                    # Ä°ndeksleri 0-based'e Ã§evir (1-based'den)
                    relevant_indices_0based = [i - 1 for i in relevant_indices if 1 <= i <= len(results)]
                    
                    if relevant_indices_0based:
                        results = [results[i] for i in relevant_indices_0based if 0 <= i < len(results)]
                        print(f"âœ… {len(results)} ilgili mail filtrelendi (LLM: {llm_count} mail belirtti)")
                    else:
                        # Filtreleme baÅŸarÄ±sÄ±z oldu, sadece ilk N tanesini al
                        if len(results) > llm_count:
                            results = results[:llm_count]
                            print(f"âš ï¸ Filtreleme baÅŸarÄ±sÄ±z, ilk {llm_count} mail seÃ§ildi")
                
                except Exception as filter_error:
                    print(f"âš ï¸ Mail filtreleme hatasÄ±: {filter_error}")
                    # Hata durumunda sadece ilk N tanesini al
                    if len(results) > llm_count:
                        results = results[:llm_count]
                        print(f"âš ï¸ Ä°lk {llm_count} mail seÃ§ildi (hata nedeniyle)")
        
    except Exception as e:
        print(f"âš ï¸ LLM cevabÄ± iÅŸlenirken hata: {e}")
        answer = "Arama sonuÃ§larÄ±na gÃ¶re cevap oluÅŸturulamadÄ±."
    
    return {"answer": answer, "mails": results}

# --- Mail Query Conversations ---
class ConversationMessage(BaseModel):
    type: str  # "user" veya "ai"
    text: str
    timestamp: datetime
    mails: Optional[List[MailSummary]] = None  # AI mesajlarÄ±nda mail sonuÃ§larÄ±

class MailConversation(BaseModel):
    id: Optional[str] = None
    tenant_id: str
    messages: List[ConversationMessage]
    created_at: datetime
    updated_at: datetime

class ConversationCreate(BaseModel):
    messages: List[ConversationMessage]

def get_mail_conversations_collection(db: firestore.Client):
    return db.collection("mail_conversations")

@router.post("/conversations", response_model=MailConversation)
def save_mail_conversation(
    conversation: ConversationCreate,
    current_user: UserInDB = Depends(get_current_user)
):
    """Mail sorgulama konuÅŸmasÄ±nÄ± kaydeder."""
    firestore_db = firestore.Client()
    conv_col = get_mail_conversations_collection(firestore_db)
    
    now = datetime.now()
    # Messages'Ä± serialize et (mails bilgisi de dahil)
    messages_data = []
    for msg in conversation.messages:
        msg_dict = msg.model_dump()
        # Mails varsa, MailSummary objelerini dict'e Ã§evir
        if msg_dict.get("mails"):
            msg_dict["mails"] = [mail.model_dump() if hasattr(mail, 'model_dump') else mail for mail in msg_dict["mails"]]
        messages_data.append(msg_dict)
    
    conv_data = {
        "tenant_id": current_user.tenant_id,
        "messages": messages_data,
        "created_at": now,
        "updated_at": now
    }
    
    doc_ref = conv_col.document()
    conv_data["id"] = doc_ref.id
    doc_ref.set(conv_data)
    
    return MailConversation(**conv_data)

@router.get("/conversations", response_model=List[MailConversation])
def get_mail_conversations(
    limit: int = 50,
    current_user: UserInDB = Depends(get_current_user)
):
    """Mail sorgulama konuÅŸmalarÄ±nÄ± getirir (tarih bazlÄ±, en yeni Ã¶nce)."""
    firestore_db = firestore.Client()
    conv_col = get_mail_conversations_collection(firestore_db)
    
    query = (
        conv_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
        .order_by("updated_at", direction=firestore.Query.DESCENDING)
        .limit(limit)
    )
    
    conversations = []
    for doc in query.stream():
        data = doc.to_dict()
        data["id"] = doc.id
        # Timestamp'leri datetime'a Ã§evir
        if "created_at" in data:
            created_at = data["created_at"]
            if hasattr(created_at, 'timestamp'):
                data["created_at"] = datetime.fromtimestamp(created_at.timestamp())
            elif isinstance(created_at, str):
                try:
                    data["created_at"] = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                except:
                    data["created_at"] = datetime.now()
        if "updated_at" in data:
            updated_at = data["updated_at"]
            if hasattr(updated_at, 'timestamp'):
                data["updated_at"] = datetime.fromtimestamp(updated_at.timestamp())
            elif isinstance(updated_at, str):
                try:
                    data["updated_at"] = datetime.fromisoformat(updated_at.replace('Z', '+00:00'))
                except:
                    data["updated_at"] = datetime.now()
        # Messages iÃ§indeki timestamp'leri ve mails bilgilerini de Ã§evir
        if "messages" in data:
            for msg in data["messages"]:
                if "timestamp" in msg:
                    ts = msg["timestamp"]
                    if hasattr(ts, 'timestamp'):
                        msg["timestamp"] = datetime.fromtimestamp(ts.timestamp())
                    elif isinstance(ts, str):
                        try:
                            msg["timestamp"] = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                        except:
                            msg["timestamp"] = datetime.now()
                # Mails bilgisini parse et (eÄŸer varsa)
                if "mails" in msg and msg["mails"]:
                    parsed_mails = []
                    for mail_data in msg["mails"]:
                        if isinstance(mail_data, dict):
                            # received_at timestamp'ini Ã§evir
                            if "received_at" in mail_data:
                                received_at = mail_data["received_at"]
                                if hasattr(received_at, 'timestamp'):
                                    mail_data["received_at"] = datetime.fromtimestamp(received_at.timestamp())
                                elif isinstance(received_at, str):
                                    try:
                                        mail_data["received_at"] = datetime.fromisoformat(received_at.replace('Z', '+00:00'))
                                    except:
                                        pass
                            parsed_mails.append(MailSummary(**mail_data))
                        else:
                            parsed_mails.append(mail_data)
                    msg["mails"] = parsed_mails
        conversations.append(MailConversation(**data))
    
    return conversations

@router.delete("/conversations/{conversation_id}")
def delete_mail_conversation(
    conversation_id: str,
    current_user: UserInDB = Depends(get_current_user)
):
    """Mail sorgulama konuÅŸmasÄ±nÄ± siler."""
    firestore_db = firestore.Client()
    conv_col = get_mail_conversations_collection(firestore_db)
    
    doc = conv_col.document(conversation_id).get()
    if not doc.exists:
        raise HTTPException(status_code=404, detail="KonuÅŸma bulunamadÄ±.")
    
    data = doc.to_dict()
    if data.get("tenant_id") != current_user.tenant_id:
        raise HTTPException(status_code=403, detail="Bu konuÅŸmaya eriÅŸim yetkiniz yok.")
    
    conv_col.document(conversation_id).delete()
    return {"message": "KonuÅŸma silindi."}

class TaskWithMailId(BaseModel):
    task: str
    mail_id: str
    received_at: Optional[datetime] = None  # Mail tarihi
    subject: str  # Mail konusu

@router.get("/tasks", response_model=List[TaskWithMailId])
def get_potential_tasks(
    period: str = "daily",
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository)
):
    """Potansiyel gÃ¶rev atamalarÄ±nÄ± getirir."""
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    
    query = mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
    
    # UTC+3 (TÃ¼rkiye saati) kullanarak tarih filtreleme
    if period == "daily":
        start = get_today_start_utc3()
        print(f"ğŸ“… Potansiyel gÃ¶revler - GÃ¼nlÃ¼k Ã¶zet - BugÃ¼nÃ¼n baÅŸlangÄ±cÄ± (UTC+3'e gÃ¶re): {start}")
        query = query.where(filter=FieldFilter("received_at", ">=", start))
    elif period == "weekly":
        now_utc3 = get_now_utc3()
        start = now_utc3 - timedelta(days=7)
        print(f"ğŸ“… Potansiyel gÃ¶revler - HaftalÄ±k Ã¶zet - 7 gÃ¼n Ã¶ncesi (UTC+3'e gÃ¶re): {start}")
        query = query.where(filter=FieldFilter("received_at", ">=", start))
    elif period == "custom" and start_date and end_date:
        try:
            if isinstance(start_date, str):
                start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            else:
                start_dt = start_date
            if isinstance(end_date, str):
                end_dt = datetime.strptime(end_date, "%Y-%m-%d")
                end_dt = end_dt.replace(hour=23, minute=59, second=59)
            else:
                end_dt = end_date
            query = query.where(filter=FieldFilter("received_at", ">=", start_dt))
            query = query.where(filter=FieldFilter("received_at", "<=", end_dt))
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"GeÃ§ersiz tarih formatÄ±: {str(e)}")
    
    all_tasks = []
    all_mails = []
    
    # TÃ¼m mailleri topla ve thread'lere gÃ¶re grupla
    for doc in query.stream():
        data = doc.to_dict()
        # Tarih kontrolÃ¼ - Firestore timestamp'ini datetime'a Ã§evir
        received_at = data.get("received_at")
        if received_at:
            if hasattr(received_at, 'timestamp'):
                received_at = datetime.fromtimestamp(received_at.timestamp())
            elif not isinstance(received_at, datetime):
                try:
                    if isinstance(received_at, str):
                        received_at = datetime.fromisoformat(received_at.replace('Z', '+00:00'))
                    else:
                        received_at = datetime.now()
                except:
                    received_at = datetime.now()
            
            # Custom period iÃ§in tarih kontrolÃ¼ (ekstra gÃ¼venlik)
            if period == "custom" and start_date and end_date:
                try:
                    if isinstance(start_date, str):
                        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
                    else:
                        start_dt = start_date
                    if isinstance(end_date, str):
                        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
                        end_dt = end_dt.replace(hour=23, minute=59, second=59)
                    else:
                        end_dt = end_date
                    
                    if received_at < start_dt or received_at > end_dt:
                        continue
                except Exception as e:
                    print(f"âš ï¸ Tarih kontrolÃ¼ hatasÄ±: {e}")
        
        data["id"] = doc.id
        all_mails.append(data)
    
    # Thread'lere gÃ¶re grupla
    threads = {}  # {thread_id: [mail1, mail2, ...]}
    for mail in all_mails:
        thread_id = mail.get("thread_id") or mail.get("message_id") or mail.get("id")
        if thread_id not in threads:
            threads[thread_id] = []
        threads[thread_id].append(mail)
    
    # Her thread iÃ§in potansiyel gÃ¶revleri topla
    for thread_id, thread_mails in threads.items():
        if len(thread_mails) == 1:
            # Tek mail ise direkt gÃ¶revleri ekle
            mail = thread_mails[0]
            tasks = mail.get("potential_tasks", [])
            mail_id = mail.get("id")
            mail_subject = mail.get("subject", "Konu bilinmiyor")
            # Mail tarihini al
            mail_received_at = mail.get("received_at")
            if mail_received_at:
                if hasattr(mail_received_at, 'timestamp'):
                    mail_received_at = datetime.fromtimestamp(mail_received_at.timestamp())
                elif isinstance(mail_received_at, str):
                    try:
                        mail_received_at = datetime.fromisoformat(mail_received_at.replace('Z', '+00:00'))
                    except:
                        mail_received_at = None
            for task in tasks:
                all_tasks.append(TaskWithMailId(task=task, mail_id=mail_id, received_at=mail_received_at, subject=mail_subject))
        else:
            # Birden fazla mail varsa - thread Ã¶zetindeki gÃ¶revleri VE thread iÃ§indeki tÃ¼m maillerin gÃ¶revlerini birleÅŸtir
            # Thread Ã¶zetindeki gÃ¶revler (eÄŸer thread_id bir mail ID'si ise)
            thread_summary_tasks = []
            thread_mail_id = None
            thread_received_at = None
            
            # Thread ID'si bir mail ID'si mi kontrol et
            for mail in thread_mails:
                if mail.get("id") == thread_id:
                    thread_summary_tasks = mail.get("potential_tasks", [])
                    thread_mail_id = mail.get("id")
                    # Thread Ã¶zet mailinin tarihini al
                    thread_received_at = mail.get("received_at")
                    if thread_received_at:
                        if hasattr(thread_received_at, 'timestamp'):
                            thread_received_at = datetime.fromtimestamp(thread_received_at.timestamp())
                        elif isinstance(thread_received_at, str):
                            try:
                                thread_received_at = datetime.fromisoformat(thread_received_at.replace('Z', '+00:00'))
                            except:
                                thread_received_at = None
                    break
            
            # Thread Ã¶zetindeki gÃ¶revleri ekle (eÄŸer varsa)
            if thread_mail_id:
                thread_subject = None
                for m in thread_mails:
                    if m.get("id") == thread_mail_id:
                        thread_subject = m.get("subject", "Konu bilinmiyor")
                        break
                if not thread_subject:
                    thread_subject = thread_mails[0].get("subject", "Konu bilinmiyor") if thread_mails else "Konu bilinmiyor"
                for task in thread_summary_tasks:
                    all_tasks.append(TaskWithMailId(task=task, mail_id=thread_mail_id, received_at=thread_received_at, subject=thread_subject))
            
            # Thread iÃ§indeki TÃœM maillerin gÃ¶revlerini de ekle
            for mail in thread_mails:
                mail_id = mail.get("id")
                mail_subject = mail.get("subject", "Konu bilinmiyor")
                tasks = mail.get("potential_tasks", [])
                # Mail tarihini al
                mail_received_at = mail.get("received_at")
                if mail_received_at:
                    if hasattr(mail_received_at, 'timestamp'):
                        mail_received_at = datetime.fromtimestamp(mail_received_at.timestamp())
                    elif isinstance(mail_received_at, str):
                        try:
                            mail_received_at = datetime.fromisoformat(mail_received_at.replace('Z', '+00:00'))
                        except:
                            mail_received_at = None
                for task in tasks:
                    # Duplicate kontrolÃ¼ - aynÄ± gÃ¶rev zaten eklenmiÅŸse atla
                    if not any(t.task == task and t.mail_id == mail_id for t in all_tasks):
                        all_tasks.append(TaskWithMailId(task=task, mail_id=mail_id, received_at=mail_received_at, subject=mail_subject))
    
    # Tarihe gÃ¶re sÄ±rala (yeniden eskiye - en yeni Ã¶nce)
    all_tasks.sort(key=lambda x: x.received_at if x.received_at else datetime.min, reverse=True)
    
    # Limit'i kaldÄ±rdÄ±k - tÃ¼m gÃ¶revleri dÃ¶ndÃ¼r
    print(f"ğŸ“Š Toplam {len(all_tasks)} potansiyel gÃ¶rev bulundu (period: {period})")
    return all_tasks

class DateWithMailId(BaseModel):
    date: str
    mail_id: str
    subject: str

@router.get("/critical-dates", response_model=Dict[str, List[DateWithMailId]])
def get_critical_dates(
    period: str = "daily",
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository)
):
    """Kritik tarihleri getirir."""
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    
    query = mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
    
    # UTC+3 (TÃ¼rkiye saati) kullanarak tarih filtreleme
    if period == "daily":
        start = get_today_start_utc3()
        print(f"ğŸ“… Kritik tarihler - GÃ¼nlÃ¼k Ã¶zet - BugÃ¼nÃ¼n baÅŸlangÄ±cÄ± (UTC+3'e gÃ¶re): {start}")
        query = query.where(filter=FieldFilter("received_at", ">=", start))
    elif period == "weekly":
        now_utc3 = get_now_utc3()
        start = now_utc3 - timedelta(days=7)
        print(f"ğŸ“… Kritik tarihler - HaftalÄ±k Ã¶zet - 7 gÃ¼n Ã¶ncesi (UTC+3'e gÃ¶re): {start}")
        query = query.where(filter=FieldFilter("received_at", ">=", start))
    elif period == "custom" and start_date and end_date:
        try:
            if isinstance(start_date, str):
                start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            else:
                start_dt = start_date
            if isinstance(end_date, str):
                end_dt = datetime.strptime(end_date, "%Y-%m-%d")
                end_dt = end_dt.replace(hour=23, minute=59, second=59)
            else:
                end_dt = end_date
            query = query.where(filter=FieldFilter("received_at", ">=", start_dt))
            query = query.where(filter=FieldFilter("received_at", "<=", end_dt))
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"GeÃ§ersiz tarih formatÄ±: {str(e)}")
    
    dates = {"contract_renewal": [], "delivery": [], "meeting": [], "deadline": []}
    for doc in query.stream():
        data = doc.to_dict()
        critical_dates = data.get("critical_dates", {})
        mail_id = doc.id
        mail_subject = data.get("subject", "Konu bilinmiyor")
        for key in dates.keys():
            date_value = critical_dates.get(key)
            if date_value:
                # date_value string, list veya dict olabilir
                if isinstance(date_value, str):
                    # String ise direkt ekle
                    dates[key].append(DateWithMailId(date=date_value, mail_id=mail_id, subject=mail_subject))
                elif isinstance(date_value, list):
                    # List ise her birini ekle
                    for date_item in date_value:
                        if isinstance(date_item, str):
                            dates[key].append(DateWithMailId(date=date_item, mail_id=mail_id, subject=mail_subject))
                elif isinstance(date_value, dict):
                    # Dict ise iÃ§indeki tÃ¼m deÄŸerleri dÃ¼zleÅŸtir
                    for sub_key, sub_value in date_value.items():
                        if isinstance(sub_value, str):
                            dates[key].append(DateWithMailId(date=sub_value, mail_id=mail_id, subject=mail_subject))
                        elif isinstance(sub_value, list):
                            for date_item in sub_value:
                                if isinstance(date_item, str):
                                    dates[key].append(DateWithMailId(date=date_item, mail_id=mail_id, subject=mail_subject))
                else:
                    # DiÄŸer tipler iÃ§in string'e Ã§evir
                    dates[key].append(DateWithMailId(date=str(date_value), mail_id=mail_id, subject=mail_subject))
    
    return dates

# --- Ã–NEMLÄ° HATIRLATMALAR Ã–ZELLÄ°ÄÄ° ---

class UrgentReminder(BaseModel):
    type: str  # "critical_mail", "meeting", "deadline", "delivery", "contract_renewal"
    title: str
    description: str
    date: Optional[str] = None  # Tarih string formatÄ±nda
    time: Optional[str] = None  # Saat bilgisi (varsa)
    mail_id: str
    priority: str = "high"  # "high", "medium", "low"

class UrgentRemindersResponse(BaseModel):
    today: List[UrgentReminder]
    tomorrow: List[UrgentReminder]
    this_week: List[UrgentReminder]
    summary: Optional[str] = None  # BugÃ¼n/yarÄ±n/bu hafta iÃ§in Ã¶zet metin

class ReminderPreferences(BaseModel):
    show_critical_mails: bool = True
    show_meetings: bool = True
    show_deadlines: bool = True
    show_deliveries: bool = True
    show_contract_renewals: bool = True
    show_today: bool = True
    show_tomorrow: bool = True
    show_this_week: bool = True

def parse_date_string(date_str: str) -> Optional[datetime]:
    """Tarih string'ini datetime'a Ã§evirir. Ã‡eÅŸitli formatlarÄ± destekler."""
    if not date_str:
        return None
    
    # YaygÄ±n tarih formatlarÄ±
    date_formats = [
        "%Y-%m-%d",
        "%d.%m.%Y",
        "%d/%m/%Y",
        "%d-%m-%Y",
        "%Y-%m-%d %H:%M:%S",
        "%d.%m.%Y %H:%M",
        "%d/%m/%Y %H:%M",
    ]
    
    for fmt in date_formats:
        try:
            return datetime.strptime(date_str.strip(), fmt)
        except:
            continue
    
    # Tarih parse edilemezse None dÃ¶ndÃ¼r
    return None

def is_date_today_or_tomorrow(date_str: str) -> tuple[bool, bool]:
    """Tarih bugÃ¼n veya yarÄ±n mÄ± kontrol eder. (is_today, is_tomorrow) dÃ¶ndÃ¼rÃ¼r. UTC+3'e gÃ¶re."""
    if not date_str:
        return False, False
    
    parsed_date = parse_date_string(date_str)
    if not parsed_date:
        return False, False
    
    # UTC+3'e gÃ¶re bugÃ¼n ve yarÄ±n
    now_utc3 = datetime.now(TURKEY_TIMEZONE)
    today = now_utc3.date()
    tomorrow = today + timedelta(days=1)
    
    # Tarihi UTC+3'e gÃ¶re kontrol et
    if parsed_date.tzinfo is None:
        # Timezone yoksa UTC+3 olarak kabul et
        date_only = parsed_date.date()
    else:
        # UTC+3'e Ã§evir
        date_only = parsed_date.astimezone(TURKEY_TIMEZONE).date()
    
    is_today = date_only == today
    is_tomorrow = date_only == tomorrow
    
    return is_today, is_tomorrow

@router.get("/urgent-reminders", response_model=UrgentRemindersResponse)
def get_urgent_reminders(
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository)
):
    """BugÃ¼n ve yarÄ±n iÃ§in kritik mailleri ve Ã¶nemli tarihleri getirir."""
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    
    # KullanÄ±cÄ± tercihlerini al
    user_prefs_doc = firestore_db.collection("user_reminder_preferences").document(current_user.id).get()
    prefs = ReminderPreferences()
    if user_prefs_doc.exists:
        prefs_data = user_prefs_doc.to_dict()
        prefs = ReminderPreferences(**prefs_data)
    
    # UTC+3'e gÃ¶re bugÃ¼n, yarÄ±n ve bu hafta tarihlerini hesapla
    now_utc3 = datetime.now(TURKEY_TIMEZONE)
    today = now_utc3.date()
    tomorrow = today + timedelta(days=1)
    
    # Bu haftanÄ±n baÅŸlangÄ±cÄ± (Pazartesi) ve bitiÅŸi (Pazar)
    days_since_monday = now_utc3.weekday()  # 0 = Pazartesi, 6 = Pazar
    week_start = today - timedelta(days=days_since_monday)
    week_end = week_start + timedelta(days=6)
    
    today_start_utc3 = datetime(today.year, today.month, today.day, tzinfo=TURKEY_TIMEZONE)
    tomorrow_end_utc3 = datetime(tomorrow.year, tomorrow.month, tomorrow.day, 23, 59, 59, tzinfo=TURKEY_TIMEZONE)
    week_start_utc3 = datetime(week_start.year, week_start.month, week_start.day, tzinfo=TURKEY_TIMEZONE)
    week_end_utc3 = datetime(week_end.year, week_end.month, week_end.day, 23, 59, 59, tzinfo=TURKEY_TIMEZONE)
    
    # UTC'ye Ã§evir (Firestore UTC kullanÄ±r)
    today_start = today_start_utc3.astimezone(timezone.utc).replace(tzinfo=None)
    tomorrow_end = tomorrow_end_utc3.astimezone(timezone.utc).replace(tzinfo=None)
    week_start_utc = week_start_utc3.astimezone(timezone.utc).replace(tzinfo=None)
    week_end_utc = week_end_utc3.astimezone(timezone.utc).replace(tzinfo=None)
    
    # Son 7 gÃ¼nÃ¼n maillerini al (bugÃ¼n/yarÄ±n/bu hafta iÃ§in kritik olanlarÄ± bulmak iÃ§in)
    start_date = today_start - timedelta(days=7)
    query = (
        mail_col.where(filter=FieldFilter("tenant_id", "==", current_user.tenant_id))
        .where(filter=FieldFilter("received_at", ">=", start_date))
        .where(filter=FieldFilter("received_at", "<=", week_end_utc))
    )
    
    today_reminders = []
    tomorrow_reminders = []
    this_week_reminders = []
    
    for doc in query.stream():
        data = doc.to_dict()
        mail_id = doc.id
        is_critical = data.get("is_critical", False)
        critical_dates = data.get("critical_dates", {})
        subject = data.get("subject", "")
        sender = data.get("sender", "")
        summary = data.get("summary", "")
        
        # Kritik mailler (bugÃ¼n/yarÄ±n alÄ±nan)
        if prefs.show_critical_mails and is_critical:
            received_at = data.get("received_at")
            if received_at:
                if hasattr(received_at, 'timestamp'):
                    received_at = datetime.fromtimestamp(received_at.timestamp())
                elif isinstance(received_at, str):
                    try:
                        received_at = datetime.fromisoformat(received_at.replace('Z', '+00:00'))
                    except:
                        received_at = None
                
                if received_at:
                    # UTC+3'e Ã§evir
                    if received_at.tzinfo is None:
                        received_at_utc3 = received_at.replace(tzinfo=timezone.utc).astimezone(TURKEY_TIMEZONE)
                    else:
                        received_at_utc3 = received_at.astimezone(TURKEY_TIMEZONE)
                    received_date = received_at_utc3.date()
                    
                    if received_date == today:
                        today_reminders.append(UrgentReminder(
                            type="critical_mail",
                            title=f"Kritik Mail: {subject}",
                            description=f"{sender}: {summary[:100] if summary else subject}",
                            mail_id=mail_id,
                            priority="high"
                        ))
                    elif received_date == tomorrow:
                        tomorrow_reminders.append(UrgentReminder(
                            type="critical_mail",
                            title=f"Kritik Mail: {subject}",
                            description=f"{sender}: {summary[:100] if summary else subject}",
                            mail_id=mail_id,
                            priority="high"
                        ))
        
        # Kritik tarihleri kontrol et
        for date_type, date_value in critical_dates.items():
            if not date_value:
                continue
            
            # KullanÄ±cÄ± tercihlerine gÃ¶re filtrele
            if date_type == "meeting" and not prefs.show_meetings:
                continue
            if date_type == "deadline" and not prefs.show_deadlines:
                continue
            if date_type == "delivery" and not prefs.show_deliveries:
                continue
            if date_type == "contract_renewal" and not prefs.show_contract_renewals:
                continue
            
            # Tarih deÄŸerini iÅŸle (string, list veya dict olabilir)
            date_strings = []
            if isinstance(date_value, str):
                date_strings.append(date_value)
            elif isinstance(date_value, list):
                date_strings.extend([str(d) for d in date_value if d])
            elif isinstance(date_value, dict):
                for v in date_value.values():
                    if isinstance(v, str):
                        date_strings.append(v)
                    elif isinstance(v, list):
                        date_strings.extend([str(d) for d in v if d])
            
            # Her tarih iÃ§in bugÃ¼n/yarÄ±n/bu hafta kontrolÃ¼ yap
            for date_str in date_strings:
                is_today, is_tomorrow = is_date_today_or_tomorrow(date_str)
                
                # Bu hafta kontrolÃ¼
                is_this_week = False
                parsed_date = parse_date_string(date_str)
                if parsed_date:
                    if parsed_date.tzinfo is None:
                        parsed_date_utc3 = parsed_date.replace(tzinfo=TURKEY_TIMEZONE)
                    else:
                        parsed_date_utc3 = parsed_date.astimezone(TURKEY_TIMEZONE)
                    date_only = parsed_date_utc3.date()
                    # BugÃ¼n ve yarÄ±n hariÃ§, bu hafta iÃ§inde mi?
                    if not is_today and not is_tomorrow and week_start <= date_only <= week_end:
                        is_this_week = True
                
                if (is_today and prefs.show_today) or (is_tomorrow and prefs.show_tomorrow) or (is_this_week and prefs.show_this_week):
                    # Tarih tipine gÃ¶re baÅŸlÄ±k ve aÃ§Ä±klama oluÅŸtur
                    type_names = {
                        "meeting": "ToplantÄ±",
                        "deadline": "Son Tarih",
                        "delivery": "Teslim Tarihi",
                        "contract_renewal": "SÃ¶zleÅŸme Yenileme"
                    }
                    
                    type_name = type_names.get(date_type, date_type)
                    time_str = None
                    if parsed_date:
                        if parsed_date.tzinfo is None:
                            parsed_date_utc3 = parsed_date.replace(tzinfo=TURKEY_TIMEZONE)
                        else:
                            parsed_date_utc3 = parsed_date.astimezone(TURKEY_TIMEZONE)
                        if parsed_date_utc3.hour != 0 or parsed_date_utc3.minute != 0:
                            time_str = parsed_date_utc3.strftime("%H:%M")
                    
                    reminder = UrgentReminder(
                        type=date_type,
                        title=f"{type_name}: {subject}",
                        description=f"{sender}: {summary[:100] if summary else subject}",
                        date=date_str,
                        time=time_str,
                        mail_id=mail_id,
                        priority="high" if date_type in ["deadline", "meeting"] else "medium"
                    )
                    
                    if is_today:
                        today_reminders.append(reminder)
                    elif is_tomorrow:
                        tomorrow_reminders.append(reminder)
                    elif is_this_week:
                        this_week_reminders.append(reminder)
    
    # Ã–zet metin oluÅŸtur
    summary_parts = []
    if today_reminders:
        critical_count = len([r for r in today_reminders if r.type == "critical_mail"])
        meeting_count = len([r for r in today_reminders if r.type == "meeting"])
        deadline_count = len([r for r in today_reminders if r.type == "deadline"])
        
        today_summary = []
        if critical_count > 0:
            today_summary.append(f"{critical_count} kritik mail")
        if meeting_count > 0:
            today_summary.append(f"{meeting_count} toplantÄ±")
        if deadline_count > 0:
            today_summary.append(f"{deadline_count} son tarih")
        
        if today_summary:
            summary_parts.append(f"BugÃ¼n: {', '.join(today_summary)}")
    
    if tomorrow_reminders:
        critical_count = len([r for r in tomorrow_reminders if r.type == "critical_mail"])
        meeting_count = len([r for r in tomorrow_reminders if r.type == "meeting"])
        deadline_count = len([r for r in tomorrow_reminders if r.type == "deadline"])
        
        tomorrow_summary = []
        if critical_count > 0:
            tomorrow_summary.append(f"{critical_count} kritik mail")
        if meeting_count > 0:
            tomorrow_summary.append(f"{meeting_count} toplantÄ±")
        if deadline_count > 0:
            tomorrow_summary.append(f"{deadline_count} son tarih")
        
        if tomorrow_summary:
            summary_parts.append(f"YarÄ±n: {', '.join(tomorrow_summary)}")
    
    if this_week_reminders:
        meeting_count = len([r for r in this_week_reminders if r.type == "meeting"])
        deadline_count = len([r for r in this_week_reminders if r.type == "deadline"])
        
        week_summary = []
        if meeting_count > 0:
            week_summary.append(f"{meeting_count} toplantÄ±")
        if deadline_count > 0:
            week_summary.append(f"{deadline_count} son tarih")
        
        if week_summary:
            summary_parts.append(f"Bu hafta: {', '.join(week_summary)}")
    
    summary_text = " | ".join(summary_parts) if summary_parts else None
    
    # Ã–nceliÄŸe gÃ¶re sÄ±rala (high -> medium -> low)
    priority_order = {"high": 0, "medium": 1, "low": 2}
    today_reminders.sort(key=lambda x: (priority_order.get(x.priority, 2), x.type))
    tomorrow_reminders.sort(key=lambda x: (priority_order.get(x.priority, 2), x.type))
    this_week_reminders.sort(key=lambda x: (priority_order.get(x.priority, 2), x.type))
    
    return UrgentRemindersResponse(
        today=today_reminders,
        tomorrow=tomorrow_reminders,
        this_week=this_week_reminders,
        summary=summary_text
    )

@router.get("/reminder-preferences", response_model=ReminderPreferences)
def get_reminder_preferences(
    current_user: UserInDB = Depends(get_current_user)
):
    """KullanÄ±cÄ±nÄ±n hatÄ±rlatma tercihlerini getirir."""
    firestore_db = firestore.Client()
    user_prefs_doc = firestore_db.collection("user_reminder_preferences").document(current_user.id).get()
    
    if user_prefs_doc.exists:
        prefs_data = user_prefs_doc.to_dict()
        return ReminderPreferences(**prefs_data)
    else:
        # VarsayÄ±lan tercihler
        return ReminderPreferences()

@router.put("/reminder-preferences", response_model=ReminderPreferences)
def update_reminder_preferences(
    preferences: ReminderPreferences,
    current_user: UserInDB = Depends(get_current_user)
):
    """KullanÄ±cÄ±nÄ±n hatÄ±rlatma tercihlerini gÃ¼nceller."""
    firestore_db = firestore.Client()
    prefs_dict = preferences.model_dump()
    
    firestore_db.collection("user_reminder_preferences").document(current_user.id).set(prefs_dict, merge=True)
    
    return preferences

@router.get("/{mail_id}", response_model=MailSummary)
def get_mail_by_id(
    mail_id: str,
    current_user: UserInDB = Depends(get_current_user),
    db: BaseRepository = Depends(get_db_repository),
    storage: BaseStorageAdapter = Depends(get_storage_adapter)
):
    """Mail ID'ye gÃ¶re mail detayÄ±nÄ± getirir. Ek Ã¶zetleri mail Ã§ekilirken oluÅŸturulur, burada sadece mevcut veriyi dÃ¶ndÃ¼rÃ¼r."""
    firestore_db = firestore.Client()
    mail_col = get_mail_collection(firestore_db)
    doc = mail_col.document(mail_id).get()
    
    if not doc.exists:
        raise HTTPException(status_code=404, detail="Mail bulunamadÄ±.")
    
    data = doc.to_dict()
    if data.get("tenant_id") != current_user.tenant_id:
        raise HTTPException(status_code=403, detail="Bu mail'e eriÅŸim yetkiniz yok.")
    
    # received_at timestamp'ini datetime'a Ã§evir
    if "received_at" in data:
        received_at = data["received_at"]
        if hasattr(received_at, 'timestamp'):
            data["received_at"] = datetime.fromtimestamp(received_at.timestamp())
        elif isinstance(received_at, str):
            try:
                data["received_at"] = datetime.fromisoformat(received_at.replace('Z', '+00:00'))
            except:
                pass
    
    # Mail detayÄ± dÃ¶ndÃ¼rÃ¼lmeden Ã¶nce, maili okunmuÅŸ olarak iÅŸaretle
    if not data.get("is_read", False):
        doc_ref = mail_col.document(mail_id)
        doc_ref.update({"is_read": True})
        data["is_read"] = True
        print(f"âœ… Mail {mail_id} okunmuÅŸ olarak iÅŸaretlendi")
    
    data["id"] = doc.id
    return MailSummary(**data)